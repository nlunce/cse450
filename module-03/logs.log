2024-02-09 11:47:43,860:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-09 11:47:43,861:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-09 11:47:43,861:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-09 11:47:43,861:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-09 11:48:38,128:INFO:PyCaret ClassificationExperiment
2024-02-09 11:48:38,128:INFO:Logging name: clf-default-name
2024-02-09 11:48:38,128:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-02-09 11:48:38,129:INFO:version 3.2.0
2024-02-09 11:48:38,129:INFO:Initializing setup()
2024-02-09 11:48:38,129:INFO:self.USI: ae89
2024-02-09 11:48:38,129:INFO:self._variable_keys: {'memory', 'exp_name_log', 'fold_generator', 'y', 'log_plots_param', 'logging_param', 'gpu_param', 'fix_imbalance', '_ml_usecase', 'pipeline', 'seed', 'fold_groups_param', 'target_param', 'X', 'html_param', '_available_plots', 'y_test', 'fold_shuffle_param', 'gpu_n_jobs_param', 'USI', 'X_test', 'X_train', 'idx', 'data', 'n_jobs_param', 'exp_id', 'y_train', 'is_multiclass'}
2024-02-09 11:48:38,129:INFO:Checking environment
2024-02-09 11:48:38,129:INFO:python_version: 3.11.7
2024-02-09 11:48:38,129:INFO:python_build: ('main', 'Dec  8 2023 14:22:46')
2024-02-09 11:48:38,129:INFO:machine: x86_64
2024-02-09 11:48:38,129:INFO:platform: Linux-6.5.0-kali3-amd64-x86_64-with-glibc2.37
2024-02-09 11:48:38,129:INFO:Memory: svmem(total=8197427200, available=3272818688, percent=60.1, used=4080590848, free=885268480, active=4698001408, inactive=1607716864, buffers=263929856, cached=2967638016, shared=523231232, slab=416059392)
2024-02-09 11:48:38,131:INFO:Physical Core: 2
2024-02-09 11:48:38,131:INFO:Logical Core: 4
2024-02-09 11:48:38,131:INFO:Checking libraries
2024-02-09 11:48:38,131:INFO:System:
2024-02-09 11:48:38,131:INFO:    python: 3.11.7 (main, Dec  8 2023, 14:22:46) [GCC 13.2.0]
2024-02-09 11:48:38,131:INFO:executable: /bin/python
2024-02-09 11:48:38,131:INFO:   machine: Linux-6.5.0-kali3-amd64-x86_64-with-glibc2.37
2024-02-09 11:48:38,132:INFO:PyCaret required dependencies:
2024-02-09 11:48:38,298:INFO:                 pip: 23.3
2024-02-09 11:48:38,298:INFO:          setuptools: 68.1.2
2024-02-09 11:48:38,298:INFO:             pycaret: 3.2.0
2024-02-09 11:48:38,298:INFO:             IPython: 8.14.0
2024-02-09 11:48:38,298:INFO:          ipywidgets: 8.1.1
2024-02-09 11:48:38,299:INFO:                tqdm: 4.64.1
2024-02-09 11:48:38,299:INFO:               numpy: 1.24.2
2024-02-09 11:48:38,299:INFO:              pandas: 1.5.3
2024-02-09 11:48:38,299:INFO:              jinja2: 3.1.2
2024-02-09 11:48:38,299:INFO:               scipy: 1.10.1
2024-02-09 11:48:38,299:INFO:              joblib: 1.3.2
2024-02-09 11:48:38,299:INFO:             sklearn: 1.2.2
2024-02-09 11:48:38,299:INFO:                pyod: 1.1.2
2024-02-09 11:48:38,299:INFO:            imblearn: 0.12.0
2024-02-09 11:48:38,299:INFO:   category_encoders: 2.6.3
2024-02-09 11:48:38,299:INFO:            lightgbm: 4.3.0
2024-02-09 11:48:38,299:INFO:               numba: 0.57.1
2024-02-09 11:48:38,299:INFO:            requests: 2.31.0
2024-02-09 11:48:38,299:INFO:          matplotlib: 3.6.3
2024-02-09 11:48:38,300:INFO:          scikitplot: 0.3.7
2024-02-09 11:48:38,300:INFO:         yellowbrick: 1.5
2024-02-09 11:48:38,300:INFO:              plotly: 5.18.0
2024-02-09 11:48:38,300:INFO:    plotly-resampler: Not installed
2024-02-09 11:48:38,300:INFO:             kaleido: 0.2.1
2024-02-09 11:48:38,300:INFO:           schemdraw: 0.15
2024-02-09 11:48:38,300:INFO:         statsmodels: 0.14.1
2024-02-09 11:48:38,300:INFO:              sktime: 0.21.1
2024-02-09 11:48:38,300:INFO:               tbats: 1.1.3
2024-02-09 11:48:38,300:INFO:            pmdarima: 2.0.4
2024-02-09 11:48:38,300:INFO:              psutil: 5.9.5
2024-02-09 11:48:38,300:INFO:          markupsafe: 2.1.3
2024-02-09 11:48:38,300:INFO:             pickle5: Not installed
2024-02-09 11:48:38,300:INFO:         cloudpickle: 3.0.0
2024-02-09 11:48:38,305:INFO:         deprecation: 2.1.0
2024-02-09 11:48:38,305:INFO:              xxhash: 3.4.1
2024-02-09 11:48:38,305:INFO:           wurlitzer: 3.0.3
2024-02-09 11:48:38,305:INFO:PyCaret optional dependencies:
2024-02-09 11:48:39,809:INFO:                shap: Not installed
2024-02-09 11:48:39,809:INFO:           interpret: Not installed
2024-02-09 11:48:39,809:INFO:                umap: Not installed
2024-02-09 11:48:39,809:INFO:     ydata_profiling: Not installed
2024-02-09 11:48:39,809:INFO:  explainerdashboard: Not installed
2024-02-09 11:48:39,809:INFO:             autoviz: Not installed
2024-02-09 11:48:39,809:INFO:           fairlearn: Not installed
2024-02-09 11:48:39,809:INFO:          deepchecks: Not installed
2024-02-09 11:48:39,809:INFO:             xgboost: 2.0.3
2024-02-09 11:48:39,809:INFO:            catboost: Not installed
2024-02-09 11:48:39,809:INFO:              kmodes: Not installed
2024-02-09 11:48:39,809:INFO:             mlxtend: Not installed
2024-02-09 11:48:39,809:INFO:       statsforecast: Not installed
2024-02-09 11:48:39,809:INFO:        tune_sklearn: Not installed
2024-02-09 11:48:39,809:INFO:                 ray: Not installed
2024-02-09 11:48:39,809:INFO:            hyperopt: Not installed
2024-02-09 11:48:39,809:INFO:              optuna: Not installed
2024-02-09 11:48:39,809:INFO:               skopt: Not installed
2024-02-09 11:48:39,809:INFO:              mlflow: Not installed
2024-02-09 11:48:39,810:INFO:              gradio: Not installed
2024-02-09 11:48:39,810:INFO:             fastapi: 0.101.0
2024-02-09 11:48:39,810:INFO:             uvicorn: 0.24.0
2024-02-09 11:48:39,810:INFO:              m2cgen: Not installed
2024-02-09 11:48:39,810:INFO:           evidently: Not installed
2024-02-09 11:48:39,810:INFO:               fugue: Not installed
2024-02-09 11:48:39,810:INFO:           streamlit: Not installed
2024-02-09 11:48:39,810:INFO:             prophet: Not installed
2024-02-09 11:48:39,810:INFO:None
2024-02-09 11:48:39,810:INFO:Set up data.
2024-02-09 11:48:39,832:INFO:Set up folding strategy.
2024-02-09 11:48:39,832:INFO:Set up train/test split.
2024-02-09 11:48:53,567:INFO:PyCaret ClassificationExperiment
2024-02-09 11:48:53,568:INFO:Logging name: clf-default-name
2024-02-09 11:48:53,568:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-02-09 11:48:53,568:INFO:version 3.2.0
2024-02-09 11:48:53,568:INFO:Initializing setup()
2024-02-09 11:48:53,568:INFO:self.USI: d997
2024-02-09 11:48:53,569:INFO:self._variable_keys: {'memory', 'exp_name_log', 'fold_generator', 'y', 'log_plots_param', 'logging_param', 'gpu_param', 'fix_imbalance', '_ml_usecase', 'pipeline', 'seed', 'fold_groups_param', 'target_param', 'X', 'html_param', '_available_plots', 'y_test', 'fold_shuffle_param', 'gpu_n_jobs_param', 'USI', 'X_test', 'X_train', 'idx', 'data', 'n_jobs_param', 'exp_id', 'y_train', 'is_multiclass'}
2024-02-09 11:48:53,569:INFO:Checking environment
2024-02-09 11:48:53,569:INFO:python_version: 3.11.7
2024-02-09 11:48:53,569:INFO:python_build: ('main', 'Dec  8 2023 14:22:46')
2024-02-09 11:48:53,569:INFO:machine: x86_64
2024-02-09 11:48:53,569:INFO:platform: Linux-6.5.0-kali3-amd64-x86_64-with-glibc2.37
2024-02-09 11:48:53,569:INFO:Memory: svmem(total=8197427200, available=3252711424, percent=60.3, used=4106391552, free=833765376, active=4745474048, inactive=1617928192, buffers=264228864, cached=2993041408, shared=517537792, slab=416571392)
2024-02-09 11:48:53,570:INFO:Physical Core: 2
2024-02-09 11:48:53,570:INFO:Logical Core: 4
2024-02-09 11:48:53,570:INFO:Checking libraries
2024-02-09 11:48:53,570:INFO:System:
2024-02-09 11:48:53,570:INFO:    python: 3.11.7 (main, Dec  8 2023, 14:22:46) [GCC 13.2.0]
2024-02-09 11:48:53,570:INFO:executable: /bin/python
2024-02-09 11:48:53,570:INFO:   machine: Linux-6.5.0-kali3-amd64-x86_64-with-glibc2.37
2024-02-09 11:48:53,570:INFO:PyCaret required dependencies:
2024-02-09 11:48:53,570:INFO:                 pip: 23.3
2024-02-09 11:48:53,570:INFO:          setuptools: 68.1.2
2024-02-09 11:48:53,571:INFO:             pycaret: 3.2.0
2024-02-09 11:48:53,571:INFO:             IPython: 8.14.0
2024-02-09 11:48:53,571:INFO:          ipywidgets: 8.1.1
2024-02-09 11:48:53,571:INFO:                tqdm: 4.64.1
2024-02-09 11:48:53,571:INFO:               numpy: 1.24.2
2024-02-09 11:48:53,571:INFO:              pandas: 1.5.3
2024-02-09 11:48:53,571:INFO:              jinja2: 3.1.2
2024-02-09 11:48:53,571:INFO:               scipy: 1.10.1
2024-02-09 11:48:53,571:INFO:              joblib: 1.3.2
2024-02-09 11:48:53,571:INFO:             sklearn: 1.2.2
2024-02-09 11:48:53,571:INFO:                pyod: 1.1.2
2024-02-09 11:48:53,571:INFO:            imblearn: 0.12.0
2024-02-09 11:48:53,571:INFO:   category_encoders: 2.6.3
2024-02-09 11:48:53,571:INFO:            lightgbm: 4.3.0
2024-02-09 11:48:53,571:INFO:               numba: 0.57.1
2024-02-09 11:48:53,571:INFO:            requests: 2.31.0
2024-02-09 11:48:53,571:INFO:          matplotlib: 3.6.3
2024-02-09 11:48:53,571:INFO:          scikitplot: 0.3.7
2024-02-09 11:48:53,571:INFO:         yellowbrick: 1.5
2024-02-09 11:48:53,571:INFO:              plotly: 5.18.0
2024-02-09 11:48:53,571:INFO:    plotly-resampler: Not installed
2024-02-09 11:48:53,572:INFO:             kaleido: 0.2.1
2024-02-09 11:48:53,572:INFO:           schemdraw: 0.15
2024-02-09 11:48:53,572:INFO:         statsmodels: 0.14.1
2024-02-09 11:48:53,572:INFO:              sktime: 0.21.1
2024-02-09 11:48:53,572:INFO:               tbats: 1.1.3
2024-02-09 11:48:53,572:INFO:            pmdarima: 2.0.4
2024-02-09 11:48:53,572:INFO:              psutil: 5.9.5
2024-02-09 11:48:53,572:INFO:          markupsafe: 2.1.3
2024-02-09 11:48:53,572:INFO:             pickle5: Not installed
2024-02-09 11:48:53,572:INFO:         cloudpickle: 3.0.0
2024-02-09 11:48:53,572:INFO:         deprecation: 2.1.0
2024-02-09 11:48:53,572:INFO:              xxhash: 3.4.1
2024-02-09 11:48:53,572:INFO:           wurlitzer: 3.0.3
2024-02-09 11:48:53,572:INFO:PyCaret optional dependencies:
2024-02-09 11:48:53,572:INFO:                shap: Not installed
2024-02-09 11:48:53,573:INFO:           interpret: Not installed
2024-02-09 11:48:53,573:INFO:                umap: Not installed
2024-02-09 11:48:53,573:INFO:     ydata_profiling: Not installed
2024-02-09 11:48:53,573:INFO:  explainerdashboard: Not installed
2024-02-09 11:48:53,573:INFO:             autoviz: Not installed
2024-02-09 11:48:53,573:INFO:           fairlearn: Not installed
2024-02-09 11:48:53,573:INFO:          deepchecks: Not installed
2024-02-09 11:48:53,573:INFO:             xgboost: 2.0.3
2024-02-09 11:48:53,573:INFO:            catboost: Not installed
2024-02-09 11:48:53,573:INFO:              kmodes: Not installed
2024-02-09 11:48:53,573:INFO:             mlxtend: Not installed
2024-02-09 11:48:53,573:INFO:       statsforecast: Not installed
2024-02-09 11:48:53,573:INFO:        tune_sklearn: Not installed
2024-02-09 11:48:53,573:INFO:                 ray: Not installed
2024-02-09 11:48:53,573:INFO:            hyperopt: Not installed
2024-02-09 11:48:53,573:INFO:              optuna: Not installed
2024-02-09 11:48:53,573:INFO:               skopt: Not installed
2024-02-09 11:48:53,573:INFO:              mlflow: Not installed
2024-02-09 11:48:53,573:INFO:              gradio: Not installed
2024-02-09 11:48:53,573:INFO:             fastapi: 0.101.0
2024-02-09 11:48:53,574:INFO:             uvicorn: 0.24.0
2024-02-09 11:48:53,574:INFO:              m2cgen: Not installed
2024-02-09 11:48:53,574:INFO:           evidently: Not installed
2024-02-09 11:48:53,574:INFO:               fugue: Not installed
2024-02-09 11:48:53,574:INFO:           streamlit: Not installed
2024-02-09 11:48:53,574:INFO:             prophet: Not installed
2024-02-09 11:48:53,574:INFO:None
2024-02-09 11:48:53,574:INFO:Set up data.
2024-02-09 11:48:53,600:INFO:Set up folding strategy.
2024-02-09 11:48:53,600:INFO:Set up train/test split.
2024-02-09 11:49:48,068:INFO:PyCaret ClassificationExperiment
2024-02-09 11:49:48,068:INFO:Logging name: clf-default-name
2024-02-09 11:49:48,068:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-02-09 11:49:48,068:INFO:version 3.2.0
2024-02-09 11:49:48,068:INFO:Initializing setup()
2024-02-09 11:49:48,068:INFO:self.USI: 2731
2024-02-09 11:49:48,069:INFO:self._variable_keys: {'memory', 'exp_name_log', 'fold_generator', 'y', 'log_plots_param', 'logging_param', 'gpu_param', 'fix_imbalance', '_ml_usecase', 'pipeline', 'seed', 'fold_groups_param', 'target_param', 'X', 'html_param', '_available_plots', 'y_test', 'fold_shuffle_param', 'gpu_n_jobs_param', 'USI', 'X_test', 'X_train', 'idx', 'data', 'n_jobs_param', 'exp_id', 'y_train', 'is_multiclass'}
2024-02-09 11:49:48,069:INFO:Checking environment
2024-02-09 11:49:48,069:INFO:python_version: 3.11.7
2024-02-09 11:49:48,070:INFO:python_build: ('main', 'Dec  8 2023 14:22:46')
2024-02-09 11:49:48,070:INFO:machine: x86_64
2024-02-09 11:49:48,070:INFO:platform: Linux-6.5.0-kali3-amd64-x86_64-with-glibc2.37
2024-02-09 11:49:48,070:INFO:Memory: svmem(total=8197427200, available=3006099456, percent=63.3, used=4364300288, free=577822720, active=4987023360, inactive=1645146112, buffers=265703424, cached=2989600768, shared=506241024, slab=419545088)
2024-02-09 11:49:48,071:INFO:Physical Core: 2
2024-02-09 11:49:48,071:INFO:Logical Core: 4
2024-02-09 11:49:48,071:INFO:Checking libraries
2024-02-09 11:49:48,071:INFO:System:
2024-02-09 11:49:48,071:INFO:    python: 3.11.7 (main, Dec  8 2023, 14:22:46) [GCC 13.2.0]
2024-02-09 11:49:48,071:INFO:executable: /bin/python
2024-02-09 11:49:48,071:INFO:   machine: Linux-6.5.0-kali3-amd64-x86_64-with-glibc2.37
2024-02-09 11:49:48,071:INFO:PyCaret required dependencies:
2024-02-09 11:49:48,072:INFO:                 pip: 23.3
2024-02-09 11:49:48,072:INFO:          setuptools: 68.1.2
2024-02-09 11:49:48,072:INFO:             pycaret: 3.2.0
2024-02-09 11:49:48,072:INFO:             IPython: 8.14.0
2024-02-09 11:49:48,072:INFO:          ipywidgets: 8.1.1
2024-02-09 11:49:48,072:INFO:                tqdm: 4.64.1
2024-02-09 11:49:48,072:INFO:               numpy: 1.24.2
2024-02-09 11:49:48,072:INFO:              pandas: 1.5.3
2024-02-09 11:49:48,072:INFO:              jinja2: 3.1.2
2024-02-09 11:49:48,072:INFO:               scipy: 1.10.1
2024-02-09 11:49:48,072:INFO:              joblib: 1.3.2
2024-02-09 11:49:48,072:INFO:             sklearn: 1.2.2
2024-02-09 11:49:48,072:INFO:                pyod: 1.1.2
2024-02-09 11:49:48,072:INFO:            imblearn: 0.12.0
2024-02-09 11:49:48,072:INFO:   category_encoders: 2.6.3
2024-02-09 11:49:48,072:INFO:            lightgbm: 4.3.0
2024-02-09 11:49:48,072:INFO:               numba: 0.57.1
2024-02-09 11:49:48,072:INFO:            requests: 2.31.0
2024-02-09 11:49:48,072:INFO:          matplotlib: 3.6.3
2024-02-09 11:49:48,072:INFO:          scikitplot: 0.3.7
2024-02-09 11:49:48,072:INFO:         yellowbrick: 1.5
2024-02-09 11:49:48,073:INFO:              plotly: 5.18.0
2024-02-09 11:49:48,073:INFO:    plotly-resampler: Not installed
2024-02-09 11:49:48,073:INFO:             kaleido: 0.2.1
2024-02-09 11:49:48,073:INFO:           schemdraw: 0.15
2024-02-09 11:49:48,073:INFO:         statsmodels: 0.14.1
2024-02-09 11:49:48,073:INFO:              sktime: 0.21.1
2024-02-09 11:49:48,073:INFO:               tbats: 1.1.3
2024-02-09 11:49:48,073:INFO:            pmdarima: 2.0.4
2024-02-09 11:49:48,073:INFO:              psutil: 5.9.5
2024-02-09 11:49:48,073:INFO:          markupsafe: 2.1.3
2024-02-09 11:49:48,073:INFO:             pickle5: Not installed
2024-02-09 11:49:48,073:INFO:         cloudpickle: 3.0.0
2024-02-09 11:49:48,073:INFO:         deprecation: 2.1.0
2024-02-09 11:49:48,073:INFO:              xxhash: 3.4.1
2024-02-09 11:49:48,073:INFO:           wurlitzer: 3.0.3
2024-02-09 11:49:48,073:INFO:PyCaret optional dependencies:
2024-02-09 11:49:48,073:INFO:                shap: Not installed
2024-02-09 11:49:48,074:INFO:           interpret: Not installed
2024-02-09 11:49:48,074:INFO:                umap: Not installed
2024-02-09 11:49:48,074:INFO:     ydata_profiling: Not installed
2024-02-09 11:49:48,074:INFO:  explainerdashboard: Not installed
2024-02-09 11:49:48,074:INFO:             autoviz: Not installed
2024-02-09 11:49:48,075:INFO:           fairlearn: Not installed
2024-02-09 11:49:48,075:INFO:          deepchecks: Not installed
2024-02-09 11:49:48,075:INFO:             xgboost: 2.0.3
2024-02-09 11:49:48,075:INFO:            catboost: Not installed
2024-02-09 11:49:48,075:INFO:              kmodes: Not installed
2024-02-09 11:49:48,075:INFO:             mlxtend: Not installed
2024-02-09 11:49:48,075:INFO:       statsforecast: Not installed
2024-02-09 11:49:48,075:INFO:        tune_sklearn: Not installed
2024-02-09 11:49:48,075:INFO:                 ray: Not installed
2024-02-09 11:49:48,075:INFO:            hyperopt: Not installed
2024-02-09 11:49:48,075:INFO:              optuna: Not installed
2024-02-09 11:49:48,076:INFO:               skopt: Not installed
2024-02-09 11:49:48,076:INFO:              mlflow: Not installed
2024-02-09 11:49:48,076:INFO:              gradio: Not installed
2024-02-09 11:49:48,076:INFO:             fastapi: 0.101.0
2024-02-09 11:49:48,076:INFO:             uvicorn: 0.24.0
2024-02-09 11:49:48,076:INFO:              m2cgen: Not installed
2024-02-09 11:49:48,076:INFO:           evidently: Not installed
2024-02-09 11:49:48,076:INFO:               fugue: Not installed
2024-02-09 11:49:48,076:INFO:           streamlit: Not installed
2024-02-09 11:49:48,076:INFO:             prophet: Not installed
2024-02-09 11:49:48,076:INFO:None
2024-02-09 11:49:48,076:INFO:Set up data.
2024-02-09 11:49:48,099:INFO:Set up folding strategy.
2024-02-09 11:49:48,099:INFO:Set up train/test split.
2024-02-09 11:50:30,780:INFO:PyCaret ClassificationExperiment
2024-02-09 11:50:30,781:INFO:Logging name: clf-default-name
2024-02-09 11:50:30,781:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-02-09 11:50:30,781:INFO:version 3.2.0
2024-02-09 11:50:30,781:INFO:Initializing setup()
2024-02-09 11:50:30,781:INFO:self.USI: 239e
2024-02-09 11:50:30,781:INFO:self._variable_keys: {'memory', 'exp_name_log', 'fold_generator', 'y', 'log_plots_param', 'logging_param', 'gpu_param', 'fix_imbalance', '_ml_usecase', 'pipeline', 'seed', 'fold_groups_param', 'target_param', 'X', 'html_param', '_available_plots', 'y_test', 'fold_shuffle_param', 'gpu_n_jobs_param', 'USI', 'X_test', 'X_train', 'idx', 'data', 'n_jobs_param', 'exp_id', 'y_train', 'is_multiclass'}
2024-02-09 11:50:30,781:INFO:Checking environment
2024-02-09 11:50:30,781:INFO:python_version: 3.11.7
2024-02-09 11:50:30,781:INFO:python_build: ('main', 'Dec  8 2023 14:22:46')
2024-02-09 11:50:30,781:INFO:machine: x86_64
2024-02-09 11:50:30,781:INFO:platform: Linux-6.5.0-kali3-amd64-x86_64-with-glibc2.37
2024-02-09 11:50:30,782:INFO:Memory: svmem(total=8197427200, available=3086958592, percent=62.3, used=4299780096, free=657952768, active=4920254464, inactive=1631600640, buffers=266309632, cached=2973384704, shared=489902080, slab=419467264)
2024-02-09 11:50:30,783:INFO:Physical Core: 2
2024-02-09 11:50:30,783:INFO:Logical Core: 4
2024-02-09 11:50:30,783:INFO:Checking libraries
2024-02-09 11:50:30,783:INFO:System:
2024-02-09 11:50:30,784:INFO:    python: 3.11.7 (main, Dec  8 2023, 14:22:46) [GCC 13.2.0]
2024-02-09 11:50:30,784:INFO:executable: /bin/python
2024-02-09 11:50:30,784:INFO:   machine: Linux-6.5.0-kali3-amd64-x86_64-with-glibc2.37
2024-02-09 11:50:30,784:INFO:PyCaret required dependencies:
2024-02-09 11:50:30,784:INFO:                 pip: 23.3
2024-02-09 11:50:30,784:INFO:          setuptools: 68.1.2
2024-02-09 11:50:30,785:INFO:             pycaret: 3.2.0
2024-02-09 11:50:30,785:INFO:             IPython: 8.14.0
2024-02-09 11:50:30,785:INFO:          ipywidgets: 8.1.1
2024-02-09 11:50:30,785:INFO:                tqdm: 4.64.1
2024-02-09 11:50:30,785:INFO:               numpy: 1.24.2
2024-02-09 11:50:30,785:INFO:              pandas: 1.5.3
2024-02-09 11:50:30,785:INFO:              jinja2: 3.1.2
2024-02-09 11:50:30,785:INFO:               scipy: 1.10.1
2024-02-09 11:50:30,785:INFO:              joblib: 1.3.2
2024-02-09 11:50:30,785:INFO:             sklearn: 1.2.2
2024-02-09 11:50:30,785:INFO:                pyod: 1.1.2
2024-02-09 11:50:30,785:INFO:            imblearn: 0.12.0
2024-02-09 11:50:30,785:INFO:   category_encoders: 2.6.3
2024-02-09 11:50:30,785:INFO:            lightgbm: 4.3.0
2024-02-09 11:50:30,785:INFO:               numba: 0.57.1
2024-02-09 11:50:30,785:INFO:            requests: 2.31.0
2024-02-09 11:50:30,785:INFO:          matplotlib: 3.6.3
2024-02-09 11:50:30,785:INFO:          scikitplot: 0.3.7
2024-02-09 11:50:30,786:INFO:         yellowbrick: 1.5
2024-02-09 11:50:30,786:INFO:              plotly: 5.18.0
2024-02-09 11:50:30,786:INFO:    plotly-resampler: Not installed
2024-02-09 11:50:30,786:INFO:             kaleido: 0.2.1
2024-02-09 11:50:30,786:INFO:           schemdraw: 0.15
2024-02-09 11:50:30,786:INFO:         statsmodels: 0.14.1
2024-02-09 11:50:30,786:INFO:              sktime: 0.21.1
2024-02-09 11:50:30,786:INFO:               tbats: 1.1.3
2024-02-09 11:50:30,786:INFO:            pmdarima: 2.0.4
2024-02-09 11:50:30,786:INFO:              psutil: 5.9.5
2024-02-09 11:50:30,786:INFO:          markupsafe: 2.1.3
2024-02-09 11:50:30,786:INFO:             pickle5: Not installed
2024-02-09 11:50:30,786:INFO:         cloudpickle: 3.0.0
2024-02-09 11:50:30,786:INFO:         deprecation: 2.1.0
2024-02-09 11:50:30,786:INFO:              xxhash: 3.4.1
2024-02-09 11:50:30,786:INFO:           wurlitzer: 3.0.3
2024-02-09 11:50:30,786:INFO:PyCaret optional dependencies:
2024-02-09 11:50:30,786:INFO:                shap: Not installed
2024-02-09 11:50:30,786:INFO:           interpret: Not installed
2024-02-09 11:50:30,786:INFO:                umap: Not installed
2024-02-09 11:50:30,786:INFO:     ydata_profiling: Not installed
2024-02-09 11:50:30,786:INFO:  explainerdashboard: Not installed
2024-02-09 11:50:30,787:INFO:             autoviz: Not installed
2024-02-09 11:50:30,787:INFO:           fairlearn: Not installed
2024-02-09 11:50:30,787:INFO:          deepchecks: Not installed
2024-02-09 11:50:30,787:INFO:             xgboost: 2.0.3
2024-02-09 11:50:30,787:INFO:            catboost: Not installed
2024-02-09 11:50:30,787:INFO:              kmodes: Not installed
2024-02-09 11:50:30,787:INFO:             mlxtend: Not installed
2024-02-09 11:50:30,787:INFO:       statsforecast: Not installed
2024-02-09 11:50:30,787:INFO:        tune_sklearn: Not installed
2024-02-09 11:50:30,787:INFO:                 ray: Not installed
2024-02-09 11:50:30,787:INFO:            hyperopt: Not installed
2024-02-09 11:50:30,787:INFO:              optuna: Not installed
2024-02-09 11:50:30,787:INFO:               skopt: Not installed
2024-02-09 11:50:30,787:INFO:              mlflow: Not installed
2024-02-09 11:50:30,787:INFO:              gradio: Not installed
2024-02-09 11:50:30,787:INFO:             fastapi: 0.101.0
2024-02-09 11:50:30,787:INFO:             uvicorn: 0.24.0
2024-02-09 11:50:30,787:INFO:              m2cgen: Not installed
2024-02-09 11:50:30,787:INFO:           evidently: Not installed
2024-02-09 11:50:30,787:INFO:               fugue: Not installed
2024-02-09 11:50:30,787:INFO:           streamlit: Not installed
2024-02-09 11:50:30,787:INFO:             prophet: Not installed
2024-02-09 11:50:30,787:INFO:None
2024-02-09 11:50:30,787:INFO:Set up data.
2024-02-09 11:50:30,801:INFO:Set up folding strategy.
2024-02-09 11:50:30,801:INFO:Set up train/test split.
2024-02-09 11:50:34,842:INFO:PyCaret ClassificationExperiment
2024-02-09 11:50:34,842:INFO:Logging name: clf-default-name
2024-02-09 11:50:34,842:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-02-09 11:50:34,842:INFO:version 3.2.0
2024-02-09 11:50:34,842:INFO:Initializing setup()
2024-02-09 11:50:34,843:INFO:self.USI: 27d5
2024-02-09 11:50:34,843:INFO:self._variable_keys: {'memory', 'exp_name_log', 'fold_generator', 'y', 'log_plots_param', 'logging_param', 'gpu_param', 'fix_imbalance', '_ml_usecase', 'pipeline', 'seed', 'fold_groups_param', 'target_param', 'X', 'html_param', '_available_plots', 'y_test', 'fold_shuffle_param', 'gpu_n_jobs_param', 'USI', 'X_test', 'X_train', 'idx', 'data', 'n_jobs_param', 'exp_id', 'y_train', 'is_multiclass'}
2024-02-09 11:50:34,843:INFO:Checking environment
2024-02-09 11:50:34,843:INFO:python_version: 3.11.7
2024-02-09 11:50:34,843:INFO:python_build: ('main', 'Dec  8 2023 14:22:46')
2024-02-09 11:50:34,843:INFO:machine: x86_64
2024-02-09 11:50:34,844:INFO:platform: Linux-6.5.0-kali3-amd64-x86_64-with-glibc2.37
2024-02-09 11:50:34,844:INFO:Memory: svmem(total=8197427200, available=3086245888, percent=62.4, used=4298932224, free=656965632, active=4916645888, inactive=1653870592, buffers=266604544, cached=2974924800, shared=491454464, slab=419459072)
2024-02-09 11:50:34,845:INFO:Physical Core: 2
2024-02-09 11:50:34,846:INFO:Logical Core: 4
2024-02-09 11:50:34,847:INFO:Checking libraries
2024-02-09 11:50:34,847:INFO:System:
2024-02-09 11:50:34,847:INFO:    python: 3.11.7 (main, Dec  8 2023, 14:22:46) [GCC 13.2.0]
2024-02-09 11:50:34,848:INFO:executable: /bin/python
2024-02-09 11:50:34,848:INFO:   machine: Linux-6.5.0-kali3-amd64-x86_64-with-glibc2.37
2024-02-09 11:50:34,848:INFO:PyCaret required dependencies:
2024-02-09 11:50:34,848:INFO:                 pip: 23.3
2024-02-09 11:50:34,848:INFO:          setuptools: 68.1.2
2024-02-09 11:50:34,848:INFO:             pycaret: 3.2.0
2024-02-09 11:50:34,849:INFO:             IPython: 8.14.0
2024-02-09 11:50:34,849:INFO:          ipywidgets: 8.1.1
2024-02-09 11:50:34,849:INFO:                tqdm: 4.64.1
2024-02-09 11:50:34,850:INFO:               numpy: 1.24.2
2024-02-09 11:50:34,850:INFO:              pandas: 1.5.3
2024-02-09 11:50:34,850:INFO:              jinja2: 3.1.2
2024-02-09 11:50:34,850:INFO:               scipy: 1.10.1
2024-02-09 11:50:34,850:INFO:              joblib: 1.3.2
2024-02-09 11:50:34,850:INFO:             sklearn: 1.2.2
2024-02-09 11:50:34,850:INFO:                pyod: 1.1.2
2024-02-09 11:50:34,850:INFO:            imblearn: 0.12.0
2024-02-09 11:50:34,850:INFO:   category_encoders: 2.6.3
2024-02-09 11:50:34,850:INFO:            lightgbm: 4.3.0
2024-02-09 11:50:34,850:INFO:               numba: 0.57.1
2024-02-09 11:50:34,852:INFO:            requests: 2.31.0
2024-02-09 11:50:34,852:INFO:          matplotlib: 3.6.3
2024-02-09 11:50:34,852:INFO:          scikitplot: 0.3.7
2024-02-09 11:50:34,853:INFO:         yellowbrick: 1.5
2024-02-09 11:50:34,854:INFO:              plotly: 5.18.0
2024-02-09 11:50:34,854:INFO:    plotly-resampler: Not installed
2024-02-09 11:50:34,854:INFO:             kaleido: 0.2.1
2024-02-09 11:50:34,854:INFO:           schemdraw: 0.15
2024-02-09 11:50:34,854:INFO:         statsmodels: 0.14.1
2024-02-09 11:50:34,854:INFO:              sktime: 0.21.1
2024-02-09 11:50:34,855:INFO:               tbats: 1.1.3
2024-02-09 11:50:34,855:INFO:            pmdarima: 2.0.4
2024-02-09 11:50:34,855:INFO:              psutil: 5.9.5
2024-02-09 11:50:34,855:INFO:          markupsafe: 2.1.3
2024-02-09 11:50:34,855:INFO:             pickle5: Not installed
2024-02-09 11:50:34,855:INFO:         cloudpickle: 3.0.0
2024-02-09 11:50:34,855:INFO:         deprecation: 2.1.0
2024-02-09 11:50:34,855:INFO:              xxhash: 3.4.1
2024-02-09 11:50:34,855:INFO:           wurlitzer: 3.0.3
2024-02-09 11:50:34,855:INFO:PyCaret optional dependencies:
2024-02-09 11:50:34,856:INFO:                shap: Not installed
2024-02-09 11:50:34,856:INFO:           interpret: Not installed
2024-02-09 11:50:34,856:INFO:                umap: Not installed
2024-02-09 11:50:34,856:INFO:     ydata_profiling: Not installed
2024-02-09 11:50:34,856:INFO:  explainerdashboard: Not installed
2024-02-09 11:50:34,856:INFO:             autoviz: Not installed
2024-02-09 11:50:34,856:INFO:           fairlearn: Not installed
2024-02-09 11:50:34,856:INFO:          deepchecks: Not installed
2024-02-09 11:50:34,856:INFO:             xgboost: 2.0.3
2024-02-09 11:50:34,856:INFO:            catboost: Not installed
2024-02-09 11:50:34,856:INFO:              kmodes: Not installed
2024-02-09 11:50:34,856:INFO:             mlxtend: Not installed
2024-02-09 11:50:34,856:INFO:       statsforecast: Not installed
2024-02-09 11:50:34,856:INFO:        tune_sklearn: Not installed
2024-02-09 11:50:34,856:INFO:                 ray: Not installed
2024-02-09 11:50:34,856:INFO:            hyperopt: Not installed
2024-02-09 11:50:34,856:INFO:              optuna: Not installed
2024-02-09 11:50:34,856:INFO:               skopt: Not installed
2024-02-09 11:50:34,856:INFO:              mlflow: Not installed
2024-02-09 11:50:34,856:INFO:              gradio: Not installed
2024-02-09 11:50:34,856:INFO:             fastapi: 0.101.0
2024-02-09 11:50:34,856:INFO:             uvicorn: 0.24.0
2024-02-09 11:50:34,857:INFO:              m2cgen: Not installed
2024-02-09 11:50:34,857:INFO:           evidently: Not installed
2024-02-09 11:50:34,857:INFO:               fugue: Not installed
2024-02-09 11:50:34,857:INFO:           streamlit: Not installed
2024-02-09 11:50:34,857:INFO:             prophet: Not installed
2024-02-09 11:50:34,857:INFO:None
2024-02-09 11:50:34,857:INFO:Set up data.
2024-02-09 11:50:34,886:INFO:Set up folding strategy.
2024-02-09 11:50:34,886:INFO:Set up train/test split.
2024-02-09 11:51:49,883:INFO:PyCaret RegressionExperiment
2024-02-09 11:51:49,883:INFO:Logging name: reg-default-name
2024-02-09 11:51:49,883:INFO:ML Usecase: MLUsecase.REGRESSION
2024-02-09 11:51:49,883:INFO:version 3.2.0
2024-02-09 11:51:49,883:INFO:Initializing setup()
2024-02-09 11:51:49,883:INFO:self.USI: 8da7
2024-02-09 11:51:49,883:INFO:self._variable_keys: {'memory', 'exp_name_log', 'fold_generator', 'y', 'log_plots_param', 'transform_target_param', 'logging_param', 'gpu_param', '_ml_usecase', 'pipeline', 'seed', 'fold_groups_param', 'target_param', 'X', 'html_param', '_available_plots', 'y_test', 'fold_shuffle_param', 'gpu_n_jobs_param', 'USI', 'X_test', 'X_train', 'idx', 'data', 'n_jobs_param', 'exp_id', 'y_train'}
2024-02-09 11:51:49,883:INFO:Checking environment
2024-02-09 11:51:49,883:INFO:python_version: 3.11.7
2024-02-09 11:51:49,883:INFO:python_build: ('main', 'Dec  8 2023 14:22:46')
2024-02-09 11:51:49,883:INFO:machine: x86_64
2024-02-09 11:51:49,883:INFO:platform: Linux-6.5.0-kali3-amd64-x86_64-with-glibc2.37
2024-02-09 11:51:49,884:INFO:Memory: svmem(total=8197427200, available=2997051392, percent=63.4, used=4405055488, free=559849472, active=5016920064, inactive=1660428288, buffers=267501568, cached=2965020672, shared=474554368, slab=419721216)
2024-02-09 11:51:49,885:INFO:Physical Core: 2
2024-02-09 11:51:49,885:INFO:Logical Core: 4
2024-02-09 11:51:49,886:INFO:Checking libraries
2024-02-09 11:51:49,886:INFO:System:
2024-02-09 11:51:49,886:INFO:    python: 3.11.7 (main, Dec  8 2023, 14:22:46) [GCC 13.2.0]
2024-02-09 11:51:49,886:INFO:executable: /bin/python
2024-02-09 11:51:49,886:INFO:   machine: Linux-6.5.0-kali3-amd64-x86_64-with-glibc2.37
2024-02-09 11:51:49,886:INFO:PyCaret required dependencies:
2024-02-09 11:51:49,887:INFO:                 pip: 23.3
2024-02-09 11:51:49,887:INFO:          setuptools: 68.1.2
2024-02-09 11:51:49,887:INFO:             pycaret: 3.2.0
2024-02-09 11:51:49,887:INFO:             IPython: 8.14.0
2024-02-09 11:51:49,887:INFO:          ipywidgets: 8.1.1
2024-02-09 11:51:49,887:INFO:                tqdm: 4.64.1
2024-02-09 11:51:49,887:INFO:               numpy: 1.24.2
2024-02-09 11:51:49,887:INFO:              pandas: 1.5.3
2024-02-09 11:51:49,887:INFO:              jinja2: 3.1.2
2024-02-09 11:51:49,887:INFO:               scipy: 1.10.1
2024-02-09 11:51:49,887:INFO:              joblib: 1.3.2
2024-02-09 11:51:49,887:INFO:             sklearn: 1.2.2
2024-02-09 11:51:49,887:INFO:                pyod: 1.1.2
2024-02-09 11:51:49,887:INFO:            imblearn: 0.12.0
2024-02-09 11:51:49,887:INFO:   category_encoders: 2.6.3
2024-02-09 11:51:49,887:INFO:            lightgbm: 4.3.0
2024-02-09 11:51:49,888:INFO:               numba: 0.57.1
2024-02-09 11:51:49,888:INFO:            requests: 2.31.0
2024-02-09 11:51:49,888:INFO:          matplotlib: 3.6.3
2024-02-09 11:51:49,888:INFO:          scikitplot: 0.3.7
2024-02-09 11:51:49,888:INFO:         yellowbrick: 1.5
2024-02-09 11:51:49,888:INFO:              plotly: 5.18.0
2024-02-09 11:51:49,888:INFO:    plotly-resampler: Not installed
2024-02-09 11:51:49,888:INFO:             kaleido: 0.2.1
2024-02-09 11:51:49,888:INFO:           schemdraw: 0.15
2024-02-09 11:51:49,888:INFO:         statsmodels: 0.14.1
2024-02-09 11:51:49,888:INFO:              sktime: 0.21.1
2024-02-09 11:51:49,888:INFO:               tbats: 1.1.3
2024-02-09 11:51:49,888:INFO:            pmdarima: 2.0.4
2024-02-09 11:51:49,888:INFO:              psutil: 5.9.5
2024-02-09 11:51:49,888:INFO:          markupsafe: 2.1.3
2024-02-09 11:51:49,888:INFO:             pickle5: Not installed
2024-02-09 11:51:49,888:INFO:         cloudpickle: 3.0.0
2024-02-09 11:51:49,889:INFO:         deprecation: 2.1.0
2024-02-09 11:51:49,889:INFO:              xxhash: 3.4.1
2024-02-09 11:51:49,889:INFO:           wurlitzer: 3.0.3
2024-02-09 11:51:49,889:INFO:PyCaret optional dependencies:
2024-02-09 11:51:49,889:INFO:                shap: Not installed
2024-02-09 11:51:49,889:INFO:           interpret: Not installed
2024-02-09 11:51:49,889:INFO:                umap: Not installed
2024-02-09 11:51:49,889:INFO:     ydata_profiling: Not installed
2024-02-09 11:51:49,889:INFO:  explainerdashboard: Not installed
2024-02-09 11:51:49,889:INFO:             autoviz: Not installed
2024-02-09 11:51:49,889:INFO:           fairlearn: Not installed
2024-02-09 11:51:49,889:INFO:          deepchecks: Not installed
2024-02-09 11:51:49,889:INFO:             xgboost: 2.0.3
2024-02-09 11:51:49,889:INFO:            catboost: Not installed
2024-02-09 11:51:49,889:INFO:              kmodes: Not installed
2024-02-09 11:51:49,889:INFO:             mlxtend: Not installed
2024-02-09 11:51:49,889:INFO:       statsforecast: Not installed
2024-02-09 11:51:49,889:INFO:        tune_sklearn: Not installed
2024-02-09 11:51:49,890:INFO:                 ray: Not installed
2024-02-09 11:51:49,890:INFO:            hyperopt: Not installed
2024-02-09 11:51:49,890:INFO:              optuna: Not installed
2024-02-09 11:51:49,890:INFO:               skopt: Not installed
2024-02-09 11:51:49,890:INFO:              mlflow: Not installed
2024-02-09 11:51:49,890:INFO:              gradio: Not installed
2024-02-09 11:51:49,890:INFO:             fastapi: 0.101.0
2024-02-09 11:51:49,890:INFO:             uvicorn: 0.24.0
2024-02-09 11:51:49,890:INFO:              m2cgen: Not installed
2024-02-09 11:51:49,890:INFO:           evidently: Not installed
2024-02-09 11:51:49,890:INFO:               fugue: Not installed
2024-02-09 11:51:49,890:INFO:           streamlit: Not installed
2024-02-09 11:51:49,891:INFO:             prophet: Not installed
2024-02-09 11:51:49,891:INFO:None
2024-02-09 11:51:49,891:INFO:Set up data.
2024-02-09 11:51:49,919:INFO:Set up folding strategy.
2024-02-09 11:51:49,919:INFO:Set up train/test split.
2024-02-09 11:51:49,947:INFO:Set up index.
2024-02-09 11:51:49,947:INFO:Assigning column types.
2024-02-09 11:51:49,968:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-02-09 11:51:49,969:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-02-09 11:51:49,983:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-02-09 11:51:49,996:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-02-09 11:51:50,142:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-02-09 11:51:50,255:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-02-09 11:51:50,256:INFO:Soft dependency imported: xgboost: 2.0.3
2024-02-09 11:51:50,262:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-02-09 11:51:50,263:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-02-09 11:51:50,273:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-02-09 11:51:50,285:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-02-09 11:51:50,431:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-02-09 11:51:50,511:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-02-09 11:51:50,512:INFO:Soft dependency imported: xgboost: 2.0.3
2024-02-09 11:51:50,518:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-02-09 11:51:50,519:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2024-02-09 11:51:50,529:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-02-09 11:51:50,547:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-02-09 11:51:50,762:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-02-09 11:51:50,839:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-02-09 11:51:50,840:INFO:Soft dependency imported: xgboost: 2.0.3
2024-02-09 11:51:50,842:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-02-09 11:51:50,846:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-02-09 11:51:50,850:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-02-09 11:51:50,932:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-02-09 11:51:50,991:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-02-09 11:51:50,992:INFO:Soft dependency imported: xgboost: 2.0.3
2024-02-09 11:51:50,994:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-02-09 11:51:50,994:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2024-02-09 11:51:51,006:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-02-09 11:51:51,077:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-02-09 11:51:51,137:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-02-09 11:51:51,138:INFO:Soft dependency imported: xgboost: 2.0.3
2024-02-09 11:51:51,144:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-02-09 11:51:51,162:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-02-09 11:51:51,265:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-02-09 11:51:51,345:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-02-09 11:51:51,347:INFO:Soft dependency imported: xgboost: 2.0.3
2024-02-09 11:51:51,350:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-02-09 11:51:51,350:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2024-02-09 11:51:51,472:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-02-09 11:51:51,532:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-02-09 11:51:51,533:INFO:Soft dependency imported: xgboost: 2.0.3
2024-02-09 11:51:51,539:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-02-09 11:51:51,615:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-02-09 11:51:51,670:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-02-09 11:51:51,671:INFO:Soft dependency imported: xgboost: 2.0.3
2024-02-09 11:51:51,674:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-02-09 11:51:51,674:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-02-09 11:51:51,764:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-02-09 11:51:51,877:INFO:Soft dependency imported: xgboost: 2.0.3
2024-02-09 11:51:51,882:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-02-09 11:51:52,012:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-02-09 11:51:52,101:INFO:Soft dependency imported: xgboost: 2.0.3
2024-02-09 11:51:52,108:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-02-09 11:51:52,109:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2024-02-09 11:51:52,263:INFO:Soft dependency imported: xgboost: 2.0.3
2024-02-09 11:51:52,265:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-02-09 11:51:52,398:INFO:Soft dependency imported: xgboost: 2.0.3
2024-02-09 11:51:52,401:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-02-09 11:51:52,405:INFO:Preparing preprocessing pipeline...
2024-02-09 11:51:52,405:INFO:Set up simple imputation.
2024-02-09 11:51:52,444:INFO:Finished creating preprocessing pipeline.
2024-02-09 11:51:52,449:INFO:Pipeline: Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['id', 'bedrooms', 'bathrooms',
                                             'sqft_living', 'sqft_lot',
                                             'floors', 'waterfront', 'view',
                                             'condition', 'grade', 'sqft_above',
                                             'sqft_basement', 'yr_built',
                                             'yr_renovated', 'zipcode', 'lat',
                                             'long', 'sqft_living15',
                                             'sqft_lot15'],
                                    transformer=SimpleImpu...
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated')))],
         verbose=False)
2024-02-09 11:51:52,449:INFO:Creating final display dataframe.
2024-02-09 11:51:52,582:INFO:Setup _display_container:                     Description             Value
0                    Session id              6818
1                        Target             price
2                   Target type        Regression
3           Original data shape       (20000, 20)
4        Transformed data shape       (20000, 20)
5   Transformed train set shape       (14000, 20)
6    Transformed test set shape        (6000, 20)
7              Numeric features                19
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator             KFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  reg-default-name
18                          USI              8da7
2024-02-09 11:51:52,785:INFO:Soft dependency imported: xgboost: 2.0.3
2024-02-09 11:51:52,791:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-02-09 11:51:52,947:INFO:Soft dependency imported: xgboost: 2.0.3
2024-02-09 11:51:52,949:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-02-09 11:51:52,950:INFO:setup() successfully completed in 3.07s...............
2024-02-09 11:53:07,717:INFO:Initializing compare_models()
2024-02-09 11:53:07,717:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fdead172190>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x7fdead172190>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>})
2024-02-09 11:53:07,717:INFO:Checking exceptions
2024-02-09 11:53:07,723:INFO:Preparing display monitor
2024-02-09 11:53:07,781:INFO:Initializing Linear Regression
2024-02-09 11:53:07,781:INFO:Total runtime is 2.8967857360839845e-06 minutes
2024-02-09 11:53:07,787:INFO:SubProcess create_model() called ==================================
2024-02-09 11:53:07,789:INFO:Initializing create_model()
2024-02-09 11:53:07,789:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fdead172190>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fdead302150>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-09 11:53:07,789:INFO:Checking exceptions
2024-02-09 11:53:07,789:INFO:Importing libraries
2024-02-09 11:53:07,789:INFO:Copying training dataset
2024-02-09 11:53:07,803:INFO:Defining folds
2024-02-09 11:53:07,803:INFO:Declaring metric variables
2024-02-09 11:53:07,808:INFO:Importing untrained model
2024-02-09 11:53:07,814:INFO:Linear Regression Imported successfully
2024-02-09 11:53:07,825:INFO:Starting cross validation
2024-02-09 11:53:07,833:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-09 11:53:12,228:INFO:Calculating mean and std
2024-02-09 11:53:12,232:INFO:Creating metrics dataframe
2024-02-09 11:53:12,239:INFO:Uploading results into container
2024-02-09 11:53:12,241:INFO:Uploading model into container now
2024-02-09 11:53:12,243:INFO:_master_model_container: 1
2024-02-09 11:53:12,243:INFO:_display_container: 2
2024-02-09 11:53:12,243:INFO:LinearRegression(copy_X=True, fit_intercept=True, n_jobs=-1, positive=False)
2024-02-09 11:53:12,244:INFO:create_model() successfully completed......................................
2024-02-09 11:53:12,434:INFO:SubProcess create_model() end ==================================
2024-02-09 11:53:12,435:INFO:Creating metrics dataframe
2024-02-09 11:53:12,458:INFO:Initializing Lasso Regression
2024-02-09 11:53:12,459:INFO:Total runtime is 0.07796477874120077 minutes
2024-02-09 11:53:12,465:INFO:SubProcess create_model() called ==================================
2024-02-09 11:53:12,465:INFO:Initializing create_model()
2024-02-09 11:53:12,465:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fdead172190>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fdead302150>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-09 11:53:12,465:INFO:Checking exceptions
2024-02-09 11:53:12,466:INFO:Importing libraries
2024-02-09 11:53:12,466:INFO:Copying training dataset
2024-02-09 11:53:12,485:INFO:Defining folds
2024-02-09 11:53:12,486:INFO:Declaring metric variables
2024-02-09 11:53:12,492:INFO:Importing untrained model
2024-02-09 11:53:12,500:INFO:Lasso Regression Imported successfully
2024-02-09 11:53:12,512:INFO:Starting cross validation
2024-02-09 11:53:12,513:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-09 11:53:13,559:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.346e+14, tolerance: 1.728e+11
  model = cd_fast.enet_coordinate_descent(

2024-02-09 11:53:13,850:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.176e+14, tolerance: 1.590e+11
  model = cd_fast.enet_coordinate_descent(

2024-02-09 11:53:13,924:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.366e+14, tolerance: 1.718e+11
  model = cd_fast.enet_coordinate_descent(

2024-02-09 11:53:14,106:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.336e+14, tolerance: 1.705e+11
  model = cd_fast.enet_coordinate_descent(

2024-02-09 11:53:14,591:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.350e+14, tolerance: 1.709e+11
  model = cd_fast.enet_coordinate_descent(

2024-02-09 11:53:14,820:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.313e+14, tolerance: 1.697e+11
  model = cd_fast.enet_coordinate_descent(

2024-02-09 11:53:15,240:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.277e+14, tolerance: 1.679e+11
  model = cd_fast.enet_coordinate_descent(

2024-02-09 11:53:15,397:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.271e+14, tolerance: 1.680e+11
  model = cd_fast.enet_coordinate_descent(

2024-02-09 11:53:15,540:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.189e+14, tolerance: 1.586e+11
  model = cd_fast.enet_coordinate_descent(

2024-02-09 11:53:15,604:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.345e+14, tolerance: 1.722e+11
  model = cd_fast.enet_coordinate_descent(

2024-02-09 11:53:15,623:INFO:Calculating mean and std
2024-02-09 11:53:15,627:INFO:Creating metrics dataframe
2024-02-09 11:53:15,634:INFO:Uploading results into container
2024-02-09 11:53:15,635:INFO:Uploading model into container now
2024-02-09 11:53:15,635:INFO:_master_model_container: 2
2024-02-09 11:53:15,635:INFO:_display_container: 2
2024-02-09 11:53:15,635:INFO:Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000, positive=False,
      precompute=False, random_state=6818, selection='cyclic', tol=0.0001,
      warm_start=False)
2024-02-09 11:53:15,635:INFO:create_model() successfully completed......................................
2024-02-09 11:53:15,770:INFO:SubProcess create_model() end ==================================
2024-02-09 11:53:15,770:INFO:Creating metrics dataframe
2024-02-09 11:53:15,785:INFO:Initializing Ridge Regression
2024-02-09 11:53:15,785:INFO:Total runtime is 0.13339986006418864 minutes
2024-02-09 11:53:15,788:INFO:SubProcess create_model() called ==================================
2024-02-09 11:53:15,789:INFO:Initializing create_model()
2024-02-09 11:53:15,789:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fdead172190>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fdead302150>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-09 11:53:15,789:INFO:Checking exceptions
2024-02-09 11:53:15,790:INFO:Importing libraries
2024-02-09 11:53:15,790:INFO:Copying training dataset
2024-02-09 11:53:15,805:INFO:Defining folds
2024-02-09 11:53:15,805:INFO:Declaring metric variables
2024-02-09 11:53:15,814:INFO:Importing untrained model
2024-02-09 11:53:15,820:INFO:Ridge Regression Imported successfully
2024-02-09 11:53:15,834:INFO:Starting cross validation
2024-02-09 11:53:15,836:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-09 11:53:15,898:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=9.56236e-24): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-02-09 11:53:15,902:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=9.54422e-24): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-02-09 11:53:15,921:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=9.53279e-24): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-02-09 11:53:15,938:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=9.54337e-24): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-02-09 11:53:15,952:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=9.58486e-24): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-02-09 11:53:15,976:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=9.57834e-24): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-02-09 11:53:15,994:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=9.5886e-24): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-02-09 11:53:16,004:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=9.59309e-24): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-02-09 11:53:16,021:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=9.60614e-24): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-02-09 11:53:16,037:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=9.59406e-24): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-02-09 11:53:16,051:INFO:Calculating mean and std
2024-02-09 11:53:16,052:INFO:Creating metrics dataframe
2024-02-09 11:53:16,055:INFO:Uploading results into container
2024-02-09 11:53:16,056:INFO:Uploading model into container now
2024-02-09 11:53:16,057:INFO:_master_model_container: 3
2024-02-09 11:53:16,057:INFO:_display_container: 2
2024-02-09 11:53:16,057:INFO:Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None, positive=False,
      random_state=6818, solver='auto', tol=0.0001)
2024-02-09 11:53:16,057:INFO:create_model() successfully completed......................................
2024-02-09 11:53:16,186:INFO:SubProcess create_model() end ==================================
2024-02-09 11:53:16,186:INFO:Creating metrics dataframe
2024-02-09 11:53:16,199:INFO:Initializing Elastic Net
2024-02-09 11:53:16,200:INFO:Total runtime is 0.14031701882680256 minutes
2024-02-09 11:53:16,203:INFO:SubProcess create_model() called ==================================
2024-02-09 11:53:16,203:INFO:Initializing create_model()
2024-02-09 11:53:16,203:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fdead172190>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fdead302150>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-09 11:53:16,204:INFO:Checking exceptions
2024-02-09 11:53:16,204:INFO:Importing libraries
2024-02-09 11:53:16,204:INFO:Copying training dataset
2024-02-09 11:53:16,219:INFO:Defining folds
2024-02-09 11:53:16,220:INFO:Declaring metric variables
2024-02-09 11:53:16,227:INFO:Importing untrained model
2024-02-09 11:53:16,234:INFO:Elastic Net Imported successfully
2024-02-09 11:53:16,251:INFO:Starting cross validation
2024-02-09 11:53:16,253:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-09 11:53:17,362:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.176e+14, tolerance: 1.590e+11
  model = cd_fast.enet_coordinate_descent(

2024-02-09 11:53:17,385:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.374e+14, tolerance: 1.705e+11
  model = cd_fast.enet_coordinate_descent(

2024-02-09 11:53:17,501:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.413e+14, tolerance: 1.728e+11
  model = cd_fast.enet_coordinate_descent(

2024-02-09 11:53:17,569:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.407e+14, tolerance: 1.718e+11
  model = cd_fast.enet_coordinate_descent(

2024-02-09 11:53:18,546:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.325e+14, tolerance: 1.680e+11
  model = cd_fast.enet_coordinate_descent(

2024-02-09 11:53:18,614:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.391e+14, tolerance: 1.709e+11
  model = cd_fast.enet_coordinate_descent(

2024-02-09 11:53:18,668:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.358e+14, tolerance: 1.697e+11
  model = cd_fast.enet_coordinate_descent(

2024-02-09 11:53:18,864:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.313e+14, tolerance: 1.679e+11
  model = cd_fast.enet_coordinate_descent(

2024-02-09 11:53:19,146:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.165e+14, tolerance: 1.586e+11
  model = cd_fast.enet_coordinate_descent(

2024-02-09 11:53:19,186:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.386e+14, tolerance: 1.722e+11
  model = cd_fast.enet_coordinate_descent(

2024-02-09 11:53:19,203:INFO:Calculating mean and std
2024-02-09 11:53:19,204:INFO:Creating metrics dataframe
2024-02-09 11:53:19,208:INFO:Uploading results into container
2024-02-09 11:53:19,210:INFO:Uploading model into container now
2024-02-09 11:53:19,211:INFO:_master_model_container: 4
2024-02-09 11:53:19,211:INFO:_display_container: 2
2024-02-09 11:53:19,212:INFO:ElasticNet(alpha=1.0, copy_X=True, fit_intercept=True, l1_ratio=0.5,
           max_iter=1000, positive=False, precompute=False, random_state=6818,
           selection='cyclic', tol=0.0001, warm_start=False)
2024-02-09 11:53:19,212:INFO:create_model() successfully completed......................................
2024-02-09 11:53:19,350:INFO:SubProcess create_model() end ==================================
2024-02-09 11:53:19,350:INFO:Creating metrics dataframe
2024-02-09 11:53:19,368:INFO:Initializing Least Angle Regression
2024-02-09 11:53:19,368:INFO:Total runtime is 0.193130083878835 minutes
2024-02-09 11:53:19,374:INFO:SubProcess create_model() called ==================================
2024-02-09 11:53:19,374:INFO:Initializing create_model()
2024-02-09 11:53:19,375:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fdead172190>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fdead302150>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-09 11:53:19,375:INFO:Checking exceptions
2024-02-09 11:53:19,375:INFO:Importing libraries
2024-02-09 11:53:19,375:INFO:Copying training dataset
2024-02-09 11:53:19,397:INFO:Defining folds
2024-02-09 11:53:19,397:INFO:Declaring metric variables
2024-02-09 11:53:19,404:INFO:Importing untrained model
2024-02-09 11:53:19,413:INFO:Least Angle Regression Imported successfully
2024-02-09 11:53:19,428:INFO:Starting cross validation
2024-02-09 11:53:19,432:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-09 11:53:19,748:INFO:Calculating mean and std
2024-02-09 11:53:19,751:INFO:Creating metrics dataframe
2024-02-09 11:53:19,755:INFO:Uploading results into container
2024-02-09 11:53:19,755:INFO:Uploading model into container now
2024-02-09 11:53:19,756:INFO:_master_model_container: 5
2024-02-09 11:53:19,756:INFO:_display_container: 2
2024-02-09 11:53:19,757:INFO:Lars(copy_X=True, eps=2.220446049250313e-16, fit_intercept=True, fit_path=True,
     jitter=None, n_nonzero_coefs=500, normalize='deprecated',
     precompute='auto', random_state=6818, verbose=False)
2024-02-09 11:53:19,757:INFO:create_model() successfully completed......................................
2024-02-09 11:53:19,886:INFO:SubProcess create_model() end ==================================
2024-02-09 11:53:19,886:INFO:Creating metrics dataframe
2024-02-09 11:53:19,901:INFO:Initializing Lasso Least Angle Regression
2024-02-09 11:53:19,901:INFO:Total runtime is 0.20200297832489011 minutes
2024-02-09 11:53:19,906:INFO:SubProcess create_model() called ==================================
2024-02-09 11:53:19,907:INFO:Initializing create_model()
2024-02-09 11:53:19,907:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fdead172190>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fdead302150>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-09 11:53:19,907:INFO:Checking exceptions
2024-02-09 11:53:19,907:INFO:Importing libraries
2024-02-09 11:53:19,908:INFO:Copying training dataset
2024-02-09 11:53:19,928:INFO:Defining folds
2024-02-09 11:53:19,928:INFO:Declaring metric variables
2024-02-09 11:53:19,934:INFO:Importing untrained model
2024-02-09 11:53:19,939:INFO:Lasso Least Angle Regression Imported successfully
2024-02-09 11:53:19,952:INFO:Starting cross validation
2024-02-09 11:53:19,953:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-09 11:53:20,592:INFO:Calculating mean and std
2024-02-09 11:53:20,596:INFO:Creating metrics dataframe
2024-02-09 11:53:20,604:INFO:Uploading results into container
2024-02-09 11:53:20,605:INFO:Uploading model into container now
2024-02-09 11:53:20,605:INFO:_master_model_container: 6
2024-02-09 11:53:20,605:INFO:_display_container: 2
2024-02-09 11:53:20,606:INFO:LassoLars(alpha=1.0, copy_X=True, eps=2.220446049250313e-16, fit_intercept=True,
          fit_path=True, jitter=None, max_iter=500, normalize='deprecated',
          positive=False, precompute='auto', random_state=6818, verbose=False)
2024-02-09 11:53:20,606:INFO:create_model() successfully completed......................................
2024-02-09 11:53:20,759:INFO:SubProcess create_model() end ==================================
2024-02-09 11:53:20,760:INFO:Creating metrics dataframe
2024-02-09 11:53:20,780:INFO:Initializing Orthogonal Matching Pursuit
2024-02-09 11:53:20,780:INFO:Total runtime is 0.2166550517082214 minutes
2024-02-09 11:53:20,785:INFO:SubProcess create_model() called ==================================
2024-02-09 11:53:20,785:INFO:Initializing create_model()
2024-02-09 11:53:20,785:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fdead172190>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fdead302150>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-09 11:53:20,786:INFO:Checking exceptions
2024-02-09 11:53:20,786:INFO:Importing libraries
2024-02-09 11:53:20,786:INFO:Copying training dataset
2024-02-09 11:53:20,802:INFO:Defining folds
2024-02-09 11:53:20,802:INFO:Declaring metric variables
2024-02-09 11:53:20,807:INFO:Importing untrained model
2024-02-09 11:53:20,814:INFO:Orthogonal Matching Pursuit Imported successfully
2024-02-09 11:53:20,824:INFO:Starting cross validation
2024-02-09 11:53:20,826:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-09 11:53:21,118:INFO:Calculating mean and std
2024-02-09 11:53:21,121:INFO:Creating metrics dataframe
2024-02-09 11:53:21,130:INFO:Uploading results into container
2024-02-09 11:53:21,131:INFO:Uploading model into container now
2024-02-09 11:53:21,132:INFO:_master_model_container: 7
2024-02-09 11:53:21,132:INFO:_display_container: 2
2024-02-09 11:53:21,133:INFO:OrthogonalMatchingPursuit(fit_intercept=True, n_nonzero_coefs=None,
                          normalize='deprecated', precompute='auto', tol=None)
2024-02-09 11:53:21,133:INFO:create_model() successfully completed......................................
2024-02-09 11:53:21,272:INFO:SubProcess create_model() end ==================================
2024-02-09 11:53:21,272:INFO:Creating metrics dataframe
2024-02-09 11:53:21,287:INFO:Initializing Bayesian Ridge
2024-02-09 11:53:21,287:INFO:Total runtime is 0.2251131733258565 minutes
2024-02-09 11:53:21,290:INFO:SubProcess create_model() called ==================================
2024-02-09 11:53:21,291:INFO:Initializing create_model()
2024-02-09 11:53:21,291:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fdead172190>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fdead302150>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-09 11:53:21,291:INFO:Checking exceptions
2024-02-09 11:53:21,291:INFO:Importing libraries
2024-02-09 11:53:21,291:INFO:Copying training dataset
2024-02-09 11:53:21,307:INFO:Defining folds
2024-02-09 11:53:21,307:INFO:Declaring metric variables
2024-02-09 11:53:21,315:INFO:Importing untrained model
2024-02-09 11:53:21,321:INFO:Bayesian Ridge Imported successfully
2024-02-09 11:53:21,333:INFO:Starting cross validation
2024-02-09 11:53:21,334:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-09 11:53:21,746:INFO:Calculating mean and std
2024-02-09 11:53:21,748:INFO:Creating metrics dataframe
2024-02-09 11:53:21,754:INFO:Uploading results into container
2024-02-09 11:53:21,756:INFO:Uploading model into container now
2024-02-09 11:53:21,757:INFO:_master_model_container: 8
2024-02-09 11:53:21,757:INFO:_display_container: 2
2024-02-09 11:53:21,758:INFO:BayesianRidge(alpha_1=1e-06, alpha_2=1e-06, alpha_init=None,
              compute_score=False, copy_X=True, fit_intercept=True,
              lambda_1=1e-06, lambda_2=1e-06, lambda_init=None, n_iter=300,
              tol=0.001, verbose=False)
2024-02-09 11:53:21,758:INFO:create_model() successfully completed......................................
2024-02-09 11:53:21,900:INFO:SubProcess create_model() end ==================================
2024-02-09 11:53:21,900:INFO:Creating metrics dataframe
2024-02-09 11:53:21,912:INFO:Initializing Passive Aggressive Regressor
2024-02-09 11:53:21,912:INFO:Total runtime is 0.235526704788208 minutes
2024-02-09 11:53:21,918:INFO:SubProcess create_model() called ==================================
2024-02-09 11:53:21,918:INFO:Initializing create_model()
2024-02-09 11:53:21,918:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fdead172190>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fdead302150>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-09 11:53:21,918:INFO:Checking exceptions
2024-02-09 11:53:21,919:INFO:Importing libraries
2024-02-09 11:53:21,919:INFO:Copying training dataset
2024-02-09 11:53:21,933:INFO:Defining folds
2024-02-09 11:53:21,933:INFO:Declaring metric variables
2024-02-09 11:53:21,943:INFO:Importing untrained model
2024-02-09 11:53:21,950:INFO:Passive Aggressive Regressor Imported successfully
2024-02-09 11:53:21,962:INFO:Starting cross validation
2024-02-09 11:53:21,964:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-09 11:53:22,536:INFO:Calculating mean and std
2024-02-09 11:53:22,539:INFO:Creating metrics dataframe
2024-02-09 11:53:22,546:INFO:Uploading results into container
2024-02-09 11:53:22,548:INFO:Uploading model into container now
2024-02-09 11:53:22,548:INFO:_master_model_container: 9
2024-02-09 11:53:22,549:INFO:_display_container: 2
2024-02-09 11:53:22,549:INFO:PassiveAggressiveRegressor(C=1.0, average=False, early_stopping=False,
                           epsilon=0.1, fit_intercept=True,
                           loss='epsilon_insensitive', max_iter=1000,
                           n_iter_no_change=5, random_state=6818, shuffle=True,
                           tol=0.001, validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-02-09 11:53:22,549:INFO:create_model() successfully completed......................................
2024-02-09 11:53:22,687:INFO:SubProcess create_model() end ==================================
2024-02-09 11:53:22,687:INFO:Creating metrics dataframe
2024-02-09 11:53:22,700:INFO:Initializing Huber Regressor
2024-02-09 11:53:22,701:INFO:Total runtime is 0.2486655036608378 minutes
2024-02-09 11:53:22,704:INFO:SubProcess create_model() called ==================================
2024-02-09 11:53:22,704:INFO:Initializing create_model()
2024-02-09 11:53:22,704:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fdead172190>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fdead302150>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-09 11:53:22,705:INFO:Checking exceptions
2024-02-09 11:53:22,705:INFO:Importing libraries
2024-02-09 11:53:22,705:INFO:Copying training dataset
2024-02-09 11:53:22,720:INFO:Defining folds
2024-02-09 11:53:22,720:INFO:Declaring metric variables
2024-02-09 11:53:22,726:INFO:Importing untrained model
2024-02-09 11:53:22,732:INFO:Huber Regressor Imported successfully
2024-02-09 11:53:22,748:INFO:Starting cross validation
2024-02-09 11:53:22,749:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-09 11:53:23,169:INFO:Calculating mean and std
2024-02-09 11:53:23,170:INFO:Creating metrics dataframe
2024-02-09 11:53:23,173:INFO:Uploading results into container
2024-02-09 11:53:23,174:INFO:Uploading model into container now
2024-02-09 11:53:23,174:INFO:_master_model_container: 10
2024-02-09 11:53:23,174:INFO:_display_container: 2
2024-02-09 11:53:23,175:INFO:HuberRegressor(alpha=0.0001, epsilon=1.35, fit_intercept=True, max_iter=100,
               tol=1e-05, warm_start=False)
2024-02-09 11:53:23,175:INFO:create_model() successfully completed......................................
2024-02-09 11:53:23,301:INFO:SubProcess create_model() end ==================================
2024-02-09 11:53:23,301:INFO:Creating metrics dataframe
2024-02-09 11:53:23,323:INFO:Initializing K Neighbors Regressor
2024-02-09 11:53:23,323:INFO:Total runtime is 0.2590410629908244 minutes
2024-02-09 11:53:23,330:INFO:SubProcess create_model() called ==================================
2024-02-09 11:53:23,330:INFO:Initializing create_model()
2024-02-09 11:53:23,331:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fdead172190>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fdead302150>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-09 11:53:23,331:INFO:Checking exceptions
2024-02-09 11:53:23,331:INFO:Importing libraries
2024-02-09 11:53:23,331:INFO:Copying training dataset
2024-02-09 11:53:23,347:INFO:Defining folds
2024-02-09 11:53:23,347:INFO:Declaring metric variables
2024-02-09 11:53:23,354:INFO:Importing untrained model
2024-02-09 11:53:23,362:INFO:K Neighbors Regressor Imported successfully
2024-02-09 11:53:23,373:INFO:Starting cross validation
2024-02-09 11:53:23,375:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-09 11:53:24,076:INFO:Calculating mean and std
2024-02-09 11:53:24,079:INFO:Creating metrics dataframe
2024-02-09 11:53:24,086:INFO:Uploading results into container
2024-02-09 11:53:24,087:INFO:Uploading model into container now
2024-02-09 11:53:24,087:INFO:_master_model_container: 11
2024-02-09 11:53:24,087:INFO:_display_container: 2
2024-02-09 11:53:24,087:INFO:KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',
                    metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                    weights='uniform')
2024-02-09 11:53:24,087:INFO:create_model() successfully completed......................................
2024-02-09 11:53:24,217:INFO:SubProcess create_model() end ==================================
2024-02-09 11:53:24,218:INFO:Creating metrics dataframe
2024-02-09 11:53:24,232:INFO:Initializing Decision Tree Regressor
2024-02-09 11:53:24,232:INFO:Total runtime is 0.27419767379760746 minutes
2024-02-09 11:53:24,236:INFO:SubProcess create_model() called ==================================
2024-02-09 11:53:24,236:INFO:Initializing create_model()
2024-02-09 11:53:24,236:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fdead172190>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fdead302150>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-09 11:53:24,236:INFO:Checking exceptions
2024-02-09 11:53:24,236:INFO:Importing libraries
2024-02-09 11:53:24,237:INFO:Copying training dataset
2024-02-09 11:53:24,251:INFO:Defining folds
2024-02-09 11:53:24,251:INFO:Declaring metric variables
2024-02-09 11:53:24,256:INFO:Importing untrained model
2024-02-09 11:53:24,262:INFO:Decision Tree Regressor Imported successfully
2024-02-09 11:53:24,278:INFO:Starting cross validation
2024-02-09 11:53:24,280:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-09 11:53:25,403:INFO:Calculating mean and std
2024-02-09 11:53:25,404:INFO:Creating metrics dataframe
2024-02-09 11:53:25,407:INFO:Uploading results into container
2024-02-09 11:53:25,408:INFO:Uploading model into container now
2024-02-09 11:53:25,408:INFO:_master_model_container: 12
2024-02-09 11:53:25,408:INFO:_display_container: 2
2024-02-09 11:53:25,408:INFO:DecisionTreeRegressor(ccp_alpha=0.0, criterion='squared_error', max_depth=None,
                      max_features=None, max_leaf_nodes=None,
                      min_impurity_decrease=0.0, min_samples_leaf=1,
                      min_samples_split=2, min_weight_fraction_leaf=0.0,
                      random_state=6818, splitter='best')
2024-02-09 11:53:25,408:INFO:create_model() successfully completed......................................
2024-02-09 11:53:25,616:INFO:SubProcess create_model() end ==================================
2024-02-09 11:53:25,617:INFO:Creating metrics dataframe
2024-02-09 11:53:25,636:INFO:Initializing Random Forest Regressor
2024-02-09 11:53:25,636:INFO:Total runtime is 0.29758623838424686 minutes
2024-02-09 11:53:25,639:INFO:SubProcess create_model() called ==================================
2024-02-09 11:53:25,640:INFO:Initializing create_model()
2024-02-09 11:53:25,640:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fdead172190>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fdead302150>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-09 11:53:25,640:INFO:Checking exceptions
2024-02-09 11:53:25,640:INFO:Importing libraries
2024-02-09 11:53:25,640:INFO:Copying training dataset
2024-02-09 11:53:25,656:INFO:Defining folds
2024-02-09 11:53:25,656:INFO:Declaring metric variables
2024-02-09 11:53:25,662:INFO:Importing untrained model
2024-02-09 11:53:25,671:INFO:Random Forest Regressor Imported successfully
2024-02-09 11:53:25,692:INFO:Starting cross validation
2024-02-09 11:53:25,698:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-09 11:54:28,429:INFO:Calculating mean and std
2024-02-09 11:54:28,432:INFO:Creating metrics dataframe
2024-02-09 11:54:28,437:INFO:Uploading results into container
2024-02-09 11:54:28,441:INFO:Uploading model into container now
2024-02-09 11:54:28,442:INFO:_master_model_container: 13
2024-02-09 11:54:28,442:INFO:_display_container: 2
2024-02-09 11:54:28,443:INFO:RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='squared_error',
                      max_depth=None, max_features=1.0, max_leaf_nodes=None,
                      max_samples=None, min_impurity_decrease=0.0,
                      min_samples_leaf=1, min_samples_split=2,
                      min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,
                      oob_score=False, random_state=6818, verbose=0,
                      warm_start=False)
2024-02-09 11:54:28,443:INFO:create_model() successfully completed......................................
2024-02-09 11:54:28,585:INFO:SubProcess create_model() end ==================================
2024-02-09 11:54:28,585:INFO:Creating metrics dataframe
2024-02-09 11:54:28,604:INFO:Initializing Extra Trees Regressor
2024-02-09 11:54:28,604:INFO:Total runtime is 1.3470616380373637 minutes
2024-02-09 11:54:28,611:INFO:SubProcess create_model() called ==================================
2024-02-09 11:54:28,611:INFO:Initializing create_model()
2024-02-09 11:54:28,611:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fdead172190>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fdead302150>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-09 11:54:28,611:INFO:Checking exceptions
2024-02-09 11:54:28,612:INFO:Importing libraries
2024-02-09 11:54:28,612:INFO:Copying training dataset
2024-02-09 11:54:28,626:INFO:Defining folds
2024-02-09 11:54:28,627:INFO:Declaring metric variables
2024-02-09 11:54:28,630:INFO:Importing untrained model
2024-02-09 11:54:28,637:INFO:Extra Trees Regressor Imported successfully
2024-02-09 11:54:28,649:INFO:Starting cross validation
2024-02-09 11:54:28,650:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-09 11:54:57,598:INFO:Calculating mean and std
2024-02-09 11:54:57,601:INFO:Creating metrics dataframe
2024-02-09 11:54:57,606:INFO:Uploading results into container
2024-02-09 11:54:57,606:INFO:Uploading model into container now
2024-02-09 11:54:57,608:INFO:_master_model_container: 14
2024-02-09 11:54:57,608:INFO:_display_container: 2
2024-02-09 11:54:57,609:INFO:ExtraTreesRegressor(bootstrap=False, ccp_alpha=0.0, criterion='squared_error',
                    max_depth=None, max_features=1.0, max_leaf_nodes=None,
                    max_samples=None, min_impurity_decrease=0.0,
                    min_samples_leaf=1, min_samples_split=2,
                    min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,
                    oob_score=False, random_state=6818, verbose=0,
                    warm_start=False)
2024-02-09 11:54:57,610:INFO:create_model() successfully completed......................................
2024-02-09 11:54:57,739:INFO:SubProcess create_model() end ==================================
2024-02-09 11:54:57,740:INFO:Creating metrics dataframe
2024-02-09 11:54:57,759:INFO:Initializing AdaBoost Regressor
2024-02-09 11:54:57,759:INFO:Total runtime is 1.8329728722572327 minutes
2024-02-09 11:54:57,764:INFO:SubProcess create_model() called ==================================
2024-02-09 11:54:57,764:INFO:Initializing create_model()
2024-02-09 11:54:57,764:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fdead172190>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fdead302150>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-09 11:54:57,765:INFO:Checking exceptions
2024-02-09 11:54:57,765:INFO:Importing libraries
2024-02-09 11:54:57,765:INFO:Copying training dataset
2024-02-09 11:54:57,777:INFO:Defining folds
2024-02-09 11:54:57,777:INFO:Declaring metric variables
2024-02-09 11:54:57,783:INFO:Importing untrained model
2024-02-09 11:54:57,788:INFO:AdaBoost Regressor Imported successfully
2024-02-09 11:54:57,805:INFO:Starting cross validation
2024-02-09 11:54:57,806:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-09 11:55:05,606:INFO:Calculating mean and std
2024-02-09 11:55:05,608:INFO:Creating metrics dataframe
2024-02-09 11:55:05,615:INFO:Uploading results into container
2024-02-09 11:55:05,616:INFO:Uploading model into container now
2024-02-09 11:55:05,617:INFO:_master_model_container: 15
2024-02-09 11:55:05,617:INFO:_display_container: 2
2024-02-09 11:55:05,617:INFO:AdaBoostRegressor(base_estimator='deprecated', estimator=None,
                  learning_rate=1.0, loss='linear', n_estimators=50,
                  random_state=6818)
2024-02-09 11:55:05,618:INFO:create_model() successfully completed......................................
2024-02-09 11:55:05,751:INFO:SubProcess create_model() end ==================================
2024-02-09 11:55:05,751:INFO:Creating metrics dataframe
2024-02-09 11:55:05,770:INFO:Initializing Gradient Boosting Regressor
2024-02-09 11:55:05,770:INFO:Total runtime is 1.9664899865786234 minutes
2024-02-09 11:55:05,775:INFO:SubProcess create_model() called ==================================
2024-02-09 11:55:05,775:INFO:Initializing create_model()
2024-02-09 11:55:05,775:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fdead172190>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fdead302150>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-09 11:55:05,776:INFO:Checking exceptions
2024-02-09 11:55:05,776:INFO:Importing libraries
2024-02-09 11:55:05,776:INFO:Copying training dataset
2024-02-09 11:55:05,795:INFO:Defining folds
2024-02-09 11:55:05,796:INFO:Declaring metric variables
2024-02-09 11:55:05,802:INFO:Importing untrained model
2024-02-09 11:55:05,811:INFO:Gradient Boosting Regressor Imported successfully
2024-02-09 11:55:05,824:INFO:Starting cross validation
2024-02-09 11:55:05,825:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-09 11:55:22,450:INFO:Calculating mean and std
2024-02-09 11:55:22,452:INFO:Creating metrics dataframe
2024-02-09 11:55:22,455:INFO:Uploading results into container
2024-02-09 11:55:22,455:INFO:Uploading model into container now
2024-02-09 11:55:22,456:INFO:_master_model_container: 16
2024-02-09 11:55:22,456:INFO:_display_container: 2
2024-02-09 11:55:22,456:INFO:GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',
                          init=None, learning_rate=0.1, loss='squared_error',
                          max_depth=3, max_features=None, max_leaf_nodes=None,
                          min_impurity_decrease=0.0, min_samples_leaf=1,
                          min_samples_split=2, min_weight_fraction_leaf=0.0,
                          n_estimators=100, n_iter_no_change=None,
                          random_state=6818, subsample=1.0, tol=0.0001,
                          validation_fraction=0.1, verbose=0, warm_start=False)
2024-02-09 11:55:22,456:INFO:create_model() successfully completed......................................
2024-02-09 11:55:22,582:INFO:SubProcess create_model() end ==================================
2024-02-09 11:55:22,582:INFO:Creating metrics dataframe
2024-02-09 11:55:22,600:INFO:Initializing Extreme Gradient Boosting
2024-02-09 11:55:22,600:INFO:Total runtime is 2.246993092695872 minutes
2024-02-09 11:55:22,607:INFO:SubProcess create_model() called ==================================
2024-02-09 11:55:22,607:INFO:Initializing create_model()
2024-02-09 11:55:22,607:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fdead172190>, estimator=xgboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fdead302150>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-09 11:55:22,607:INFO:Checking exceptions
2024-02-09 11:55:22,607:INFO:Importing libraries
2024-02-09 11:55:22,607:INFO:Copying training dataset
2024-02-09 11:55:22,622:INFO:Defining folds
2024-02-09 11:55:22,622:INFO:Declaring metric variables
2024-02-09 11:55:22,627:INFO:Importing untrained model
2024-02-09 11:55:22,635:INFO:Extreme Gradient Boosting Imported successfully
2024-02-09 11:55:22,651:INFO:Starting cross validation
2024-02-09 11:55:22,652:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-09 11:55:25,246:INFO:Calculating mean and std
2024-02-09 11:55:25,248:INFO:Creating metrics dataframe
2024-02-09 11:55:25,252:INFO:Uploading results into container
2024-02-09 11:55:25,252:INFO:Uploading model into container now
2024-02-09 11:55:25,252:INFO:_master_model_container: 17
2024-02-09 11:55:25,252:INFO:_display_container: 2
2024-02-09 11:55:25,253:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, objective='reg:squarederror', ...)
2024-02-09 11:55:25,253:INFO:create_model() successfully completed......................................
2024-02-09 11:55:25,383:INFO:SubProcess create_model() end ==================================
2024-02-09 11:55:25,383:INFO:Creating metrics dataframe
2024-02-09 11:55:25,405:INFO:Initializing Light Gradient Boosting Machine
2024-02-09 11:55:25,405:INFO:Total runtime is 2.2937468886375427 minutes
2024-02-09 11:55:25,415:INFO:SubProcess create_model() called ==================================
2024-02-09 11:55:25,415:INFO:Initializing create_model()
2024-02-09 11:55:25,415:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fdead172190>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fdead302150>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-09 11:55:25,415:INFO:Checking exceptions
2024-02-09 11:55:25,415:INFO:Importing libraries
2024-02-09 11:55:25,416:INFO:Copying training dataset
2024-02-09 11:55:25,430:INFO:Defining folds
2024-02-09 11:55:25,430:INFO:Declaring metric variables
2024-02-09 11:55:25,434:INFO:Importing untrained model
2024-02-09 11:55:25,441:INFO:Light Gradient Boosting Machine Imported successfully
2024-02-09 11:55:25,458:INFO:Starting cross validation
2024-02-09 11:55:25,459:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-09 12:00:18,998:INFO:PyCaret RegressionExperiment
2024-02-09 12:00:18,998:INFO:Logging name: reg-default-name
2024-02-09 12:00:18,998:INFO:ML Usecase: MLUsecase.REGRESSION
2024-02-09 12:00:18,998:INFO:version 3.2.0
2024-02-09 12:00:18,998:INFO:Initializing setup()
2024-02-09 12:00:18,998:INFO:self.USI: 3c20
2024-02-09 12:00:18,998:INFO:self._variable_keys: {'memory', 'exp_name_log', 'fold_generator', 'y', 'log_plots_param', 'transform_target_param', 'logging_param', 'gpu_param', '_ml_usecase', 'pipeline', 'seed', 'fold_groups_param', 'target_param', 'X', 'html_param', '_available_plots', 'y_test', 'fold_shuffle_param', 'gpu_n_jobs_param', 'USI', 'X_test', 'X_train', 'idx', 'data', 'n_jobs_param', 'exp_id', 'y_train'}
2024-02-09 12:00:18,998:INFO:Checking environment
2024-02-09 12:00:18,998:INFO:python_version: 3.11.7
2024-02-09 12:00:18,999:INFO:python_build: ('main', 'Dec  8 2023 14:22:46')
2024-02-09 12:00:18,999:INFO:machine: x86_64
2024-02-09 12:00:18,999:INFO:platform: Linux-6.5.0-kali3-amd64-x86_64-with-glibc2.37
2024-02-09 12:00:18,999:INFO:Memory: svmem(total=8197427200, available=2443288576, percent=70.2, used=4936626176, free=1418440704, active=5457932288, inactive=718520320, buffers=20897792, cached=1821462528, shared=496726016, slab=335601664)
2024-02-09 12:00:19,000:INFO:Physical Core: 2
2024-02-09 12:00:19,000:INFO:Logical Core: 4
2024-02-09 12:00:19,000:INFO:Checking libraries
2024-02-09 12:00:19,000:INFO:System:
2024-02-09 12:00:19,000:INFO:    python: 3.11.7 (main, Dec  8 2023, 14:22:46) [GCC 13.2.0]
2024-02-09 12:00:19,000:INFO:executable: /bin/python
2024-02-09 12:00:19,000:INFO:   machine: Linux-6.5.0-kali3-amd64-x86_64-with-glibc2.37
2024-02-09 12:00:19,000:INFO:PyCaret required dependencies:
2024-02-09 12:00:19,001:INFO:                 pip: 23.3
2024-02-09 12:00:19,001:INFO:          setuptools: 68.1.2
2024-02-09 12:00:19,001:INFO:             pycaret: 3.2.0
2024-02-09 12:00:19,001:INFO:             IPython: 8.14.0
2024-02-09 12:00:19,001:INFO:          ipywidgets: 8.1.1
2024-02-09 12:00:19,001:INFO:                tqdm: 4.64.1
2024-02-09 12:00:19,001:INFO:               numpy: 1.24.2
2024-02-09 12:00:19,001:INFO:              pandas: 1.5.3
2024-02-09 12:00:19,001:INFO:              jinja2: 3.1.2
2024-02-09 12:00:19,001:INFO:               scipy: 1.10.1
2024-02-09 12:00:19,001:INFO:              joblib: 1.3.2
2024-02-09 12:00:19,001:INFO:             sklearn: 1.2.2
2024-02-09 12:00:19,001:INFO:                pyod: 1.1.2
2024-02-09 12:00:19,001:INFO:            imblearn: 0.12.0
2024-02-09 12:00:19,001:INFO:   category_encoders: 2.6.3
2024-02-09 12:00:19,001:INFO:            lightgbm: 4.3.0
2024-02-09 12:00:19,002:INFO:               numba: 0.57.1
2024-02-09 12:00:19,002:INFO:            requests: 2.31.0
2024-02-09 12:00:19,002:INFO:          matplotlib: 3.6.3
2024-02-09 12:00:19,002:INFO:          scikitplot: 0.3.7
2024-02-09 12:00:19,002:INFO:         yellowbrick: 1.5
2024-02-09 12:00:19,002:INFO:              plotly: 5.18.0
2024-02-09 12:00:19,002:INFO:    plotly-resampler: Not installed
2024-02-09 12:00:19,002:INFO:             kaleido: 0.2.1
2024-02-09 12:00:19,002:INFO:           schemdraw: 0.15
2024-02-09 12:00:19,002:INFO:         statsmodels: 0.14.1
2024-02-09 12:00:19,002:INFO:              sktime: 0.21.1
2024-02-09 12:00:19,002:INFO:               tbats: 1.1.3
2024-02-09 12:00:19,002:INFO:            pmdarima: 2.0.4
2024-02-09 12:00:19,002:INFO:              psutil: 5.9.5
2024-02-09 12:00:19,002:INFO:          markupsafe: 2.1.3
2024-02-09 12:00:19,002:INFO:             pickle5: Not installed
2024-02-09 12:00:19,002:INFO:         cloudpickle: 3.0.0
2024-02-09 12:00:19,002:INFO:         deprecation: 2.1.0
2024-02-09 12:00:19,002:INFO:              xxhash: 3.4.1
2024-02-09 12:00:19,003:INFO:           wurlitzer: 3.0.3
2024-02-09 12:00:19,003:INFO:PyCaret optional dependencies:
2024-02-09 12:00:19,003:INFO:                shap: Not installed
2024-02-09 12:00:19,003:INFO:           interpret: Not installed
2024-02-09 12:00:19,003:INFO:                umap: Not installed
2024-02-09 12:00:19,003:INFO:     ydata_profiling: Not installed
2024-02-09 12:00:19,003:INFO:  explainerdashboard: Not installed
2024-02-09 12:00:19,003:INFO:             autoviz: Not installed
2024-02-09 12:00:19,003:INFO:           fairlearn: Not installed
2024-02-09 12:00:19,003:INFO:          deepchecks: Not installed
2024-02-09 12:00:19,003:INFO:             xgboost: 2.0.3
2024-02-09 12:00:19,003:INFO:            catboost: Not installed
2024-02-09 12:00:19,003:INFO:              kmodes: Not installed
2024-02-09 12:00:19,003:INFO:             mlxtend: Not installed
2024-02-09 12:00:19,003:INFO:       statsforecast: Not installed
2024-02-09 12:00:19,003:INFO:        tune_sklearn: Not installed
2024-02-09 12:00:19,003:INFO:                 ray: Not installed
2024-02-09 12:00:19,003:INFO:            hyperopt: Not installed
2024-02-09 12:00:19,003:INFO:              optuna: Not installed
2024-02-09 12:00:19,003:INFO:               skopt: Not installed
2024-02-09 12:00:19,004:INFO:              mlflow: Not installed
2024-02-09 12:00:19,004:INFO:              gradio: Not installed
2024-02-09 12:00:19,004:INFO:             fastapi: 0.101.0
2024-02-09 12:00:19,004:INFO:             uvicorn: 0.24.0
2024-02-09 12:00:19,004:INFO:              m2cgen: Not installed
2024-02-09 12:00:19,004:INFO:           evidently: Not installed
2024-02-09 12:00:19,004:INFO:               fugue: Not installed
2024-02-09 12:00:19,004:INFO:           streamlit: Not installed
2024-02-09 12:00:19,004:INFO:             prophet: Not installed
2024-02-09 12:00:19,004:INFO:None
2024-02-09 12:00:19,004:INFO:Set up data.
2024-02-09 12:00:19,033:INFO:Set up folding strategy.
2024-02-09 12:00:19,033:INFO:Set up train/test split.
2024-02-09 12:00:19,050:INFO:Set up index.
2024-02-09 12:00:19,051:INFO:Assigning column types.
2024-02-09 12:00:19,060:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-02-09 12:00:19,060:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-02-09 12:00:19,067:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-02-09 12:00:19,072:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-02-09 12:00:19,148:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-02-09 12:00:19,206:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-02-09 12:00:19,206:INFO:Soft dependency imported: xgboost: 2.0.3
2024-02-09 12:00:19,209:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-02-09 12:00:19,209:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-02-09 12:00:19,213:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-02-09 12:00:19,221:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-02-09 12:00:19,291:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-02-09 12:00:19,346:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-02-09 12:00:19,348:INFO:Soft dependency imported: xgboost: 2.0.3
2024-02-09 12:00:19,352:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-02-09 12:00:19,353:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2024-02-09 12:00:19,357:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-02-09 12:00:19,361:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-02-09 12:00:19,454:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-02-09 12:00:19,547:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-02-09 12:00:19,549:INFO:Soft dependency imported: xgboost: 2.0.3
2024-02-09 12:00:19,554:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-02-09 12:00:19,561:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-02-09 12:00:19,570:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-02-09 12:00:19,671:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-02-09 12:00:19,738:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-02-09 12:00:19,738:INFO:Soft dependency imported: xgboost: 2.0.3
2024-02-09 12:00:19,743:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-02-09 12:00:19,743:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2024-02-09 12:00:19,760:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-02-09 12:00:19,833:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-02-09 12:00:19,889:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-02-09 12:00:19,889:INFO:Soft dependency imported: xgboost: 2.0.3
2024-02-09 12:00:19,892:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-02-09 12:00:19,905:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-02-09 12:00:19,985:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-02-09 12:00:20,042:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-02-09 12:00:20,044:INFO:Soft dependency imported: xgboost: 2.0.3
2024-02-09 12:00:20,049:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-02-09 12:00:20,050:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2024-02-09 12:00:20,135:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-02-09 12:00:20,192:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-02-09 12:00:20,192:INFO:Soft dependency imported: xgboost: 2.0.3
2024-02-09 12:00:20,195:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-02-09 12:00:20,274:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-02-09 12:00:20,323:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-02-09 12:00:20,324:INFO:Soft dependency imported: xgboost: 2.0.3
2024-02-09 12:00:20,326:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-02-09 12:00:20,326:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-02-09 12:00:20,416:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-02-09 12:00:20,471:INFO:Soft dependency imported: xgboost: 2.0.3
2024-02-09 12:00:20,474:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-02-09 12:00:20,594:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-02-09 12:00:20,678:INFO:Soft dependency imported: xgboost: 2.0.3
2024-02-09 12:00:20,683:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-02-09 12:00:20,684:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2024-02-09 12:00:20,829:INFO:Soft dependency imported: xgboost: 2.0.3
2024-02-09 12:00:20,834:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-02-09 12:00:20,996:INFO:Soft dependency imported: xgboost: 2.0.3
2024-02-09 12:00:21,001:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-02-09 12:00:21,002:INFO:Preparing preprocessing pipeline...
2024-02-09 12:00:21,002:INFO:Set up date feature engineering.
2024-02-09 12:00:21,002:INFO:Set up simple imputation.
2024-02-09 12:00:21,081:INFO:Finished creating preprocessing pipeline.
2024-02-09 12:00:21,088:INFO:Pipeline: Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['date'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['id', 'bedrooms', 'bathrooms',
                                             'sqft_living', 'sqft_lot',
                                             'floors', 'waterfront', 'view',
                                             'con...
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated')))],
         verbose=False)
2024-02-09 12:00:21,088:INFO:Creating final display dataframe.
2024-02-09 12:00:21,391:INFO:Setup _display_container:                     Description             Value
0                    Session id              8730
1                        Target             price
2                   Target type        Regression
3           Original data shape       (20000, 21)
4        Transformed data shape       (20000, 23)
5   Transformed train set shape       (14000, 23)
6    Transformed test set shape        (6000, 23)
7              Numeric features                19
8                 Date features                 1
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13               Fold Generator             KFold
14                  Fold Number                10
15                     CPU Jobs                -1
16                      Use GPU             False
17               Log Experiment             False
18              Experiment Name  reg-default-name
19                          USI              3c20
2024-02-09 12:00:21,616:INFO:Soft dependency imported: xgboost: 2.0.3
2024-02-09 12:00:21,623:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-02-09 12:00:21,783:INFO:Soft dependency imported: xgboost: 2.0.3
2024-02-09 12:00:21,787:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-02-09 12:00:21,788:INFO:setup() successfully completed in 2.8s...............
2024-02-09 12:00:21,824:INFO:Initializing compare_models()
2024-02-09 12:00:21,825:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fde8e643550>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x7fde8e643550>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>})
2024-02-09 12:00:21,825:INFO:Checking exceptions
2024-02-09 12:00:21,833:INFO:Preparing display monitor
2024-02-09 12:00:21,895:INFO:Initializing Linear Regression
2024-02-09 12:00:21,895:INFO:Total runtime is 4.804134368896484e-06 minutes
2024-02-09 12:00:21,904:INFO:SubProcess create_model() called ==================================
2024-02-09 12:00:21,904:INFO:Initializing create_model()
2024-02-09 12:00:21,904:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fde8e643550>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fde8df040d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-09 12:00:21,904:INFO:Checking exceptions
2024-02-09 12:00:21,904:INFO:Importing libraries
2024-02-09 12:00:21,904:INFO:Copying training dataset
2024-02-09 12:00:21,922:INFO:Defining folds
2024-02-09 12:00:21,923:INFO:Declaring metric variables
2024-02-09 12:00:21,932:INFO:Importing untrained model
2024-02-09 12:00:21,942:INFO:Linear Regression Imported successfully
2024-02-09 12:00:21,957:INFO:Starting cross validation
2024-02-09 12:00:21,959:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-09 12:00:26,738:INFO:Calculating mean and std
2024-02-09 12:00:26,744:INFO:Creating metrics dataframe
2024-02-09 12:00:26,760:INFO:Uploading results into container
2024-02-09 12:00:26,762:INFO:Uploading model into container now
2024-02-09 12:00:26,763:INFO:_master_model_container: 1
2024-02-09 12:00:26,763:INFO:_display_container: 2
2024-02-09 12:00:26,763:INFO:LinearRegression(copy_X=True, fit_intercept=True, n_jobs=-1, positive=False)
2024-02-09 12:00:26,763:INFO:create_model() successfully completed......................................
2024-02-09 12:00:26,965:INFO:SubProcess create_model() end ==================================
2024-02-09 12:00:26,965:INFO:Creating metrics dataframe
2024-02-09 12:00:26,976:INFO:Initializing Lasso Regression
2024-02-09 12:00:26,976:INFO:Total runtime is 0.08468033075332643 minutes
2024-02-09 12:00:26,979:INFO:SubProcess create_model() called ==================================
2024-02-09 12:00:26,980:INFO:Initializing create_model()
2024-02-09 12:00:26,980:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fde8e643550>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fde8df040d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-09 12:00:26,980:INFO:Checking exceptions
2024-02-09 12:00:26,980:INFO:Importing libraries
2024-02-09 12:00:26,981:INFO:Copying training dataset
2024-02-09 12:00:26,999:INFO:Defining folds
2024-02-09 12:00:26,999:INFO:Declaring metric variables
2024-02-09 12:00:27,005:INFO:Importing untrained model
2024-02-09 12:00:27,011:INFO:Lasso Regression Imported successfully
2024-02-09 12:00:27,025:INFO:Starting cross validation
2024-02-09 12:00:27,027:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-09 12:00:28,326:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.170e+14, tolerance: 1.666e+11
  model = cd_fast.enet_coordinate_descent(

2024-02-09 12:00:28,388:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.194e+14, tolerance: 1.679e+11
  model = cd_fast.enet_coordinate_descent(

2024-02-09 12:00:28,505:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.196e+14, tolerance: 1.700e+11
  model = cd_fast.enet_coordinate_descent(

2024-02-09 12:00:28,641:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.215e+14, tolerance: 1.679e+11
  model = cd_fast.enet_coordinate_descent(

2024-02-09 12:00:29,837:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.190e+14, tolerance: 1.683e+11
  model = cd_fast.enet_coordinate_descent(

2024-02-09 12:00:29,960:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.130e+14, tolerance: 1.650e+11
  model = cd_fast.enet_coordinate_descent(

2024-02-09 12:00:29,975:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.121e+14, tolerance: 1.669e+11
  model = cd_fast.enet_coordinate_descent(

2024-02-09 12:00:30,068:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.153e+14, tolerance: 1.659e+11
  model = cd_fast.enet_coordinate_descent(

2024-02-09 12:00:30,705:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.150e+14, tolerance: 1.658e+11
  model = cd_fast.enet_coordinate_descent(

2024-02-09 12:00:30,753:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.179e+14, tolerance: 1.670e+11
  model = cd_fast.enet_coordinate_descent(

2024-02-09 12:00:30,779:INFO:Calculating mean and std
2024-02-09 12:00:30,783:INFO:Creating metrics dataframe
2024-02-09 12:00:30,790:INFO:Uploading results into container
2024-02-09 12:00:30,790:INFO:Uploading model into container now
2024-02-09 12:00:30,791:INFO:_master_model_container: 2
2024-02-09 12:00:30,791:INFO:_display_container: 2
2024-02-09 12:00:30,791:INFO:Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000, positive=False,
      precompute=False, random_state=8730, selection='cyclic', tol=0.0001,
      warm_start=False)
2024-02-09 12:00:30,791:INFO:create_model() successfully completed......................................
2024-02-09 12:00:30,946:INFO:SubProcess create_model() end ==================================
2024-02-09 12:00:30,946:INFO:Creating metrics dataframe
2024-02-09 12:00:30,963:INFO:Initializing Ridge Regression
2024-02-09 12:00:30,964:INFO:Total runtime is 0.1511453111966451 minutes
2024-02-09 12:00:30,970:INFO:SubProcess create_model() called ==================================
2024-02-09 12:00:30,971:INFO:Initializing create_model()
2024-02-09 12:00:30,971:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fde8e643550>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fde8df040d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-09 12:00:30,971:INFO:Checking exceptions
2024-02-09 12:00:30,971:INFO:Importing libraries
2024-02-09 12:00:30,971:INFO:Copying training dataset
2024-02-09 12:00:30,985:INFO:Defining folds
2024-02-09 12:00:30,985:INFO:Declaring metric variables
2024-02-09 12:00:30,992:INFO:Importing untrained model
2024-02-09 12:00:30,999:INFO:Ridge Regression Imported successfully
2024-02-09 12:00:31,011:INFO:Starting cross validation
2024-02-09 12:00:31,013:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-09 12:00:31,128:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=9.68696e-24): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-02-09 12:00:31,130:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=9.65168e-24): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-02-09 12:00:31,158:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=9.66653e-24): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-02-09 12:00:31,178:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=9.66408e-24): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-02-09 12:00:31,261:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=9.67418e-24): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-02-09 12:00:31,279:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=9.67324e-24): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-02-09 12:00:31,317:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=9.67283e-24): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-02-09 12:00:31,344:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=9.67656e-24): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-02-09 12:00:31,387:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=9.61708e-24): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-02-09 12:00:31,425:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=9.63535e-24): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-02-09 12:00:31,471:INFO:Calculating mean and std
2024-02-09 12:00:31,473:INFO:Creating metrics dataframe
2024-02-09 12:00:31,485:INFO:Uploading results into container
2024-02-09 12:00:31,491:INFO:Uploading model into container now
2024-02-09 12:00:31,492:INFO:_master_model_container: 3
2024-02-09 12:00:31,492:INFO:_display_container: 2
2024-02-09 12:00:31,492:INFO:Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None, positive=False,
      random_state=8730, solver='auto', tol=0.0001)
2024-02-09 12:00:31,493:INFO:create_model() successfully completed......................................
2024-02-09 12:00:31,680:INFO:SubProcess create_model() end ==================================
2024-02-09 12:00:31,680:INFO:Creating metrics dataframe
2024-02-09 12:00:31,703:INFO:Initializing Elastic Net
2024-02-09 12:00:31,703:INFO:Total runtime is 0.16346586942672728 minutes
2024-02-09 12:00:31,708:INFO:SubProcess create_model() called ==================================
2024-02-09 12:00:31,709:INFO:Initializing create_model()
2024-02-09 12:00:31,709:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fde8e643550>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fde8df040d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-09 12:00:31,709:INFO:Checking exceptions
2024-02-09 12:00:31,709:INFO:Importing libraries
2024-02-09 12:00:31,709:INFO:Copying training dataset
2024-02-09 12:00:31,735:INFO:Defining folds
2024-02-09 12:00:31,735:INFO:Declaring metric variables
2024-02-09 12:00:31,742:INFO:Importing untrained model
2024-02-09 12:00:31,749:INFO:Elastic Net Imported successfully
2024-02-09 12:00:31,762:INFO:Starting cross validation
2024-02-09 12:00:31,763:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-09 12:00:32,892:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.319e+14, tolerance: 1.679e+11
  model = cd_fast.enet_coordinate_descent(

2024-02-09 12:00:33,139:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.313e+14, tolerance: 1.666e+11
  model = cd_fast.enet_coordinate_descent(

2024-02-09 12:00:33,461:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.313e+14, tolerance: 1.700e+11
  model = cd_fast.enet_coordinate_descent(

2024-02-09 12:00:33,554:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.299e+14, tolerance: 1.679e+11
  model = cd_fast.enet_coordinate_descent(

2024-02-09 12:00:34,290:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.233e+14, tolerance: 1.650e+11
  model = cd_fast.enet_coordinate_descent(

2024-02-09 12:00:34,345:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.271e+14, tolerance: 1.669e+11
  model = cd_fast.enet_coordinate_descent(

2024-02-09 12:00:35,153:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.297e+14, tolerance: 1.683e+11
  model = cd_fast.enet_coordinate_descent(

2024-02-09 12:00:35,208:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.258e+14, tolerance: 1.659e+11
  model = cd_fast.enet_coordinate_descent(

2024-02-09 12:00:35,368:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.283e+14, tolerance: 1.670e+11
  model = cd_fast.enet_coordinate_descent(

2024-02-09 12:00:35,494:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.264e+14, tolerance: 1.658e+11
  model = cd_fast.enet_coordinate_descent(

2024-02-09 12:00:35,530:INFO:Calculating mean and std
2024-02-09 12:00:35,534:INFO:Creating metrics dataframe
2024-02-09 12:00:35,540:INFO:Uploading results into container
2024-02-09 12:00:35,542:INFO:Uploading model into container now
2024-02-09 12:00:35,542:INFO:_master_model_container: 4
2024-02-09 12:00:35,542:INFO:_display_container: 2
2024-02-09 12:00:35,543:INFO:ElasticNet(alpha=1.0, copy_X=True, fit_intercept=True, l1_ratio=0.5,
           max_iter=1000, positive=False, precompute=False, random_state=8730,
           selection='cyclic', tol=0.0001, warm_start=False)
2024-02-09 12:00:35,543:INFO:create_model() successfully completed......................................
2024-02-09 12:00:35,697:INFO:SubProcess create_model() end ==================================
2024-02-09 12:00:35,697:INFO:Creating metrics dataframe
2024-02-09 12:00:35,711:INFO:Initializing Least Angle Regression
2024-02-09 12:00:35,711:INFO:Total runtime is 0.2302656610806783 minutes
2024-02-09 12:00:35,716:INFO:SubProcess create_model() called ==================================
2024-02-09 12:00:35,716:INFO:Initializing create_model()
2024-02-09 12:00:35,716:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fde8e643550>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fde8df040d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-09 12:00:35,716:INFO:Checking exceptions
2024-02-09 12:00:35,717:INFO:Importing libraries
2024-02-09 12:00:35,717:INFO:Copying training dataset
2024-02-09 12:00:35,737:INFO:Defining folds
2024-02-09 12:00:35,737:INFO:Declaring metric variables
2024-02-09 12:00:35,743:INFO:Importing untrained model
2024-02-09 12:00:35,749:INFO:Least Angle Regression Imported successfully
2024-02-09 12:00:35,759:INFO:Starting cross validation
2024-02-09 12:00:35,760:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-09 12:00:36,173:INFO:Calculating mean and std
2024-02-09 12:00:36,174:INFO:Creating metrics dataframe
2024-02-09 12:00:36,177:INFO:Uploading results into container
2024-02-09 12:00:36,177:INFO:Uploading model into container now
2024-02-09 12:00:36,178:INFO:_master_model_container: 5
2024-02-09 12:00:36,178:INFO:_display_container: 2
2024-02-09 12:00:36,178:INFO:Lars(copy_X=True, eps=2.220446049250313e-16, fit_intercept=True, fit_path=True,
     jitter=None, n_nonzero_coefs=500, normalize='deprecated',
     precompute='auto', random_state=8730, verbose=False)
2024-02-09 12:00:36,178:INFO:create_model() successfully completed......................................
2024-02-09 12:00:36,333:INFO:SubProcess create_model() end ==================================
2024-02-09 12:00:36,333:INFO:Creating metrics dataframe
2024-02-09 12:00:36,352:INFO:Initializing Lasso Least Angle Regression
2024-02-09 12:00:36,353:INFO:Total runtime is 0.24096768299738566 minutes
2024-02-09 12:00:36,358:INFO:SubProcess create_model() called ==================================
2024-02-09 12:00:36,359:INFO:Initializing create_model()
2024-02-09 12:00:36,359:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fde8e643550>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fde8df040d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-09 12:00:36,359:INFO:Checking exceptions
2024-02-09 12:00:36,359:INFO:Importing libraries
2024-02-09 12:00:36,359:INFO:Copying training dataset
2024-02-09 12:00:36,375:INFO:Defining folds
2024-02-09 12:00:36,375:INFO:Declaring metric variables
2024-02-09 12:00:36,380:INFO:Importing untrained model
2024-02-09 12:00:36,388:INFO:Lasso Least Angle Regression Imported successfully
2024-02-09 12:00:36,400:INFO:Starting cross validation
2024-02-09 12:00:36,401:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-09 12:00:36,813:INFO:Calculating mean and std
2024-02-09 12:00:36,816:INFO:Creating metrics dataframe
2024-02-09 12:00:36,820:INFO:Uploading results into container
2024-02-09 12:00:36,820:INFO:Uploading model into container now
2024-02-09 12:00:36,820:INFO:_master_model_container: 6
2024-02-09 12:00:36,821:INFO:_display_container: 2
2024-02-09 12:00:36,821:INFO:LassoLars(alpha=1.0, copy_X=True, eps=2.220446049250313e-16, fit_intercept=True,
          fit_path=True, jitter=None, max_iter=500, normalize='deprecated',
          positive=False, precompute='auto', random_state=8730, verbose=False)
2024-02-09 12:00:36,821:INFO:create_model() successfully completed......................................
2024-02-09 12:00:36,968:INFO:SubProcess create_model() end ==================================
2024-02-09 12:00:36,968:INFO:Creating metrics dataframe
2024-02-09 12:00:36,985:INFO:Initializing Orthogonal Matching Pursuit
2024-02-09 12:00:36,985:INFO:Total runtime is 0.2515093882878621 minutes
2024-02-09 12:00:36,992:INFO:SubProcess create_model() called ==================================
2024-02-09 12:00:36,993:INFO:Initializing create_model()
2024-02-09 12:00:36,993:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fde8e643550>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fde8df040d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-09 12:00:36,993:INFO:Checking exceptions
2024-02-09 12:00:36,993:INFO:Importing libraries
2024-02-09 12:00:36,993:INFO:Copying training dataset
2024-02-09 12:00:37,015:INFO:Defining folds
2024-02-09 12:00:37,016:INFO:Declaring metric variables
2024-02-09 12:00:37,023:INFO:Importing untrained model
2024-02-09 12:00:37,030:INFO:Orthogonal Matching Pursuit Imported successfully
2024-02-09 12:00:37,045:INFO:Starting cross validation
2024-02-09 12:00:37,049:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-09 12:00:37,430:INFO:Calculating mean and std
2024-02-09 12:00:37,432:INFO:Creating metrics dataframe
2024-02-09 12:00:37,436:INFO:Uploading results into container
2024-02-09 12:00:37,437:INFO:Uploading model into container now
2024-02-09 12:00:37,438:INFO:_master_model_container: 7
2024-02-09 12:00:37,438:INFO:_display_container: 2
2024-02-09 12:00:37,439:INFO:OrthogonalMatchingPursuit(fit_intercept=True, n_nonzero_coefs=None,
                          normalize='deprecated', precompute='auto', tol=None)
2024-02-09 12:00:37,439:INFO:create_model() successfully completed......................................
2024-02-09 12:00:37,591:INFO:SubProcess create_model() end ==================================
2024-02-09 12:00:37,592:INFO:Creating metrics dataframe
2024-02-09 12:00:37,606:INFO:Initializing Bayesian Ridge
2024-02-09 12:00:37,606:INFO:Total runtime is 0.26185092131296794 minutes
2024-02-09 12:00:37,611:INFO:SubProcess create_model() called ==================================
2024-02-09 12:00:37,611:INFO:Initializing create_model()
2024-02-09 12:00:37,611:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fde8e643550>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fde8df040d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-09 12:00:37,612:INFO:Checking exceptions
2024-02-09 12:00:37,612:INFO:Importing libraries
2024-02-09 12:00:37,612:INFO:Copying training dataset
2024-02-09 12:00:37,625:INFO:Defining folds
2024-02-09 12:00:37,625:INFO:Declaring metric variables
2024-02-09 12:00:37,633:INFO:Importing untrained model
2024-02-09 12:00:37,638:INFO:Bayesian Ridge Imported successfully
2024-02-09 12:00:37,652:INFO:Starting cross validation
2024-02-09 12:00:37,653:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-09 12:00:38,133:INFO:Calculating mean and std
2024-02-09 12:00:38,135:INFO:Creating metrics dataframe
2024-02-09 12:00:38,162:INFO:Uploading results into container
2024-02-09 12:00:38,163:INFO:Uploading model into container now
2024-02-09 12:00:38,163:INFO:_master_model_container: 8
2024-02-09 12:00:38,164:INFO:_display_container: 2
2024-02-09 12:00:38,164:INFO:BayesianRidge(alpha_1=1e-06, alpha_2=1e-06, alpha_init=None,
              compute_score=False, copy_X=True, fit_intercept=True,
              lambda_1=1e-06, lambda_2=1e-06, lambda_init=None, n_iter=300,
              tol=0.001, verbose=False)
2024-02-09 12:00:38,164:INFO:create_model() successfully completed......................................
2024-02-09 12:00:38,314:INFO:SubProcess create_model() end ==================================
2024-02-09 12:00:38,314:INFO:Creating metrics dataframe
2024-02-09 12:00:38,327:INFO:Initializing Passive Aggressive Regressor
2024-02-09 12:00:38,328:INFO:Total runtime is 0.2738796631495158 minutes
2024-02-09 12:00:38,332:INFO:SubProcess create_model() called ==================================
2024-02-09 12:00:38,333:INFO:Initializing create_model()
2024-02-09 12:00:38,333:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fde8e643550>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fde8df040d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-09 12:00:38,333:INFO:Checking exceptions
2024-02-09 12:00:38,333:INFO:Importing libraries
2024-02-09 12:00:38,333:INFO:Copying training dataset
2024-02-09 12:00:38,351:INFO:Defining folds
2024-02-09 12:00:38,351:INFO:Declaring metric variables
2024-02-09 12:00:38,357:INFO:Importing untrained model
2024-02-09 12:00:38,362:INFO:Passive Aggressive Regressor Imported successfully
2024-02-09 12:00:38,374:INFO:Starting cross validation
2024-02-09 12:00:38,376:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-09 12:00:39,104:INFO:Calculating mean and std
2024-02-09 12:00:39,106:INFO:Creating metrics dataframe
2024-02-09 12:00:39,109:INFO:Uploading results into container
2024-02-09 12:00:39,110:INFO:Uploading model into container now
2024-02-09 12:00:39,110:INFO:_master_model_container: 9
2024-02-09 12:00:39,110:INFO:_display_container: 2
2024-02-09 12:00:39,111:INFO:PassiveAggressiveRegressor(C=1.0, average=False, early_stopping=False,
                           epsilon=0.1, fit_intercept=True,
                           loss='epsilon_insensitive', max_iter=1000,
                           n_iter_no_change=5, random_state=8730, shuffle=True,
                           tol=0.001, validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-02-09 12:00:39,111:INFO:create_model() successfully completed......................................
2024-02-09 12:00:39,264:INFO:SubProcess create_model() end ==================================
2024-02-09 12:00:39,265:INFO:Creating metrics dataframe
2024-02-09 12:00:39,288:INFO:Initializing Huber Regressor
2024-02-09 12:00:39,288:INFO:Total runtime is 0.28988786935806277 minutes
2024-02-09 12:00:39,295:INFO:SubProcess create_model() called ==================================
2024-02-09 12:00:39,295:INFO:Initializing create_model()
2024-02-09 12:00:39,296:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fde8e643550>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fde8df040d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-09 12:00:39,296:INFO:Checking exceptions
2024-02-09 12:00:39,296:INFO:Importing libraries
2024-02-09 12:00:39,296:INFO:Copying training dataset
2024-02-09 12:00:39,311:INFO:Defining folds
2024-02-09 12:00:39,311:INFO:Declaring metric variables
2024-02-09 12:00:39,318:INFO:Importing untrained model
2024-02-09 12:00:39,327:INFO:Huber Regressor Imported successfully
2024-02-09 12:00:39,340:INFO:Starting cross validation
2024-02-09 12:00:39,341:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-09 12:00:39,983:INFO:Calculating mean and std
2024-02-09 12:00:39,985:INFO:Creating metrics dataframe
2024-02-09 12:00:39,990:INFO:Uploading results into container
2024-02-09 12:00:39,991:INFO:Uploading model into container now
2024-02-09 12:00:39,992:INFO:_master_model_container: 10
2024-02-09 12:00:39,992:INFO:_display_container: 2
2024-02-09 12:00:39,992:INFO:HuberRegressor(alpha=0.0001, epsilon=1.35, fit_intercept=True, max_iter=100,
               tol=1e-05, warm_start=False)
2024-02-09 12:00:39,993:INFO:create_model() successfully completed......................................
2024-02-09 12:00:40,153:INFO:SubProcess create_model() end ==================================
2024-02-09 12:00:40,153:INFO:Creating metrics dataframe
2024-02-09 12:00:40,170:INFO:Initializing K Neighbors Regressor
2024-02-09 12:00:40,170:INFO:Total runtime is 0.304583481947581 minutes
2024-02-09 12:00:40,173:INFO:SubProcess create_model() called ==================================
2024-02-09 12:00:40,173:INFO:Initializing create_model()
2024-02-09 12:00:40,174:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fde8e643550>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fde8df040d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-09 12:00:40,174:INFO:Checking exceptions
2024-02-09 12:00:40,174:INFO:Importing libraries
2024-02-09 12:00:40,174:INFO:Copying training dataset
2024-02-09 12:00:40,188:INFO:Defining folds
2024-02-09 12:00:40,188:INFO:Declaring metric variables
2024-02-09 12:00:40,194:INFO:Importing untrained model
2024-02-09 12:00:40,203:INFO:K Neighbors Regressor Imported successfully
2024-02-09 12:00:40,215:INFO:Starting cross validation
2024-02-09 12:00:40,216:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-09 12:00:41,119:INFO:Calculating mean and std
2024-02-09 12:00:41,121:INFO:Creating metrics dataframe
2024-02-09 12:00:41,123:INFO:Uploading results into container
2024-02-09 12:00:41,124:INFO:Uploading model into container now
2024-02-09 12:00:41,124:INFO:_master_model_container: 11
2024-02-09 12:00:41,124:INFO:_display_container: 2
2024-02-09 12:00:41,124:INFO:KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',
                    metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                    weights='uniform')
2024-02-09 12:00:41,124:INFO:create_model() successfully completed......................................
2024-02-09 12:00:41,279:INFO:SubProcess create_model() end ==================================
2024-02-09 12:00:41,279:INFO:Creating metrics dataframe
2024-02-09 12:00:41,298:INFO:Initializing Decision Tree Regressor
2024-02-09 12:00:41,299:INFO:Total runtime is 0.3234013875325521 minutes
2024-02-09 12:00:41,306:INFO:SubProcess create_model() called ==================================
2024-02-09 12:00:41,307:INFO:Initializing create_model()
2024-02-09 12:00:41,307:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fde8e643550>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fde8df040d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-09 12:00:41,307:INFO:Checking exceptions
2024-02-09 12:00:41,307:INFO:Importing libraries
2024-02-09 12:00:41,307:INFO:Copying training dataset
2024-02-09 12:00:41,322:INFO:Defining folds
2024-02-09 12:00:41,322:INFO:Declaring metric variables
2024-02-09 12:00:41,327:INFO:Importing untrained model
2024-02-09 12:00:41,334:INFO:Decision Tree Regressor Imported successfully
2024-02-09 12:00:41,350:INFO:Starting cross validation
2024-02-09 12:00:41,352:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-09 12:00:42,765:INFO:Calculating mean and std
2024-02-09 12:00:42,767:INFO:Creating metrics dataframe
2024-02-09 12:00:42,771:INFO:Uploading results into container
2024-02-09 12:00:42,772:INFO:Uploading model into container now
2024-02-09 12:00:42,773:INFO:_master_model_container: 12
2024-02-09 12:00:42,773:INFO:_display_container: 2
2024-02-09 12:00:42,774:INFO:DecisionTreeRegressor(ccp_alpha=0.0, criterion='squared_error', max_depth=None,
                      max_features=None, max_leaf_nodes=None,
                      min_impurity_decrease=0.0, min_samples_leaf=1,
                      min_samples_split=2, min_weight_fraction_leaf=0.0,
                      random_state=8730, splitter='best')
2024-02-09 12:00:42,774:INFO:create_model() successfully completed......................................
2024-02-09 12:00:42,930:INFO:SubProcess create_model() end ==================================
2024-02-09 12:00:42,931:INFO:Creating metrics dataframe
2024-02-09 12:00:42,945:INFO:Initializing Random Forest Regressor
2024-02-09 12:00:42,946:INFO:Total runtime is 0.3508454243342082 minutes
2024-02-09 12:00:42,953:INFO:SubProcess create_model() called ==================================
2024-02-09 12:00:42,953:INFO:Initializing create_model()
2024-02-09 12:00:42,953:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fde8e643550>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fde8df040d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-09 12:00:42,953:INFO:Checking exceptions
2024-02-09 12:00:42,953:INFO:Importing libraries
2024-02-09 12:00:42,953:INFO:Copying training dataset
2024-02-09 12:00:42,967:INFO:Defining folds
2024-02-09 12:00:42,967:INFO:Declaring metric variables
2024-02-09 12:00:42,971:INFO:Importing untrained model
2024-02-09 12:00:42,978:INFO:Random Forest Regressor Imported successfully
2024-02-09 12:00:42,992:INFO:Starting cross validation
2024-02-09 12:00:42,994:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-09 12:01:45,410:INFO:Calculating mean and std
2024-02-09 12:01:45,411:INFO:Creating metrics dataframe
2024-02-09 12:01:45,417:INFO:Uploading results into container
2024-02-09 12:01:45,418:INFO:Uploading model into container now
2024-02-09 12:01:45,419:INFO:_master_model_container: 13
2024-02-09 12:01:45,419:INFO:_display_container: 2
2024-02-09 12:01:45,419:INFO:RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='squared_error',
                      max_depth=None, max_features=1.0, max_leaf_nodes=None,
                      max_samples=None, min_impurity_decrease=0.0,
                      min_samples_leaf=1, min_samples_split=2,
                      min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,
                      oob_score=False, random_state=8730, verbose=0,
                      warm_start=False)
2024-02-09 12:01:45,420:INFO:create_model() successfully completed......................................
2024-02-09 12:01:45,576:INFO:SubProcess create_model() end ==================================
2024-02-09 12:01:45,577:INFO:Creating metrics dataframe
2024-02-09 12:01:45,590:INFO:Initializing Extra Trees Regressor
2024-02-09 12:01:45,591:INFO:Total runtime is 1.394930398464203 minutes
2024-02-09 12:01:45,595:INFO:SubProcess create_model() called ==================================
2024-02-09 12:01:45,596:INFO:Initializing create_model()
2024-02-09 12:01:45,596:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fde8e643550>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fde8df040d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-09 12:01:45,596:INFO:Checking exceptions
2024-02-09 12:01:45,597:INFO:Importing libraries
2024-02-09 12:01:45,597:INFO:Copying training dataset
2024-02-09 12:01:45,610:INFO:Defining folds
2024-02-09 12:01:45,610:INFO:Declaring metric variables
2024-02-09 12:01:45,617:INFO:Importing untrained model
2024-02-09 12:01:45,623:INFO:Extra Trees Regressor Imported successfully
2024-02-09 12:01:45,637:INFO:Starting cross validation
2024-02-09 12:01:45,639:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-09 12:02:16,186:INFO:Calculating mean and std
2024-02-09 12:02:16,189:INFO:Creating metrics dataframe
2024-02-09 12:02:16,194:INFO:Uploading results into container
2024-02-09 12:02:16,195:INFO:Uploading model into container now
2024-02-09 12:02:16,197:INFO:_master_model_container: 14
2024-02-09 12:02:16,198:INFO:_display_container: 2
2024-02-09 12:02:16,199:INFO:ExtraTreesRegressor(bootstrap=False, ccp_alpha=0.0, criterion='squared_error',
                    max_depth=None, max_features=1.0, max_leaf_nodes=None,
                    max_samples=None, min_impurity_decrease=0.0,
                    min_samples_leaf=1, min_samples_split=2,
                    min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,
                    oob_score=False, random_state=8730, verbose=0,
                    warm_start=False)
2024-02-09 12:02:16,199:INFO:create_model() successfully completed......................................
2024-02-09 12:02:16,363:INFO:SubProcess create_model() end ==================================
2024-02-09 12:02:16,363:INFO:Creating metrics dataframe
2024-02-09 12:02:16,377:INFO:Initializing AdaBoost Regressor
2024-02-09 12:02:16,377:INFO:Total runtime is 1.9080379883448284 minutes
2024-02-09 12:02:16,381:INFO:SubProcess create_model() called ==================================
2024-02-09 12:02:16,381:INFO:Initializing create_model()
2024-02-09 12:02:16,382:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fde8e643550>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fde8df040d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-09 12:02:16,382:INFO:Checking exceptions
2024-02-09 12:02:16,382:INFO:Importing libraries
2024-02-09 12:02:16,382:INFO:Copying training dataset
2024-02-09 12:02:16,396:INFO:Defining folds
2024-02-09 12:02:16,397:INFO:Declaring metric variables
2024-02-09 12:02:16,404:INFO:Importing untrained model
2024-02-09 12:02:16,410:INFO:AdaBoost Regressor Imported successfully
2024-02-09 12:02:16,422:INFO:Starting cross validation
2024-02-09 12:02:16,424:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-09 12:02:24,718:INFO:Calculating mean and std
2024-02-09 12:02:24,720:INFO:Creating metrics dataframe
2024-02-09 12:02:24,723:INFO:Uploading results into container
2024-02-09 12:02:24,723:INFO:Uploading model into container now
2024-02-09 12:02:24,724:INFO:_master_model_container: 15
2024-02-09 12:02:24,724:INFO:_display_container: 2
2024-02-09 12:02:24,724:INFO:AdaBoostRegressor(base_estimator='deprecated', estimator=None,
                  learning_rate=1.0, loss='linear', n_estimators=50,
                  random_state=8730)
2024-02-09 12:02:24,724:INFO:create_model() successfully completed......................................
2024-02-09 12:02:24,879:INFO:SubProcess create_model() end ==================================
2024-02-09 12:02:24,880:INFO:Creating metrics dataframe
2024-02-09 12:02:24,897:INFO:Initializing Gradient Boosting Regressor
2024-02-09 12:02:24,898:INFO:Total runtime is 2.0500508666038515 minutes
2024-02-09 12:02:24,904:INFO:SubProcess create_model() called ==================================
2024-02-09 12:02:24,904:INFO:Initializing create_model()
2024-02-09 12:02:24,904:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fde8e643550>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fde8df040d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-09 12:02:24,904:INFO:Checking exceptions
2024-02-09 12:02:24,904:INFO:Importing libraries
2024-02-09 12:02:24,904:INFO:Copying training dataset
2024-02-09 12:02:24,920:INFO:Defining folds
2024-02-09 12:02:24,921:INFO:Declaring metric variables
2024-02-09 12:02:24,924:INFO:Importing untrained model
2024-02-09 12:02:24,933:INFO:Gradient Boosting Regressor Imported successfully
2024-02-09 12:02:24,944:INFO:Starting cross validation
2024-02-09 12:02:24,947:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-09 12:02:42,538:INFO:Calculating mean and std
2024-02-09 12:02:42,540:INFO:Creating metrics dataframe
2024-02-09 12:02:42,543:INFO:Uploading results into container
2024-02-09 12:02:42,544:INFO:Uploading model into container now
2024-02-09 12:02:42,545:INFO:_master_model_container: 16
2024-02-09 12:02:42,546:INFO:_display_container: 2
2024-02-09 12:02:42,548:INFO:GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',
                          init=None, learning_rate=0.1, loss='squared_error',
                          max_depth=3, max_features=None, max_leaf_nodes=None,
                          min_impurity_decrease=0.0, min_samples_leaf=1,
                          min_samples_split=2, min_weight_fraction_leaf=0.0,
                          n_estimators=100, n_iter_no_change=None,
                          random_state=8730, subsample=1.0, tol=0.0001,
                          validation_fraction=0.1, verbose=0, warm_start=False)
2024-02-09 12:02:42,548:INFO:create_model() successfully completed......................................
2024-02-09 12:02:42,707:INFO:SubProcess create_model() end ==================================
2024-02-09 12:02:42,707:INFO:Creating metrics dataframe
2024-02-09 12:02:42,732:INFO:Initializing Extreme Gradient Boosting
2024-02-09 12:02:42,733:INFO:Total runtime is 2.3472979267438254 minutes
2024-02-09 12:02:42,739:INFO:SubProcess create_model() called ==================================
2024-02-09 12:02:42,740:INFO:Initializing create_model()
2024-02-09 12:02:42,740:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fde8e643550>, estimator=xgboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fde8df040d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-09 12:02:42,740:INFO:Checking exceptions
2024-02-09 12:02:42,740:INFO:Importing libraries
2024-02-09 12:02:42,740:INFO:Copying training dataset
2024-02-09 12:02:42,756:INFO:Defining folds
2024-02-09 12:02:42,756:INFO:Declaring metric variables
2024-02-09 12:02:42,762:INFO:Importing untrained model
2024-02-09 12:02:42,771:INFO:Extreme Gradient Boosting Imported successfully
2024-02-09 12:02:42,778:INFO:Starting cross validation
2024-02-09 12:02:42,781:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-09 12:02:45,455:INFO:Calculating mean and std
2024-02-09 12:02:45,458:INFO:Creating metrics dataframe
2024-02-09 12:02:45,464:INFO:Uploading results into container
2024-02-09 12:02:45,465:INFO:Uploading model into container now
2024-02-09 12:02:45,465:INFO:_master_model_container: 17
2024-02-09 12:02:45,465:INFO:_display_container: 2
2024-02-09 12:02:45,467:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, objective='reg:squarederror', ...)
2024-02-09 12:02:45,470:INFO:create_model() successfully completed......................................
2024-02-09 12:02:45,624:INFO:SubProcess create_model() end ==================================
2024-02-09 12:02:45,624:INFO:Creating metrics dataframe
2024-02-09 12:02:45,640:INFO:Initializing Light Gradient Boosting Machine
2024-02-09 12:02:45,640:INFO:Total runtime is 2.3957520763079327 minutes
2024-02-09 12:02:45,643:INFO:SubProcess create_model() called ==================================
2024-02-09 12:02:45,644:INFO:Initializing create_model()
2024-02-09 12:02:45,644:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fde8e643550>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fde8df040d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-09 12:02:45,644:INFO:Checking exceptions
2024-02-09 12:02:45,644:INFO:Importing libraries
2024-02-09 12:02:45,644:INFO:Copying training dataset
2024-02-09 12:02:45,666:INFO:Defining folds
2024-02-09 12:02:45,666:INFO:Declaring metric variables
2024-02-09 12:02:45,673:INFO:Importing untrained model
2024-02-09 12:02:45,676:INFO:Light Gradient Boosting Machine Imported successfully
2024-02-09 12:02:45,690:INFO:Starting cross validation
2024-02-09 12:02:45,691:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-09 12:17:31,556:INFO:Calculating mean and std
2024-02-09 12:17:31,560:INFO:Creating metrics dataframe
2024-02-09 12:17:31,567:INFO:Uploading results into container
2024-02-09 12:17:31,568:INFO:Uploading model into container now
2024-02-09 12:17:31,569:INFO:_master_model_container: 18
2024-02-09 12:17:31,569:INFO:_display_container: 2
2024-02-09 12:17:31,570:INFO:LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
              importance_type='split', learning_rate=0.1, max_depth=-1,
              min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
              n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
              random_state=8730, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
              subsample_for_bin=200000, subsample_freq=0)
2024-02-09 12:17:31,570:INFO:create_model() successfully completed......................................
2024-02-09 12:17:31,740:INFO:SubProcess create_model() end ==================================
2024-02-09 12:17:31,740:INFO:Creating metrics dataframe
2024-02-09 12:17:31,757:INFO:Initializing Dummy Regressor
2024-02-09 12:17:31,757:INFO:Total runtime is 17.164366467793783 minutes
2024-02-09 12:17:31,761:INFO:SubProcess create_model() called ==================================
2024-02-09 12:17:31,761:INFO:Initializing create_model()
2024-02-09 12:17:31,762:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fde8e643550>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fde8df040d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-09 12:17:31,762:INFO:Checking exceptions
2024-02-09 12:17:31,762:INFO:Importing libraries
2024-02-09 12:17:31,762:INFO:Copying training dataset
2024-02-09 12:17:31,775:INFO:Defining folds
2024-02-09 12:17:31,775:INFO:Declaring metric variables
2024-02-09 12:17:31,784:INFO:Importing untrained model
2024-02-09 12:17:31,789:INFO:Dummy Regressor Imported successfully
2024-02-09 12:17:31,804:INFO:Starting cross validation
2024-02-09 12:17:31,806:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-09 12:17:32,193:INFO:Calculating mean and std
2024-02-09 12:17:32,201:INFO:Creating metrics dataframe
2024-02-09 12:17:32,219:INFO:Uploading results into container
2024-02-09 12:17:32,221:INFO:Uploading model into container now
2024-02-09 12:17:32,221:INFO:_master_model_container: 19
2024-02-09 12:17:32,222:INFO:_display_container: 2
2024-02-09 12:17:32,222:INFO:DummyRegressor(constant=None, quantile=None, strategy='mean')
2024-02-09 12:17:32,222:INFO:create_model() successfully completed......................................
2024-02-09 12:17:32,441:INFO:SubProcess create_model() end ==================================
2024-02-09 12:17:32,441:INFO:Creating metrics dataframe
2024-02-09 12:17:32,488:INFO:Initializing create_model()
2024-02-09 12:17:32,490:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fde8e643550>, estimator=LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
              importance_type='split', learning_rate=0.1, max_depth=-1,
              min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
              n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
              random_state=8730, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
              subsample_for_bin=200000, subsample_freq=0), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-09 12:17:32,490:INFO:Checking exceptions
2024-02-09 12:17:32,494:INFO:Importing libraries
2024-02-09 12:17:32,495:INFO:Copying training dataset
2024-02-09 12:17:32,520:INFO:Defining folds
2024-02-09 12:17:32,521:INFO:Declaring metric variables
2024-02-09 12:17:32,521:INFO:Importing untrained model
2024-02-09 12:17:32,521:INFO:Declaring custom model
2024-02-09 12:17:32,522:INFO:Light Gradient Boosting Machine Imported successfully
2024-02-09 12:17:32,523:INFO:Cross validation set to False
2024-02-09 12:17:32,524:INFO:Fitting Model
2024-02-09 12:17:32,631:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005380 seconds.
2024-02-09 12:17:32,631:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-02-09 12:17:32,631:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-02-09 12:17:32,632:INFO:[LightGBM] [Info] Total Bins 2628
2024-02-09 12:17:32,632:INFO:[LightGBM] [Info] Number of data points in the train set: 14000, number of used features: 22
2024-02-09 12:17:32,633:INFO:[LightGBM] [Info] Start training from score 539640.240357
2024-02-09 12:17:33,211:INFO:LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
              importance_type='split', learning_rate=0.1, max_depth=-1,
              min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
              n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
              random_state=8730, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
              subsample_for_bin=200000, subsample_freq=0)
2024-02-09 12:17:33,211:INFO:create_model() successfully completed......................................
2024-02-09 12:17:33,467:INFO:_master_model_container: 19
2024-02-09 12:17:33,467:INFO:_display_container: 2
2024-02-09 12:17:33,468:INFO:LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
              importance_type='split', learning_rate=0.1, max_depth=-1,
              min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
              n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
              random_state=8730, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
              subsample_for_bin=200000, subsample_freq=0)
2024-02-09 12:17:33,468:INFO:compare_models() successfully completed......................................
2024-02-09 12:20:01,942:INFO:Initializing evaluate_model()
2024-02-09 12:20:01,943:INFO:evaluate_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fde8e643550>, estimator=LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
              importance_type='split', learning_rate=0.1, max_depth=-1,
              min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
              n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
              random_state=8730, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
              subsample_for_bin=200000, subsample_freq=0), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2024-02-09 12:20:01,983:INFO:Initializing plot_model()
2024-02-09 12:20:01,984:INFO:plot_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fde8e643550>, estimator=LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
              importance_type='split', learning_rate=0.1, max_depth=-1,
              min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
              n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
              random_state=8730, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
              subsample_for_bin=200000, subsample_freq=0), plot=pipeline, scale=1, save=False, fold=KFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-02-09 12:20:01,984:INFO:Checking exceptions
2024-02-09 12:20:01,991:INFO:Preloading libraries
2024-02-09 12:20:02,025:INFO:Copying training dataset
2024-02-09 12:20:02,026:INFO:Plot type: pipeline
2024-02-09 12:20:02,283:INFO:Visual Rendered Successfully
2024-02-09 12:20:02,465:INFO:plot_model() successfully completed......................................
2024-02-09 12:20:09,592:INFO:Initializing plot_model()
2024-02-09 12:20:09,593:INFO:plot_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fde8e643550>, estimator=LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
              importance_type='split', learning_rate=0.1, max_depth=-1,
              min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
              n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
              random_state=8730, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
              subsample_for_bin=200000, subsample_freq=0), plot=parameter, scale=1, save=False, fold=KFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-02-09 12:20:09,593:INFO:Checking exceptions
2024-02-09 12:20:09,600:INFO:Preloading libraries
2024-02-09 12:20:09,637:INFO:Copying training dataset
2024-02-09 12:20:09,637:INFO:Plot type: parameter
2024-02-09 12:20:09,655:INFO:Visual Rendered Successfully
2024-02-09 12:20:09,848:INFO:plot_model() successfully completed......................................
2024-02-09 12:20:10,654:INFO:Initializing plot_model()
2024-02-09 12:20:10,654:INFO:plot_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fde8e643550>, estimator=LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
              importance_type='split', learning_rate=0.1, max_depth=-1,
              min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
              n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
              random_state=8730, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
              subsample_for_bin=200000, subsample_freq=0), plot=feature, scale=1, save=False, fold=KFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-02-09 12:20:10,655:INFO:Checking exceptions
2024-02-09 12:20:10,670:INFO:Preloading libraries
2024-02-09 12:20:10,714:INFO:Copying training dataset
2024-02-09 12:20:10,714:INFO:Plot type: feature
2024-02-09 12:20:10,727:WARNING:No coef_ found. Trying feature_importances_
2024-02-09 12:20:11,024:INFO:Visual Rendered Successfully
2024-02-09 12:20:11,202:INFO:plot_model() successfully completed......................................
2024-02-09 12:20:15,051:INFO:Initializing plot_model()
2024-02-09 12:20:15,052:INFO:plot_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fde8e643550>, estimator=LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
              importance_type='split', learning_rate=0.1, max_depth=-1,
              min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
              n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
              random_state=8730, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
              subsample_for_bin=200000, subsample_freq=0), plot=rfe, scale=1, save=False, fold=KFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-02-09 12:20:15,053:INFO:Checking exceptions
2024-02-09 12:20:15,068:INFO:Preloading libraries
2024-02-09 12:20:15,080:INFO:Copying training dataset
2024-02-09 12:20:15,080:INFO:Plot type: rfe
2024-02-09 12:20:15,246:INFO:Fitting Model
2024-02-09 12:20:15,281:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000554 seconds.
2024-02-09 12:20:15,282:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-02-09 12:20:15,282:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-02-09 12:20:15,282:INFO:[LightGBM] [Info] Total Bins 2616
2024-02-09 12:20:15,282:INFO:[LightGBM] [Info] Number of data points in the train set: 12600, number of used features: 22
2024-02-09 12:20:15,282:INFO:[LightGBM] [Info] Start training from score 541061.342778
2024-02-09 12:20:15,502:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000586 seconds.
2024-02-09 12:20:15,502:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-02-09 12:20:15,502:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-02-09 12:20:15,502:INFO:[LightGBM] [Info] Total Bins 2609
2024-02-09 12:20:15,503:INFO:[LightGBM] [Info] Number of data points in the train set: 12600, number of used features: 21
2024-02-09 12:20:15,503:INFO:[LightGBM] [Info] Start training from score 541061.342778
2024-02-09 12:20:15,757:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001159 seconds.
2024-02-09 12:20:15,757:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-09 12:20:15,758:INFO:[LightGBM] [Info] Total Bins 2606
2024-02-09 12:20:15,758:INFO:[LightGBM] [Info] Number of data points in the train set: 12600, number of used features: 20
2024-02-09 12:20:15,758:INFO:[LightGBM] [Info] Start training from score 541061.342778
2024-02-09 12:20:15,931:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001042 seconds.
2024-02-09 12:20:15,931:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-09 12:20:15,931:INFO:[LightGBM] [Info] Total Bins 2595
2024-02-09 12:20:15,932:INFO:[LightGBM] [Info] Number of data points in the train set: 12600, number of used features: 19
2024-02-09 12:20:15,932:INFO:[LightGBM] [Info] Start training from score 541061.342778
2024-02-09 12:20:16,154:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000605 seconds.
2024-02-09 12:20:16,154:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-02-09 12:20:16,154:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-02-09 12:20:16,155:INFO:[LightGBM] [Info] Total Bins 2593
2024-02-09 12:20:16,155:INFO:[LightGBM] [Info] Number of data points in the train set: 12600, number of used features: 18
2024-02-09 12:20:16,155:INFO:[LightGBM] [Info] Start training from score 541061.342778
2024-02-09 12:20:16,363:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000946 seconds.
2024-02-09 12:20:16,363:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-09 12:20:16,364:INFO:[LightGBM] [Info] Total Bins 2541
2024-02-09 12:20:16,364:INFO:[LightGBM] [Info] Number of data points in the train set: 12600, number of used features: 17
2024-02-09 12:20:16,364:INFO:[LightGBM] [Info] Start training from score 541061.342778
2024-02-09 12:20:16,584:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000606 seconds.
2024-02-09 12:20:16,584:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-02-09 12:20:16,585:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-02-09 12:20:16,585:INFO:[LightGBM] [Info] Total Bins 2509
2024-02-09 12:20:16,585:INFO:[LightGBM] [Info] Number of data points in the train set: 12600, number of used features: 16
2024-02-09 12:20:16,585:INFO:[LightGBM] [Info] Start training from score 541061.342778
2024-02-09 12:20:16,779:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000560 seconds.
2024-02-09 12:20:16,780:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-02-09 12:20:16,780:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-02-09 12:20:16,780:INFO:[LightGBM] [Info] Total Bins 2503
2024-02-09 12:20:16,780:INFO:[LightGBM] [Info] Number of data points in the train set: 12600, number of used features: 15
2024-02-09 12:20:16,780:INFO:[LightGBM] [Info] Start training from score 541061.342778
2024-02-09 12:20:17,006:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000409 seconds.
2024-02-09 12:20:17,006:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-02-09 12:20:17,006:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-02-09 12:20:17,006:INFO:[LightGBM] [Info] Total Bins 2490
2024-02-09 12:20:17,007:INFO:[LightGBM] [Info] Number of data points in the train set: 12600, number of used features: 14
2024-02-09 12:20:17,007:INFO:[LightGBM] [Info] Start training from score 541061.342778
2024-02-09 12:20:17,237:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000923 seconds.
2024-02-09 12:20:17,238:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-02-09 12:20:17,238:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-02-09 12:20:17,238:INFO:[LightGBM] [Info] Total Bins 2235
2024-02-09 12:20:17,240:INFO:[LightGBM] [Info] Number of data points in the train set: 12600, number of used features: 13
2024-02-09 12:20:17,240:INFO:[LightGBM] [Info] Start training from score 541061.342778
2024-02-09 12:20:17,440:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000418 seconds.
2024-02-09 12:20:17,440:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-02-09 12:20:17,440:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-02-09 12:20:17,440:INFO:[LightGBM] [Info] Total Bins 2209
2024-02-09 12:20:17,441:INFO:[LightGBM] [Info] Number of data points in the train set: 12600, number of used features: 12
2024-02-09 12:20:17,442:INFO:[LightGBM] [Info] Start training from score 541061.342778
2024-02-09 12:20:17,650:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000384 seconds.
2024-02-09 12:20:17,650:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-02-09 12:20:17,651:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-02-09 12:20:17,651:INFO:[LightGBM] [Info] Total Bins 2198
2024-02-09 12:20:17,651:INFO:[LightGBM] [Info] Number of data points in the train set: 12600, number of used features: 11
2024-02-09 12:20:17,651:INFO:[LightGBM] [Info] Start training from score 541061.342778
2024-02-09 12:20:17,805:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000617 seconds.
2024-02-09 12:20:17,805:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-09 12:20:17,806:INFO:[LightGBM] [Info] Total Bins 2193
2024-02-09 12:20:17,806:INFO:[LightGBM] [Info] Number of data points in the train set: 12600, number of used features: 10
2024-02-09 12:20:17,806:INFO:[LightGBM] [Info] Start training from score 541061.342778
2024-02-09 12:20:17,938:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000971 seconds.
2024-02-09 12:20:17,938:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-09 12:20:17,939:INFO:[LightGBM] [Info] Total Bins 1938
2024-02-09 12:20:17,939:INFO:[LightGBM] [Info] Number of data points in the train set: 12600, number of used features: 9
2024-02-09 12:20:17,939:INFO:[LightGBM] [Info] Start training from score 541061.342778
2024-02-09 12:20:18,058:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000541 seconds.
2024-02-09 12:20:18,059:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-09 12:20:18,059:INFO:[LightGBM] [Info] Total Bins 1867
2024-02-09 12:20:18,059:INFO:[LightGBM] [Info] Number of data points in the train set: 12600, number of used features: 8
2024-02-09 12:20:18,059:INFO:[LightGBM] [Info] Start training from score 541061.342778
2024-02-09 12:20:18,167:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001157 seconds.
2024-02-09 12:20:18,167:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-09 12:20:18,167:INFO:[LightGBM] [Info] Total Bins 1647
2024-02-09 12:20:18,167:INFO:[LightGBM] [Info] Number of data points in the train set: 12600, number of used features: 7
2024-02-09 12:20:18,167:INFO:[LightGBM] [Info] Start training from score 541061.342778
2024-02-09 12:20:18,266:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000352 seconds.
2024-02-09 12:20:18,266:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-09 12:20:18,266:INFO:[LightGBM] [Info] Total Bins 1392
2024-02-09 12:20:18,267:INFO:[LightGBM] [Info] Number of data points in the train set: 12600, number of used features: 6
2024-02-09 12:20:18,267:INFO:[LightGBM] [Info] Start training from score 541061.342778
2024-02-09 12:20:18,777:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000285 seconds.
2024-02-09 12:20:18,777:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-09 12:20:18,778:INFO:[LightGBM] [Info] Total Bins 1275
2024-02-09 12:20:18,778:INFO:[LightGBM] [Info] Number of data points in the train set: 12600, number of used features: 5
2024-02-09 12:20:18,778:INFO:[LightGBM] [Info] Start training from score 541061.342778
2024-02-09 12:20:18,914:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000246 seconds.
2024-02-09 12:20:18,914:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-09 12:20:18,914:INFO:[LightGBM] [Info] Total Bins 1020
2024-02-09 12:20:18,915:INFO:[LightGBM] [Info] Number of data points in the train set: 12600, number of used features: 4
2024-02-09 12:20:18,915:INFO:[LightGBM] [Info] Start training from score 541061.342778
2024-02-09 12:20:18,999:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000173 seconds.
2024-02-09 12:20:18,999:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-09 12:20:18,999:INFO:[LightGBM] [Info] Total Bins 765
2024-02-09 12:20:18,999:INFO:[LightGBM] [Info] Number of data points in the train set: 12600, number of used features: 3
2024-02-09 12:20:18,999:INFO:[LightGBM] [Info] Start training from score 541061.342778
2024-02-09 12:20:19,144:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000152 seconds.
2024-02-09 12:20:19,144:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-09 12:20:19,144:INFO:[LightGBM] [Info] Total Bins 510
2024-02-09 12:20:19,144:INFO:[LightGBM] [Info] Number of data points in the train set: 12600, number of used features: 2
2024-02-09 12:20:19,144:INFO:[LightGBM] [Info] Start training from score 541061.342778
2024-02-09 12:20:19,219:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000095 seconds.
2024-02-09 12:20:19,219:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-09 12:20:19,219:INFO:[LightGBM] [Info] Total Bins 255
2024-02-09 12:20:19,219:INFO:[LightGBM] [Info] Number of data points in the train set: 12600, number of used features: 1
2024-02-09 12:20:19,219:INFO:[LightGBM] [Info] Start training from score 541061.342778
2024-02-09 12:20:19,364:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002356 seconds.
2024-02-09 12:20:19,364:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-09 12:20:19,364:INFO:[LightGBM] [Info] Total Bins 2621
2024-02-09 12:20:19,364:INFO:[LightGBM] [Info] Number of data points in the train set: 12600, number of used features: 22
2024-02-09 12:20:19,365:INFO:[LightGBM] [Info] Start training from score 540193.995873
2024-02-09 12:20:19,597:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001347 seconds.
2024-02-09 12:20:19,597:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-09 12:20:19,597:INFO:[LightGBM] [Info] Total Bins 2614
2024-02-09 12:20:19,597:INFO:[LightGBM] [Info] Number of data points in the train set: 12600, number of used features: 21
2024-02-09 12:20:19,598:INFO:[LightGBM] [Info] Start training from score 540193.995873
2024-02-09 12:20:19,893:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001298 seconds.
2024-02-09 12:20:19,893:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-09 12:20:19,893:INFO:[LightGBM] [Info] Total Bins 2611
2024-02-09 12:20:19,893:INFO:[LightGBM] [Info] Number of data points in the train set: 12600, number of used features: 20
2024-02-09 12:20:19,894:INFO:[LightGBM] [Info] Start training from score 540193.995873
2024-02-09 12:20:20,157:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001204 seconds.
2024-02-09 12:20:20,158:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-09 12:20:20,158:INFO:[LightGBM] [Info] Total Bins 2559
2024-02-09 12:20:20,158:INFO:[LightGBM] [Info] Number of data points in the train set: 12600, number of used features: 19
2024-02-09 12:20:20,158:INFO:[LightGBM] [Info] Start training from score 540193.995873
2024-02-09 12:20:20,410:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001507 seconds.
2024-02-09 12:20:20,411:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-09 12:20:20,411:INFO:[LightGBM] [Info] Total Bins 2548
2024-02-09 12:20:20,411:INFO:[LightGBM] [Info] Number of data points in the train set: 12600, number of used features: 18
2024-02-09 12:20:20,412:INFO:[LightGBM] [Info] Start training from score 540193.995873
2024-02-09 12:20:20,572:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000451 seconds.
2024-02-09 12:20:20,573:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-02-09 12:20:20,573:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-02-09 12:20:20,573:INFO:[LightGBM] [Info] Total Bins 2546
2024-02-09 12:20:20,573:INFO:[LightGBM] [Info] Number of data points in the train set: 12600, number of used features: 17
2024-02-09 12:20:20,573:INFO:[LightGBM] [Info] Start training from score 540193.995873
2024-02-09 12:20:20,778:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000972 seconds.
2024-02-09 12:20:20,778:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-09 12:20:20,778:INFO:[LightGBM] [Info] Total Bins 2540
2024-02-09 12:20:20,778:INFO:[LightGBM] [Info] Number of data points in the train set: 12600, number of used features: 16
2024-02-09 12:20:20,779:INFO:[LightGBM] [Info] Start training from score 540193.995873
2024-02-09 12:20:20,945:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000431 seconds.
2024-02-09 12:20:20,945:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-02-09 12:20:20,945:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-02-09 12:20:20,945:INFO:[LightGBM] [Info] Total Bins 2508
2024-02-09 12:20:20,946:INFO:[LightGBM] [Info] Number of data points in the train set: 12600, number of used features: 15
2024-02-09 12:20:20,946:INFO:[LightGBM] [Info] Start training from score 540193.995873
2024-02-09 12:20:21,092:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000446 seconds.
2024-02-09 12:20:21,093:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-02-09 12:20:21,093:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-02-09 12:20:21,093:INFO:[LightGBM] [Info] Total Bins 2495
2024-02-09 12:20:21,093:INFO:[LightGBM] [Info] Number of data points in the train set: 12600, number of used features: 14
2024-02-09 12:20:21,093:INFO:[LightGBM] [Info] Start training from score 540193.995873
2024-02-09 12:20:21,294:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000882 seconds.
2024-02-09 12:20:21,294:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-09 12:20:21,294:INFO:[LightGBM] [Info] Total Bins 2240
2024-02-09 12:20:21,294:INFO:[LightGBM] [Info] Number of data points in the train set: 12600, number of used features: 13
2024-02-09 12:20:21,294:INFO:[LightGBM] [Info] Start training from score 540193.995873
2024-02-09 12:20:21,487:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000388 seconds.
2024-02-09 12:20:21,487:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-02-09 12:20:21,487:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-02-09 12:20:21,488:INFO:[LightGBM] [Info] Total Bins 2214
2024-02-09 12:20:21,488:INFO:[LightGBM] [Info] Number of data points in the train set: 12600, number of used features: 12
2024-02-09 12:20:21,488:INFO:[LightGBM] [Info] Start training from score 540193.995873
2024-02-09 12:20:21,635:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000377 seconds.
2024-02-09 12:20:21,636:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-02-09 12:20:21,636:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-02-09 12:20:21,636:INFO:[LightGBM] [Info] Total Bins 2203
2024-02-09 12:20:21,637:INFO:[LightGBM] [Info] Number of data points in the train set: 12600, number of used features: 11
2024-02-09 12:20:21,637:INFO:[LightGBM] [Info] Start training from score 540193.995873
2024-02-09 12:20:21,793:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000710 seconds.
2024-02-09 12:20:21,794:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-09 12:20:21,794:INFO:[LightGBM] [Info] Total Bins 2198
2024-02-09 12:20:21,794:INFO:[LightGBM] [Info] Number of data points in the train set: 12600, number of used features: 10
2024-02-09 12:20:21,794:INFO:[LightGBM] [Info] Start training from score 540193.995873
2024-02-09 12:20:21,921:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002092 seconds.
2024-02-09 12:20:21,921:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-09 12:20:21,922:INFO:[LightGBM] [Info] Total Bins 1943
2024-02-09 12:20:21,922:INFO:[LightGBM] [Info] Number of data points in the train set: 12600, number of used features: 9
2024-02-09 12:20:21,922:INFO:[LightGBM] [Info] Start training from score 540193.995873
2024-02-09 12:20:22,029:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000428 seconds.
2024-02-09 12:20:22,029:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-09 12:20:22,029:INFO:[LightGBM] [Info] Total Bins 1872
2024-02-09 12:20:22,029:INFO:[LightGBM] [Info] Number of data points in the train set: 12600, number of used features: 8
2024-02-09 12:20:22,030:INFO:[LightGBM] [Info] Start training from score 540193.995873
2024-02-09 12:20:22,229:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000398 seconds.
2024-02-09 12:20:22,230:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-09 12:20:22,230:INFO:[LightGBM] [Info] Total Bins 1755
2024-02-09 12:20:22,230:INFO:[LightGBM] [Info] Number of data points in the train set: 12600, number of used features: 7
2024-02-09 12:20:22,232:INFO:[LightGBM] [Info] Start training from score 540193.995873
2024-02-09 12:20:22,398:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000342 seconds.
2024-02-09 12:20:22,398:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-09 12:20:22,398:INFO:[LightGBM] [Info] Total Bins 1500
2024-02-09 12:20:22,400:INFO:[LightGBM] [Info] Number of data points in the train set: 12600, number of used features: 6
2024-02-09 12:20:22,402:INFO:[LightGBM] [Info] Start training from score 540193.995873
2024-02-09 12:20:22,578:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000297 seconds.
2024-02-09 12:20:22,578:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-09 12:20:22,578:INFO:[LightGBM] [Info] Total Bins 1275
2024-02-09 12:20:22,578:INFO:[LightGBM] [Info] Number of data points in the train set: 12600, number of used features: 5
2024-02-09 12:20:22,578:INFO:[LightGBM] [Info] Start training from score 540193.995873
2024-02-09 12:20:22,733:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001593 seconds.
2024-02-09 12:20:22,733:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-02-09 12:20:22,733:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-02-09 12:20:22,734:INFO:[LightGBM] [Info] Total Bins 1020
2024-02-09 12:20:22,734:INFO:[LightGBM] [Info] Number of data points in the train set: 12600, number of used features: 4
2024-02-09 12:20:22,734:INFO:[LightGBM] [Info] Start training from score 540193.995873
2024-02-09 12:20:22,855:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000171 seconds.
2024-02-09 12:20:22,856:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-09 12:20:22,856:INFO:[LightGBM] [Info] Total Bins 765
2024-02-09 12:20:22,856:INFO:[LightGBM] [Info] Number of data points in the train set: 12600, number of used features: 3
2024-02-09 12:20:22,856:INFO:[LightGBM] [Info] Start training from score 540193.995873
2024-02-09 12:20:22,955:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000166 seconds.
2024-02-09 12:20:22,955:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-09 12:20:22,955:INFO:[LightGBM] [Info] Total Bins 510
2024-02-09 12:20:22,955:INFO:[LightGBM] [Info] Number of data points in the train set: 12600, number of used features: 2
2024-02-09 12:20:22,955:INFO:[LightGBM] [Info] Start training from score 540193.995873
2024-02-09 12:20:23,024:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000086 seconds.
2024-02-09 12:20:23,024:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-09 12:20:23,024:INFO:[LightGBM] [Info] Total Bins 255
2024-02-09 12:20:23,024:INFO:[LightGBM] [Info] Number of data points in the train set: 12600, number of used features: 1
2024-02-09 12:20:23,024:INFO:[LightGBM] [Info] Start training from score 540193.995873
2024-02-09 12:20:23,115:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000615 seconds.
2024-02-09 12:20:23,115:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-02-09 12:20:23,116:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-02-09 12:20:23,116:INFO:[LightGBM] [Info] Total Bins 2624
2024-02-09 12:20:23,116:INFO:[LightGBM] [Info] Number of data points in the train set: 12600, number of used features: 22
2024-02-09 12:20:23,116:INFO:[LightGBM] [Info] Start training from score 537272.034286
2024-02-09 12:20:23,285:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000582 seconds.
2024-02-09 12:20:23,285:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-02-09 12:20:23,286:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-02-09 12:20:23,286:INFO:[LightGBM] [Info] Total Bins 2617
2024-02-09 12:20:23,286:INFO:[LightGBM] [Info] Number of data points in the train set: 12600, number of used features: 21
2024-02-09 12:20:23,286:INFO:[LightGBM] [Info] Start training from score 537272.034286
2024-02-09 12:20:23,455:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000921 seconds.
2024-02-09 12:20:23,455:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-02-09 12:20:23,455:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-02-09 12:20:23,456:INFO:[LightGBM] [Info] Total Bins 2614
2024-02-09 12:20:23,456:INFO:[LightGBM] [Info] Number of data points in the train set: 12600, number of used features: 20
2024-02-09 12:20:23,456:INFO:[LightGBM] [Info] Start training from score 537272.034286
2024-02-09 12:20:23,713:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001039 seconds.
2024-02-09 12:20:23,713:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-09 12:20:23,713:INFO:[LightGBM] [Info] Total Bins 2603
2024-02-09 12:20:23,714:INFO:[LightGBM] [Info] Number of data points in the train set: 12600, number of used features: 19
2024-02-09 12:20:23,715:INFO:[LightGBM] [Info] Start training from score 537272.034286
2024-02-09 12:20:24,054:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001019 seconds.
2024-02-09 12:20:24,054:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-09 12:20:24,054:INFO:[LightGBM] [Info] Total Bins 2550
2024-02-09 12:20:24,055:INFO:[LightGBM] [Info] Number of data points in the train set: 12600, number of used features: 18
2024-02-09 12:20:24,055:INFO:[LightGBM] [Info] Start training from score 537272.034286
2024-02-09 12:20:24,649:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000999 seconds.
2024-02-09 12:20:24,650:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-09 12:20:24,650:INFO:[LightGBM] [Info] Total Bins 2548
2024-02-09 12:20:24,650:INFO:[LightGBM] [Info] Number of data points in the train set: 12600, number of used features: 17
2024-02-09 12:20:24,650:INFO:[LightGBM] [Info] Start training from score 537272.034286
2024-02-09 12:20:24,837:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001011 seconds.
2024-02-09 12:20:24,837:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-09 12:20:24,838:INFO:[LightGBM] [Info] Total Bins 2542
2024-02-09 12:20:24,838:INFO:[LightGBM] [Info] Number of data points in the train set: 12600, number of used features: 16
2024-02-09 12:20:24,838:INFO:[LightGBM] [Info] Start training from score 537272.034286
2024-02-09 12:20:25,568:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000878 seconds.
2024-02-09 12:20:25,569:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-09 12:20:25,569:INFO:[LightGBM] [Info] Total Bins 2510
2024-02-09 12:20:25,569:INFO:[LightGBM] [Info] Number of data points in the train set: 12600, number of used features: 15
2024-02-09 12:20:25,569:INFO:[LightGBM] [Info] Start training from score 537272.034286
2024-02-09 12:20:25,796:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000837 seconds.
2024-02-09 12:20:25,797:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-09 12:20:25,797:INFO:[LightGBM] [Info] Total Bins 2497
2024-02-09 12:20:25,797:INFO:[LightGBM] [Info] Number of data points in the train set: 12600, number of used features: 14
2024-02-09 12:20:25,797:INFO:[LightGBM] [Info] Start training from score 537272.034286
2024-02-09 12:20:25,983:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000405 seconds.
2024-02-09 12:20:25,984:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-02-09 12:20:25,984:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-02-09 12:20:25,984:INFO:[LightGBM] [Info] Total Bins 2471
2024-02-09 12:20:25,984:INFO:[LightGBM] [Info] Number of data points in the train set: 12600, number of used features: 13
2024-02-09 12:20:25,984:INFO:[LightGBM] [Info] Start training from score 537272.034286
2024-02-09 12:20:26,120:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000674 seconds.
2024-02-09 12:20:26,120:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-09 12:20:26,120:INFO:[LightGBM] [Info] Total Bins 2460
2024-02-09 12:20:26,120:INFO:[LightGBM] [Info] Number of data points in the train set: 12600, number of used features: 12
2024-02-09 12:20:26,120:INFO:[LightGBM] [Info] Start training from score 537272.034286
2024-02-09 12:20:26,260:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000606 seconds.
2024-02-09 12:20:26,260:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-09 12:20:26,260:INFO:[LightGBM] [Info] Total Bins 2455
2024-02-09 12:20:26,260:INFO:[LightGBM] [Info] Number of data points in the train set: 12600, number of used features: 11
2024-02-09 12:20:26,260:INFO:[LightGBM] [Info] Start training from score 537272.034286
2024-02-09 12:20:26,508:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000751 seconds.
2024-02-09 12:20:26,508:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-09 12:20:26,509:INFO:[LightGBM] [Info] Total Bins 2200
2024-02-09 12:20:26,509:INFO:[LightGBM] [Info] Number of data points in the train set: 12600, number of used features: 10
2024-02-09 12:20:26,509:INFO:[LightGBM] [Info] Start training from score 537272.034286
2024-02-09 12:20:26,754:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000868 seconds.
2024-02-09 12:20:26,755:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-09 12:20:26,755:INFO:[LightGBM] [Info] Total Bins 1945
2024-02-09 12:20:26,755:INFO:[LightGBM] [Info] Number of data points in the train set: 12600, number of used features: 9
2024-02-09 12:20:26,755:INFO:[LightGBM] [Info] Start training from score 537272.034286
2024-02-09 12:20:26,904:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000461 seconds.
2024-02-09 12:20:26,905:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-09 12:20:26,905:INFO:[LightGBM] [Info] Total Bins 1874
2024-02-09 12:20:26,905:INFO:[LightGBM] [Info] Number of data points in the train set: 12600, number of used features: 8
2024-02-09 12:20:26,905:INFO:[LightGBM] [Info] Start training from score 537272.034286
2024-02-09 12:20:27,036:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000429 seconds.
2024-02-09 12:20:27,037:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-09 12:20:27,037:INFO:[LightGBM] [Info] Total Bins 1647
2024-02-09 12:20:27,037:INFO:[LightGBM] [Info] Number of data points in the train set: 12600, number of used features: 7
2024-02-09 12:20:27,037:INFO:[LightGBM] [Info] Start training from score 537272.034286
2024-02-09 12:20:27,221:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000383 seconds.
2024-02-09 12:20:27,221:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-09 12:20:27,222:INFO:[LightGBM] [Info] Total Bins 1392
2024-02-09 12:20:27,222:INFO:[LightGBM] [Info] Number of data points in the train set: 12600, number of used features: 6
2024-02-09 12:20:27,222:INFO:[LightGBM] [Info] Start training from score 537272.034286
2024-02-09 12:20:27,367:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008093 seconds.
2024-02-09 12:20:27,368:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-09 12:20:27,368:INFO:[LightGBM] [Info] Total Bins 1275
2024-02-09 12:20:27,368:INFO:[LightGBM] [Info] Number of data points in the train set: 12600, number of used features: 5
2024-02-09 12:20:27,369:INFO:[LightGBM] [Info] Start training from score 537272.034286
2024-02-09 12:20:27,545:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000266 seconds.
2024-02-09 12:20:27,545:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-09 12:20:27,545:INFO:[LightGBM] [Info] Total Bins 1020
2024-02-09 12:20:27,546:INFO:[LightGBM] [Info] Number of data points in the train set: 12600, number of used features: 4
2024-02-09 12:20:27,546:INFO:[LightGBM] [Info] Start training from score 537272.034286
2024-02-09 12:20:27,696:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000289 seconds.
2024-02-09 12:20:27,696:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-09 12:20:27,697:INFO:[LightGBM] [Info] Total Bins 765
2024-02-09 12:20:27,698:INFO:[LightGBM] [Info] Number of data points in the train set: 12600, number of used features: 3
2024-02-09 12:20:27,698:INFO:[LightGBM] [Info] Start training from score 537272.034286
2024-02-09 12:20:27,839:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000159 seconds.
2024-02-09 12:20:27,840:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-09 12:20:27,840:INFO:[LightGBM] [Info] Total Bins 510
2024-02-09 12:20:27,840:INFO:[LightGBM] [Info] Number of data points in the train set: 12600, number of used features: 2
2024-02-09 12:20:27,840:INFO:[LightGBM] [Info] Start training from score 537272.034286
2024-02-09 12:20:27,916:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000086 seconds.
2024-02-09 12:20:27,916:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-09 12:20:27,917:INFO:[LightGBM] [Info] Total Bins 255
2024-02-09 12:20:27,917:INFO:[LightGBM] [Info] Number of data points in the train set: 12600, number of used features: 1
2024-02-09 12:20:27,917:INFO:[LightGBM] [Info] Start training from score 537272.034286
2024-02-09 12:20:28,015:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000568 seconds.
2024-02-09 12:20:28,016:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-02-09 12:20:28,016:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-02-09 12:20:28,016:INFO:[LightGBM] [Info] Total Bins 2622
2024-02-09 12:20:28,016:INFO:[LightGBM] [Info] Number of data points in the train set: 12600, number of used features: 22
2024-02-09 12:20:28,017:INFO:[LightGBM] [Info] Start training from score 539583.932778
2024-02-09 12:20:28,836:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000994 seconds.
2024-02-09 12:20:28,836:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-02-09 12:20:28,836:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-02-09 12:20:28,836:INFO:[LightGBM] [Info] Total Bins 2615
2024-02-09 12:20:28,837:INFO:[LightGBM] [Info] Number of data points in the train set: 12600, number of used features: 21
2024-02-09 12:20:28,837:INFO:[LightGBM] [Info] Start training from score 539583.932778
2024-02-09 12:20:29,076:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001111 seconds.
2024-02-09 12:20:29,077:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-09 12:20:29,077:INFO:[LightGBM] [Info] Total Bins 2612
2024-02-09 12:20:29,077:INFO:[LightGBM] [Info] Number of data points in the train set: 12600, number of used features: 20
2024-02-09 12:20:29,077:INFO:[LightGBM] [Info] Start training from score 539583.932778
2024-02-09 12:20:29,279:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001185 seconds.
2024-02-09 12:20:29,280:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-09 12:20:29,280:INFO:[LightGBM] [Info] Total Bins 2602
2024-02-09 12:20:29,280:INFO:[LightGBM] [Info] Number of data points in the train set: 12600, number of used features: 19
2024-02-09 12:20:29,280:INFO:[LightGBM] [Info] Start training from score 539583.932778
2024-02-09 12:20:29,470:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001106 seconds.
2024-02-09 12:20:29,470:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-09 12:20:29,470:INFO:[LightGBM] [Info] Total Bins 2600
2024-02-09 12:20:29,470:INFO:[LightGBM] [Info] Number of data points in the train set: 12600, number of used features: 18
2024-02-09 12:20:29,470:INFO:[LightGBM] [Info] Start training from score 539583.932778
2024-02-09 12:20:29,767:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000961 seconds.
2024-02-09 12:20:29,768:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-09 12:20:29,768:INFO:[LightGBM] [Info] Total Bins 2547
2024-02-09 12:20:29,768:INFO:[LightGBM] [Info] Number of data points in the train set: 12600, number of used features: 17
2024-02-09 12:20:29,768:INFO:[LightGBM] [Info] Start training from score 539583.932778
2024-02-09 12:20:29,943:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000935 seconds.
2024-02-09 12:20:29,943:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-09 12:20:29,944:INFO:[LightGBM] [Info] Total Bins 2541
2024-02-09 12:20:29,944:INFO:[LightGBM] [Info] Number of data points in the train set: 12600, number of used features: 16
2024-02-09 12:20:29,944:INFO:[LightGBM] [Info] Start training from score 539583.932778
2024-02-09 12:20:30,152:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000425 seconds.
2024-02-09 12:20:30,153:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-02-09 12:20:30,153:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-02-09 12:20:30,153:INFO:[LightGBM] [Info] Total Bins 2509
2024-02-09 12:20:30,153:INFO:[LightGBM] [Info] Number of data points in the train set: 12600, number of used features: 15
2024-02-09 12:20:30,153:INFO:[LightGBM] [Info] Start training from score 539583.932778
2024-02-09 12:20:30,340:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005211 seconds.
2024-02-09 12:20:30,340:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-02-09 12:20:30,341:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-02-09 12:20:30,341:INFO:[LightGBM] [Info] Total Bins 2496
2024-02-09 12:20:30,341:INFO:[LightGBM] [Info] Number of data points in the train set: 12600, number of used features: 14
2024-02-09 12:20:30,341:INFO:[LightGBM] [Info] Start training from score 539583.932778
2024-02-09 12:20:30,542:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001039 seconds.
2024-02-09 12:20:30,542:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-09 12:20:30,542:INFO:[LightGBM] [Info] Total Bins 2485
2024-02-09 12:20:30,542:INFO:[LightGBM] [Info] Number of data points in the train set: 12600, number of used features: 13
2024-02-09 12:20:30,543:INFO:[LightGBM] [Info] Start training from score 539583.932778
2024-02-09 12:20:30,770:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000670 seconds.
2024-02-09 12:20:30,771:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-09 12:20:30,771:INFO:[LightGBM] [Info] Total Bins 2458
2024-02-09 12:20:30,771:INFO:[LightGBM] [Info] Number of data points in the train set: 12600, number of used features: 12
2024-02-09 12:20:30,771:INFO:[LightGBM] [Info] Start training from score 539583.932778
2024-02-09 12:20:30,943:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001192 seconds.
2024-02-09 12:20:30,943:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-09 12:20:30,943:INFO:[LightGBM] [Info] Total Bins 2453
2024-02-09 12:20:30,944:INFO:[LightGBM] [Info] Number of data points in the train set: 12600, number of used features: 11
2024-02-09 12:20:30,944:INFO:[LightGBM] [Info] Start training from score 539583.932778
2024-02-09 12:20:31,100:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003660 seconds.
2024-02-09 12:20:31,100:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-09 12:20:31,100:INFO:[LightGBM] [Info] Total Bins 2198
2024-02-09 12:20:31,100:INFO:[LightGBM] [Info] Number of data points in the train set: 12600, number of used features: 10
2024-02-09 12:20:31,100:INFO:[LightGBM] [Info] Start training from score 539583.932778
2024-02-09 12:20:31,282:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000635 seconds.
2024-02-09 12:20:31,283:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-09 12:20:31,283:INFO:[LightGBM] [Info] Total Bins 1943
2024-02-09 12:20:31,283:INFO:[LightGBM] [Info] Number of data points in the train set: 12600, number of used features: 9
2024-02-09 12:20:31,283:INFO:[LightGBM] [Info] Start training from score 539583.932778
2024-02-09 12:20:31,434:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000511 seconds.
2024-02-09 12:20:31,434:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-09 12:20:31,434:INFO:[LightGBM] [Info] Total Bins 1872
2024-02-09 12:20:31,434:INFO:[LightGBM] [Info] Number of data points in the train set: 12600, number of used features: 8
2024-02-09 12:20:31,434:INFO:[LightGBM] [Info] Start training from score 539583.932778
2024-02-09 12:20:31,546:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000413 seconds.
2024-02-09 12:20:31,547:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-09 12:20:31,547:INFO:[LightGBM] [Info] Total Bins 1617
2024-02-09 12:20:31,547:INFO:[LightGBM] [Info] Number of data points in the train set: 12600, number of used features: 7
2024-02-09 12:20:31,547:INFO:[LightGBM] [Info] Start training from score 539583.932778
2024-02-09 12:20:31,784:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001577 seconds.
2024-02-09 12:20:31,785:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-09 12:20:31,785:INFO:[LightGBM] [Info] Total Bins 1500
2024-02-09 12:20:31,786:INFO:[LightGBM] [Info] Number of data points in the train set: 12600, number of used features: 6
2024-02-09 12:20:31,787:INFO:[LightGBM] [Info] Start training from score 539583.932778
2024-02-09 12:20:32,092:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000121 seconds.
2024-02-09 12:20:32,092:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-02-09 12:20:32,092:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-02-09 12:20:32,092:INFO:[LightGBM] [Info] Total Bins 1275
2024-02-09 12:20:32,092:INFO:[LightGBM] [Info] Number of data points in the train set: 12600, number of used features: 5
2024-02-09 12:20:32,095:INFO:[LightGBM] [Info] Start training from score 539583.932778
2024-02-09 12:20:32,238:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000222 seconds.
2024-02-09 12:20:32,238:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-09 12:20:32,238:INFO:[LightGBM] [Info] Total Bins 1020
2024-02-09 12:20:32,238:INFO:[LightGBM] [Info] Number of data points in the train set: 12600, number of used features: 4
2024-02-09 12:20:32,238:INFO:[LightGBM] [Info] Start training from score 539583.932778
2024-02-09 12:20:32,350:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000083 seconds.
2024-02-09 12:20:32,350:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-02-09 12:20:32,350:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-02-09 12:20:32,350:INFO:[LightGBM] [Info] Total Bins 765
2024-02-09 12:20:32,350:INFO:[LightGBM] [Info] Number of data points in the train set: 12600, number of used features: 3
2024-02-09 12:20:32,350:INFO:[LightGBM] [Info] Start training from score 539583.932778
2024-02-09 12:20:32,504:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000163 seconds.
2024-02-09 12:20:32,505:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-09 12:20:32,505:INFO:[LightGBM] [Info] Total Bins 510
2024-02-09 12:20:32,506:INFO:[LightGBM] [Info] Number of data points in the train set: 12600, number of used features: 2
2024-02-09 12:20:32,506:INFO:[LightGBM] [Info] Start training from score 539583.932778
2024-02-09 12:20:32,914:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.084374 seconds.
2024-02-09 12:20:32,914:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-09 12:20:32,915:INFO:[LightGBM] [Info] Total Bins 255
2024-02-09 12:20:32,923:INFO:[LightGBM] [Info] Number of data points in the train set: 12600, number of used features: 1
2024-02-09 12:20:32,923:INFO:[LightGBM] [Info] Start training from score 539583.932778
2024-02-09 12:20:33,067:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000616 seconds.
2024-02-09 12:20:33,067:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-02-09 12:20:33,067:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-02-09 12:20:33,067:INFO:[LightGBM] [Info] Total Bins 2617
2024-02-09 12:20:33,068:INFO:[LightGBM] [Info] Number of data points in the train set: 12600, number of used features: 22
2024-02-09 12:20:33,068:INFO:[LightGBM] [Info] Start training from score 538263.584683
2024-02-09 12:20:33,440:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000699 seconds.
2024-02-09 12:20:33,440:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-02-09 12:20:33,440:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-02-09 12:20:33,441:INFO:[LightGBM] [Info] Total Bins 2610
2024-02-09 12:20:33,441:INFO:[LightGBM] [Info] Number of data points in the train set: 12600, number of used features: 21
2024-02-09 12:20:33,441:INFO:[LightGBM] [Info] Start training from score 538263.584683
2024-02-09 12:20:33,674:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000744 seconds.
2024-02-09 12:20:33,674:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-02-09 12:20:33,674:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-02-09 12:20:33,675:INFO:[LightGBM] [Info] Total Bins 2607
2024-02-09 12:20:33,675:INFO:[LightGBM] [Info] Number of data points in the train set: 12600, number of used features: 20
2024-02-09 12:20:33,675:INFO:[LightGBM] [Info] Start training from score 538263.584683
2024-02-09 12:20:33,873:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001037 seconds.
2024-02-09 12:20:33,874:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-09 12:20:33,874:INFO:[LightGBM] [Info] Total Bins 2596
2024-02-09 12:20:33,874:INFO:[LightGBM] [Info] Number of data points in the train set: 12600, number of used features: 19
2024-02-09 12:20:33,875:INFO:[LightGBM] [Info] Start training from score 538263.584683
2024-02-09 12:20:34,063:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001019 seconds.
2024-02-09 12:20:34,063:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-09 12:20:34,064:INFO:[LightGBM] [Info] Total Bins 2594
2024-02-09 12:20:34,064:INFO:[LightGBM] [Info] Number of data points in the train set: 12600, number of used features: 18
2024-02-09 12:20:34,064:INFO:[LightGBM] [Info] Start training from score 538263.584683
2024-02-09 12:20:35,745:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002509 seconds.
2024-02-09 12:20:35,746:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-02-09 12:20:35,746:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-02-09 12:20:35,746:INFO:[LightGBM] [Info] Total Bins 2543
2024-02-09 12:20:35,747:INFO:[LightGBM] [Info] Number of data points in the train set: 12600, number of used features: 17
2024-02-09 12:20:35,747:INFO:[LightGBM] [Info] Start training from score 538263.584683
2024-02-09 12:20:35,922:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000893 seconds.
2024-02-09 12:20:35,922:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-09 12:20:35,922:INFO:[LightGBM] [Info] Total Bins 2537
2024-02-09 12:20:35,922:INFO:[LightGBM] [Info] Number of data points in the train set: 12600, number of used features: 16
2024-02-09 12:20:35,923:INFO:[LightGBM] [Info] Start training from score 538263.584683
2024-02-09 12:20:36,072:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000426 seconds.
2024-02-09 12:20:36,072:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-02-09 12:20:36,072:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-02-09 12:20:36,072:INFO:[LightGBM] [Info] Total Bins 2505
2024-02-09 12:20:36,073:INFO:[LightGBM] [Info] Number of data points in the train set: 12600, number of used features: 15
2024-02-09 12:20:36,073:INFO:[LightGBM] [Info] Start training from score 538263.584683
2024-02-09 12:20:36,542:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000827 seconds.
2024-02-09 12:20:36,542:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-09 12:20:36,542:INFO:[LightGBM] [Info] Total Bins 2492
2024-02-09 12:20:36,542:INFO:[LightGBM] [Info] Number of data points in the train set: 12600, number of used features: 14
2024-02-09 12:20:36,542:INFO:[LightGBM] [Info] Start training from score 538263.584683
2024-02-09 12:20:37,098:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000504 seconds.
2024-02-09 12:20:37,099:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-02-09 12:20:37,099:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-02-09 12:20:37,099:INFO:[LightGBM] [Info] Total Bins 2466
2024-02-09 12:20:37,099:INFO:[LightGBM] [Info] Number of data points in the train set: 12600, number of used features: 13
2024-02-09 12:20:37,100:INFO:[LightGBM] [Info] Start training from score 538263.584683
2024-02-09 12:20:37,388:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000815 seconds.
2024-02-09 12:20:37,388:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-02-09 12:20:37,388:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-02-09 12:20:37,388:INFO:[LightGBM] [Info] Total Bins 2211
2024-02-09 12:20:37,388:INFO:[LightGBM] [Info] Number of data points in the train set: 12600, number of used features: 12
2024-02-09 12:20:37,388:INFO:[LightGBM] [Info] Start training from score 538263.584683
2024-02-09 12:20:37,577:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000671 seconds.
2024-02-09 12:20:37,577:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-09 12:20:37,577:INFO:[LightGBM] [Info] Total Bins 2200
2024-02-09 12:20:37,577:INFO:[LightGBM] [Info] Number of data points in the train set: 12600, number of used features: 11
2024-02-09 12:20:37,578:INFO:[LightGBM] [Info] Start training from score 538263.584683
2024-02-09 12:20:37,749:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000659 seconds.
2024-02-09 12:20:37,749:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-09 12:20:37,749:INFO:[LightGBM] [Info] Total Bins 2195
2024-02-09 12:20:37,749:INFO:[LightGBM] [Info] Number of data points in the train set: 12600, number of used features: 10
2024-02-09 12:20:37,750:INFO:[LightGBM] [Info] Start training from score 538263.584683
2024-02-09 12:20:38,058:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000610 seconds.
2024-02-09 12:20:38,058:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-09 12:20:38,058:INFO:[LightGBM] [Info] Total Bins 1940
2024-02-09 12:20:38,058:INFO:[LightGBM] [Info] Number of data points in the train set: 12600, number of used features: 9
2024-02-09 12:20:38,058:INFO:[LightGBM] [Info] Start training from score 538263.584683
2024-02-09 12:20:38,256:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000469 seconds.
2024-02-09 12:20:38,256:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-09 12:20:38,256:INFO:[LightGBM] [Info] Total Bins 1869
2024-02-09 12:20:38,256:INFO:[LightGBM] [Info] Number of data points in the train set: 12600, number of used features: 8
2024-02-09 12:20:38,257:INFO:[LightGBM] [Info] Start training from score 538263.584683
2024-02-09 12:20:38,406:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000440 seconds.
2024-02-09 12:20:38,406:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-09 12:20:38,406:INFO:[LightGBM] [Info] Total Bins 1614
2024-02-09 12:20:38,406:INFO:[LightGBM] [Info] Number of data points in the train set: 12600, number of used features: 7
2024-02-09 12:20:38,419:INFO:[LightGBM] [Info] Start training from score 538263.584683
2024-02-09 12:20:38,559:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000558 seconds.
2024-02-09 12:20:38,559:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-09 12:20:38,559:INFO:[LightGBM] [Info] Total Bins 1497
2024-02-09 12:20:38,559:INFO:[LightGBM] [Info] Number of data points in the train set: 12600, number of used features: 6
2024-02-09 12:20:38,560:INFO:[LightGBM] [Info] Start training from score 538263.584683
2024-02-09 12:20:38,782:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000294 seconds.
2024-02-09 12:20:38,782:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-09 12:20:38,782:INFO:[LightGBM] [Info] Total Bins 1275
2024-02-09 12:20:38,782:INFO:[LightGBM] [Info] Number of data points in the train set: 12600, number of used features: 5
2024-02-09 12:20:38,783:INFO:[LightGBM] [Info] Start training from score 538263.584683
2024-02-09 12:20:38,895:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000241 seconds.
2024-02-09 12:20:38,895:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-09 12:20:38,895:INFO:[LightGBM] [Info] Total Bins 1020
2024-02-09 12:20:38,895:INFO:[LightGBM] [Info] Number of data points in the train set: 12600, number of used features: 4
2024-02-09 12:20:38,896:INFO:[LightGBM] [Info] Start training from score 538263.584683
2024-02-09 12:20:39,004:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000288 seconds.
2024-02-09 12:20:39,004:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-09 12:20:39,004:INFO:[LightGBM] [Info] Total Bins 765
2024-02-09 12:20:39,004:INFO:[LightGBM] [Info] Number of data points in the train set: 12600, number of used features: 3
2024-02-09 12:20:39,004:INFO:[LightGBM] [Info] Start training from score 538263.584683
2024-02-09 12:20:39,083:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000143 seconds.
2024-02-09 12:20:39,083:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-09 12:20:39,083:INFO:[LightGBM] [Info] Total Bins 510
2024-02-09 12:20:39,083:INFO:[LightGBM] [Info] Number of data points in the train set: 12600, number of used features: 2
2024-02-09 12:20:39,084:INFO:[LightGBM] [Info] Start training from score 538263.584683
2024-02-09 12:20:39,150:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000105 seconds.
2024-02-09 12:20:39,150:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-09 12:20:39,150:INFO:[LightGBM] [Info] Total Bins 255
2024-02-09 12:20:39,150:INFO:[LightGBM] [Info] Number of data points in the train set: 12600, number of used features: 1
2024-02-09 12:20:39,150:INFO:[LightGBM] [Info] Start training from score 538263.584683
2024-02-09 12:20:39,255:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000647 seconds.
2024-02-09 12:20:39,255:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-02-09 12:20:39,255:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-02-09 12:20:39,256:INFO:[LightGBM] [Info] Total Bins 2617
2024-02-09 12:20:39,256:INFO:[LightGBM] [Info] Number of data points in the train set: 12600, number of used features: 22
2024-02-09 12:20:39,256:INFO:[LightGBM] [Info] Start training from score 541574.085317
2024-02-09 12:20:39,587:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.036835 seconds.
2024-02-09 12:20:39,587:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-02-09 12:20:39,587:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-02-09 12:20:39,588:INFO:[LightGBM] [Info] Total Bins 2610
2024-02-09 12:20:39,588:INFO:[LightGBM] [Info] Number of data points in the train set: 12600, number of used features: 21
2024-02-09 12:20:39,588:INFO:[LightGBM] [Info] Start training from score 541574.085317
2024-02-09 12:20:40,733:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001231 seconds.
2024-02-09 12:20:40,733:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-09 12:20:40,734:INFO:[LightGBM] [Info] Total Bins 2607
2024-02-09 12:20:40,747:INFO:[LightGBM] [Info] Number of data points in the train set: 12600, number of used features: 20
2024-02-09 12:20:40,748:INFO:[LightGBM] [Info] Start training from score 541574.085317
2024-02-09 12:20:41,018:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000967 seconds.
2024-02-09 12:20:41,018:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-02-09 12:20:41,018:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-02-09 12:20:41,018:INFO:[LightGBM] [Info] Total Bins 2596
2024-02-09 12:20:41,018:INFO:[LightGBM] [Info] Number of data points in the train set: 12600, number of used features: 19
2024-02-09 12:20:41,018:INFO:[LightGBM] [Info] Start training from score 541574.085317
2024-02-09 12:20:41,284:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001170 seconds.
2024-02-09 12:20:41,285:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-09 12:20:41,285:INFO:[LightGBM] [Info] Total Bins 2544
2024-02-09 12:20:41,285:INFO:[LightGBM] [Info] Number of data points in the train set: 12600, number of used features: 18
2024-02-09 12:20:41,285:INFO:[LightGBM] [Info] Start training from score 541574.085317
2024-02-09 12:20:41,585:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001066 seconds.
2024-02-09 12:20:41,585:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-09 12:20:41,585:INFO:[LightGBM] [Info] Total Bins 2512
2024-02-09 12:20:41,585:INFO:[LightGBM] [Info] Number of data points in the train set: 12600, number of used features: 17
2024-02-09 12:20:41,586:INFO:[LightGBM] [Info] Start training from score 541574.085317
2024-02-09 12:20:41,898:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000465 seconds.
2024-02-09 12:20:41,898:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-02-09 12:20:41,898:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-02-09 12:20:41,898:INFO:[LightGBM] [Info] Total Bins 2510
2024-02-09 12:20:41,899:INFO:[LightGBM] [Info] Number of data points in the train set: 12600, number of used features: 16
2024-02-09 12:20:41,899:INFO:[LightGBM] [Info] Start training from score 541574.085317
2024-02-09 12:20:42,065:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000414 seconds.
2024-02-09 12:20:42,065:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-02-09 12:20:42,065:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-02-09 12:20:42,066:INFO:[LightGBM] [Info] Total Bins 2504
2024-02-09 12:20:42,066:INFO:[LightGBM] [Info] Number of data points in the train set: 12600, number of used features: 15
2024-02-09 12:20:42,066:INFO:[LightGBM] [Info] Start training from score 541574.085317
2024-02-09 12:20:42,900:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000820 seconds.
2024-02-09 12:20:42,900:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-09 12:20:42,900:INFO:[LightGBM] [Info] Total Bins 2491
2024-02-09 12:20:42,901:INFO:[LightGBM] [Info] Number of data points in the train set: 12600, number of used features: 14
2024-02-09 12:20:42,901:INFO:[LightGBM] [Info] Start training from score 541574.085317
2024-02-09 12:20:43,076:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000402 seconds.
2024-02-09 12:20:43,077:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-02-09 12:20:43,077:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-02-09 12:20:43,077:INFO:[LightGBM] [Info] Total Bins 2465
2024-02-09 12:20:43,077:INFO:[LightGBM] [Info] Number of data points in the train set: 12600, number of used features: 13
2024-02-09 12:20:43,077:INFO:[LightGBM] [Info] Start training from score 541574.085317
2024-02-09 12:20:43,275:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000410 seconds.
2024-02-09 12:20:43,276:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-02-09 12:20:43,276:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-02-09 12:20:43,276:INFO:[LightGBM] [Info] Total Bins 2210
2024-02-09 12:20:43,276:INFO:[LightGBM] [Info] Number of data points in the train set: 12600, number of used features: 12
2024-02-09 12:20:43,276:INFO:[LightGBM] [Info] Start training from score 541574.085317
2024-02-09 12:20:43,399:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000739 seconds.
2024-02-09 12:20:43,399:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-09 12:20:43,399:INFO:[LightGBM] [Info] Total Bins 2205
2024-02-09 12:20:43,399:INFO:[LightGBM] [Info] Number of data points in the train set: 12600, number of used features: 11
2024-02-09 12:20:43,400:INFO:[LightGBM] [Info] Start training from score 541574.085317
2024-02-09 12:20:43,533:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000593 seconds.
2024-02-09 12:20:43,533:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-09 12:20:43,533:INFO:[LightGBM] [Info] Total Bins 2194
2024-02-09 12:20:43,533:INFO:[LightGBM] [Info] Number of data points in the train set: 12600, number of used features: 10
2024-02-09 12:20:43,534:INFO:[LightGBM] [Info] Start training from score 541574.085317
2024-02-09 12:20:43,642:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000560 seconds.
2024-02-09 12:20:43,642:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-09 12:20:43,642:INFO:[LightGBM] [Info] Total Bins 1939
2024-02-09 12:20:43,642:INFO:[LightGBM] [Info] Number of data points in the train set: 12600, number of used features: 9
2024-02-09 12:20:43,643:INFO:[LightGBM] [Info] Start training from score 541574.085317
2024-02-09 12:20:43,783:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000454 seconds.
2024-02-09 12:20:43,783:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-09 12:20:43,783:INFO:[LightGBM] [Info] Total Bins 1868
2024-02-09 12:20:43,783:INFO:[LightGBM] [Info] Number of data points in the train set: 12600, number of used features: 8
2024-02-09 12:20:43,783:INFO:[LightGBM] [Info] Start training from score 541574.085317
2024-02-09 12:20:43,892:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000391 seconds.
2024-02-09 12:20:43,892:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-09 12:20:43,892:INFO:[LightGBM] [Info] Total Bins 1647
2024-02-09 12:20:43,892:INFO:[LightGBM] [Info] Number of data points in the train set: 12600, number of used features: 7
2024-02-09 12:20:43,892:INFO:[LightGBM] [Info] Start training from score 541574.085317
2024-02-09 12:20:44,787:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000360 seconds.
2024-02-09 12:20:44,787:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-09 12:20:44,787:INFO:[LightGBM] [Info] Total Bins 1530
2024-02-09 12:20:44,787:INFO:[LightGBM] [Info] Number of data points in the train set: 12600, number of used features: 6
2024-02-09 12:20:44,788:INFO:[LightGBM] [Info] Start training from score 541574.085317
2024-02-09 12:20:44,899:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000463 seconds.
2024-02-09 12:20:44,899:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-09 12:20:44,899:INFO:[LightGBM] [Info] Total Bins 1275
2024-02-09 12:20:44,899:INFO:[LightGBM] [Info] Number of data points in the train set: 12600, number of used features: 5
2024-02-09 12:20:44,900:INFO:[LightGBM] [Info] Start training from score 541574.085317
2024-02-09 12:20:45,013:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000239 seconds.
2024-02-09 12:20:45,013:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-09 12:20:45,013:INFO:[LightGBM] [Info] Total Bins 1020
2024-02-09 12:20:45,013:INFO:[LightGBM] [Info] Number of data points in the train set: 12600, number of used features: 4
2024-02-09 12:20:45,014:INFO:[LightGBM] [Info] Start training from score 541574.085317
2024-02-09 12:20:45,089:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000185 seconds.
2024-02-09 12:20:45,089:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-09 12:20:45,090:INFO:[LightGBM] [Info] Total Bins 765
2024-02-09 12:20:45,090:INFO:[LightGBM] [Info] Number of data points in the train set: 12600, number of used features: 3
2024-02-09 12:20:45,090:INFO:[LightGBM] [Info] Start training from score 541574.085317
2024-02-09 12:20:45,162:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000151 seconds.
2024-02-09 12:20:45,162:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-09 12:20:45,162:INFO:[LightGBM] [Info] Total Bins 510
2024-02-09 12:20:45,162:INFO:[LightGBM] [Info] Number of data points in the train set: 12600, number of used features: 2
2024-02-09 12:20:45,163:INFO:[LightGBM] [Info] Start training from score 541574.085317
2024-02-09 12:20:45,245:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000100 seconds.
2024-02-09 12:20:45,245:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-09 12:20:45,245:INFO:[LightGBM] [Info] Total Bins 255
2024-02-09 12:20:45,245:INFO:[LightGBM] [Info] Number of data points in the train set: 12600, number of used features: 1
2024-02-09 12:20:45,245:INFO:[LightGBM] [Info] Start training from score 541574.085317
2024-02-09 12:20:45,352:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000597 seconds.
2024-02-09 12:20:45,353:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-02-09 12:20:45,353:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-02-09 12:20:45,353:INFO:[LightGBM] [Info] Total Bins 2620
2024-02-09 12:20:45,353:INFO:[LightGBM] [Info] Number of data points in the train set: 12600, number of used features: 22
2024-02-09 12:20:45,353:INFO:[LightGBM] [Info] Start training from score 540423.726746
2024-02-09 12:20:45,588:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000591 seconds.
2024-02-09 12:20:45,589:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-02-09 12:20:45,589:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-02-09 12:20:45,589:INFO:[LightGBM] [Info] Total Bins 2613
2024-02-09 12:20:45,589:INFO:[LightGBM] [Info] Number of data points in the train set: 12600, number of used features: 21
2024-02-09 12:20:45,589:INFO:[LightGBM] [Info] Start training from score 540423.726746
2024-02-09 12:20:45,776:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001094 seconds.
2024-02-09 12:20:45,776:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-09 12:20:45,776:INFO:[LightGBM] [Info] Total Bins 2610
2024-02-09 12:20:45,776:INFO:[LightGBM] [Info] Number of data points in the train set: 12600, number of used features: 20
2024-02-09 12:20:45,776:INFO:[LightGBM] [Info] Start training from score 540423.726746
2024-02-09 12:20:45,954:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001125 seconds.
2024-02-09 12:20:45,955:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-09 12:20:45,955:INFO:[LightGBM] [Info] Total Bins 2599
2024-02-09 12:20:45,955:INFO:[LightGBM] [Info] Number of data points in the train set: 12600, number of used features: 19
2024-02-09 12:20:45,967:INFO:[LightGBM] [Info] Start training from score 540423.726746
2024-02-09 12:20:46,159:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000519 seconds.
2024-02-09 12:20:46,159:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-02-09 12:20:46,160:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-02-09 12:20:46,160:INFO:[LightGBM] [Info] Total Bins 2597
2024-02-09 12:20:46,160:INFO:[LightGBM] [Info] Number of data points in the train set: 12600, number of used features: 18
2024-02-09 12:20:46,160:INFO:[LightGBM] [Info] Start training from score 540423.726746
2024-02-09 12:20:46,334:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000981 seconds.
2024-02-09 12:20:46,334:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-09 12:20:46,334:INFO:[LightGBM] [Info] Total Bins 2543
2024-02-09 12:20:46,334:INFO:[LightGBM] [Info] Number of data points in the train set: 12600, number of used features: 17
2024-02-09 12:20:46,335:INFO:[LightGBM] [Info] Start training from score 540423.726746
2024-02-09 12:20:46,501:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000448 seconds.
2024-02-09 12:20:46,502:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-02-09 12:20:46,502:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-02-09 12:20:46,502:INFO:[LightGBM] [Info] Total Bins 2511
2024-02-09 12:20:46,502:INFO:[LightGBM] [Info] Number of data points in the train set: 12600, number of used features: 16
2024-02-09 12:20:46,502:INFO:[LightGBM] [Info] Start training from score 540423.726746
2024-02-09 12:20:46,646:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000788 seconds.
2024-02-09 12:20:46,646:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-02-09 12:20:46,647:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-02-09 12:20:46,647:INFO:[LightGBM] [Info] Total Bins 2505
2024-02-09 12:20:46,647:INFO:[LightGBM] [Info] Number of data points in the train set: 12600, number of used features: 15
2024-02-09 12:20:46,647:INFO:[LightGBM] [Info] Start training from score 540423.726746
2024-02-09 12:20:46,834:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000831 seconds.
2024-02-09 12:20:46,834:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-09 12:20:46,834:INFO:[LightGBM] [Info] Total Bins 2492
2024-02-09 12:20:46,834:INFO:[LightGBM] [Info] Number of data points in the train set: 12600, number of used features: 14
2024-02-09 12:20:46,834:INFO:[LightGBM] [Info] Start training from score 540423.726746
2024-02-09 12:20:47,032:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000416 seconds.
2024-02-09 12:20:47,033:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-02-09 12:20:47,033:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-02-09 12:20:47,033:INFO:[LightGBM] [Info] Total Bins 2466
2024-02-09 12:20:47,033:INFO:[LightGBM] [Info] Number of data points in the train set: 12600, number of used features: 13
2024-02-09 12:20:47,033:INFO:[LightGBM] [Info] Start training from score 540423.726746
2024-02-09 12:20:47,167:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000729 seconds.
2024-02-09 12:20:47,167:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-09 12:20:47,167:INFO:[LightGBM] [Info] Total Bins 2455
2024-02-09 12:20:47,167:INFO:[LightGBM] [Info] Number of data points in the train set: 12600, number of used features: 12
2024-02-09 12:20:47,168:INFO:[LightGBM] [Info] Start training from score 540423.726746
2024-02-09 12:20:47,324:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000632 seconds.
2024-02-09 12:20:47,324:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-09 12:20:47,325:INFO:[LightGBM] [Info] Total Bins 2450
2024-02-09 12:20:47,325:INFO:[LightGBM] [Info] Number of data points in the train set: 12600, number of used features: 11
2024-02-09 12:20:47,325:INFO:[LightGBM] [Info] Start training from score 540423.726746
2024-02-09 12:20:47,445:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000658 seconds.
2024-02-09 12:20:47,445:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-09 12:20:47,445:INFO:[LightGBM] [Info] Total Bins 2195
2024-02-09 12:20:47,445:INFO:[LightGBM] [Info] Number of data points in the train set: 12600, number of used features: 10
2024-02-09 12:20:47,445:INFO:[LightGBM] [Info] Start training from score 540423.726746
2024-02-09 12:20:47,671:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000525 seconds.
2024-02-09 12:20:47,671:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-09 12:20:47,671:INFO:[LightGBM] [Info] Total Bins 1940
2024-02-09 12:20:47,671:INFO:[LightGBM] [Info] Number of data points in the train set: 12600, number of used features: 9
2024-02-09 12:20:47,672:INFO:[LightGBM] [Info] Start training from score 540423.726746
2024-02-09 12:20:47,876:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000496 seconds.
2024-02-09 12:20:47,876:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-09 12:20:47,876:INFO:[LightGBM] [Info] Total Bins 1869
2024-02-09 12:20:47,876:INFO:[LightGBM] [Info] Number of data points in the train set: 12600, number of used features: 8
2024-02-09 12:20:47,877:INFO:[LightGBM] [Info] Start training from score 540423.726746
2024-02-09 12:20:48,325:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002474 seconds.
2024-02-09 12:20:48,326:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-02-09 12:20:48,326:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-02-09 12:20:48,326:INFO:[LightGBM] [Info] Total Bins 1752
2024-02-09 12:20:48,326:INFO:[LightGBM] [Info] Number of data points in the train set: 12600, number of used features: 7
2024-02-09 12:20:48,327:INFO:[LightGBM] [Info] Start training from score 540423.726746
2024-02-09 12:20:48,572:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000572 seconds.
2024-02-09 12:20:48,572:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-09 12:20:48,572:INFO:[LightGBM] [Info] Total Bins 1497
2024-02-09 12:20:48,572:INFO:[LightGBM] [Info] Number of data points in the train set: 12600, number of used features: 6
2024-02-09 12:20:48,572:INFO:[LightGBM] [Info] Start training from score 540423.726746
2024-02-09 12:20:48,749:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000289 seconds.
2024-02-09 12:20:48,750:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-09 12:20:48,750:INFO:[LightGBM] [Info] Total Bins 1275
2024-02-09 12:20:48,750:INFO:[LightGBM] [Info] Number of data points in the train set: 12600, number of used features: 5
2024-02-09 12:20:48,750:INFO:[LightGBM] [Info] Start training from score 540423.726746
2024-02-09 12:20:48,882:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000273 seconds.
2024-02-09 12:20:48,882:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-09 12:20:48,882:INFO:[LightGBM] [Info] Total Bins 1020
2024-02-09 12:20:48,882:INFO:[LightGBM] [Info] Number of data points in the train set: 12600, number of used features: 4
2024-02-09 12:20:48,882:INFO:[LightGBM] [Info] Start training from score 540423.726746
2024-02-09 12:20:49,021:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000076 seconds.
2024-02-09 12:20:49,021:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-02-09 12:20:49,021:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-02-09 12:20:49,021:INFO:[LightGBM] [Info] Total Bins 765
2024-02-09 12:20:49,021:INFO:[LightGBM] [Info] Number of data points in the train set: 12600, number of used features: 3
2024-02-09 12:20:49,021:INFO:[LightGBM] [Info] Start training from score 540423.726746
2024-02-09 12:20:49,169:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000158 seconds.
2024-02-09 12:20:49,169:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-09 12:20:49,169:INFO:[LightGBM] [Info] Total Bins 510
2024-02-09 12:20:49,169:INFO:[LightGBM] [Info] Number of data points in the train set: 12600, number of used features: 2
2024-02-09 12:20:49,170:INFO:[LightGBM] [Info] Start training from score 540423.726746
2024-02-09 12:20:49,300:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000098 seconds.
2024-02-09 12:20:49,300:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-09 12:20:49,300:INFO:[LightGBM] [Info] Total Bins 255
2024-02-09 12:20:49,301:INFO:[LightGBM] [Info] Number of data points in the train set: 12600, number of used features: 1
2024-02-09 12:20:49,301:INFO:[LightGBM] [Info] Start training from score 540423.726746
2024-02-09 12:20:49,433:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005019 seconds.
2024-02-09 12:20:49,433:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-02-09 12:20:49,433:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-02-09 12:20:49,434:INFO:[LightGBM] [Info] Total Bins 2624
2024-02-09 12:20:49,434:INFO:[LightGBM] [Info] Number of data points in the train set: 12600, number of used features: 22
2024-02-09 12:20:49,434:INFO:[LightGBM] [Info] Start training from score 539483.547460
2024-02-09 12:20:49,643:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000572 seconds.
2024-02-09 12:20:49,643:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-02-09 12:20:49,643:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-02-09 12:20:49,643:INFO:[LightGBM] [Info] Total Bins 2617
2024-02-09 12:20:49,644:INFO:[LightGBM] [Info] Number of data points in the train set: 12600, number of used features: 21
2024-02-09 12:20:49,644:INFO:[LightGBM] [Info] Start training from score 539483.547460
2024-02-09 12:20:49,872:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014616 seconds.
2024-02-09 12:20:49,872:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-02-09 12:20:49,872:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-02-09 12:20:49,872:INFO:[LightGBM] [Info] Total Bins 2614
2024-02-09 12:20:49,873:INFO:[LightGBM] [Info] Number of data points in the train set: 12600, number of used features: 20
2024-02-09 12:20:49,874:INFO:[LightGBM] [Info] Start training from score 539483.547460
2024-02-09 12:20:50,159:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001979 seconds.
2024-02-09 12:20:50,159:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-02-09 12:20:50,159:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-02-09 12:20:50,159:INFO:[LightGBM] [Info] Total Bins 2603
2024-02-09 12:20:50,160:INFO:[LightGBM] [Info] Number of data points in the train set: 12600, number of used features: 19
2024-02-09 12:20:50,160:INFO:[LightGBM] [Info] Start training from score 539483.547460
2024-02-09 12:20:50,443:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001198 seconds.
2024-02-09 12:20:50,443:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-09 12:20:50,443:INFO:[LightGBM] [Info] Total Bins 2549
2024-02-09 12:20:50,443:INFO:[LightGBM] [Info] Number of data points in the train set: 12600, number of used features: 18
2024-02-09 12:20:50,444:INFO:[LightGBM] [Info] Start training from score 539483.547460
2024-02-09 12:20:50,701:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001025 seconds.
2024-02-09 12:20:50,701:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-09 12:20:50,701:INFO:[LightGBM] [Info] Total Bins 2547
2024-02-09 12:20:50,701:INFO:[LightGBM] [Info] Number of data points in the train set: 12600, number of used features: 17
2024-02-09 12:20:50,701:INFO:[LightGBM] [Info] Start training from score 539483.547460
2024-02-09 12:20:50,916:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001394 seconds.
2024-02-09 12:20:50,919:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-09 12:20:50,919:INFO:[LightGBM] [Info] Total Bins 2541
2024-02-09 12:20:50,919:INFO:[LightGBM] [Info] Number of data points in the train set: 12600, number of used features: 16
2024-02-09 12:20:50,919:INFO:[LightGBM] [Info] Start training from score 539483.547460
2024-02-09 12:20:51,573:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000430 seconds.
2024-02-09 12:20:51,574:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-02-09 12:20:51,574:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-02-09 12:20:51,574:INFO:[LightGBM] [Info] Total Bins 2509
2024-02-09 12:20:51,574:INFO:[LightGBM] [Info] Number of data points in the train set: 12600, number of used features: 15
2024-02-09 12:20:51,574:INFO:[LightGBM] [Info] Start training from score 539483.547460
2024-02-09 12:20:52,223:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000850 seconds.
2024-02-09 12:20:52,223:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-09 12:20:52,223:INFO:[LightGBM] [Info] Total Bins 2496
2024-02-09 12:20:52,223:INFO:[LightGBM] [Info] Number of data points in the train set: 12600, number of used features: 14
2024-02-09 12:20:52,224:INFO:[LightGBM] [Info] Start training from score 539483.547460
2024-02-09 12:20:52,439:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000404 seconds.
2024-02-09 12:20:52,440:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-02-09 12:20:52,440:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-02-09 12:20:52,440:INFO:[LightGBM] [Info] Total Bins 2469
2024-02-09 12:20:52,440:INFO:[LightGBM] [Info] Number of data points in the train set: 12600, number of used features: 13
2024-02-09 12:20:52,447:INFO:[LightGBM] [Info] Start training from score 539483.547460
2024-02-09 12:20:53,382:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016381 seconds.
2024-02-09 12:20:53,383:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-02-09 12:20:53,383:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-02-09 12:20:53,383:INFO:[LightGBM] [Info] Total Bins 2214
2024-02-09 12:20:53,383:INFO:[LightGBM] [Info] Number of data points in the train set: 12600, number of used features: 12
2024-02-09 12:20:53,384:INFO:[LightGBM] [Info] Start training from score 539483.547460
2024-02-09 12:20:53,722:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000591 seconds.
2024-02-09 12:20:53,722:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-09 12:20:53,722:INFO:[LightGBM] [Info] Total Bins 2209
2024-02-09 12:20:53,723:INFO:[LightGBM] [Info] Number of data points in the train set: 12600, number of used features: 11
2024-02-09 12:20:53,743:INFO:[LightGBM] [Info] Start training from score 539483.547460
2024-02-09 12:20:54,049:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000599 seconds.
2024-02-09 12:20:54,049:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-09 12:20:54,049:INFO:[LightGBM] [Info] Total Bins 2198
2024-02-09 12:20:54,050:INFO:[LightGBM] [Info] Number of data points in the train set: 12600, number of used features: 10
2024-02-09 12:20:54,050:INFO:[LightGBM] [Info] Start training from score 539483.547460
2024-02-09 12:20:54,667:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000597 seconds.
2024-02-09 12:20:54,667:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-09 12:20:54,668:INFO:[LightGBM] [Info] Total Bins 2127
2024-02-09 12:20:54,668:INFO:[LightGBM] [Info] Number of data points in the train set: 12600, number of used features: 9
2024-02-09 12:20:54,668:INFO:[LightGBM] [Info] Start training from score 539483.547460
2024-02-09 12:20:54,925:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000479 seconds.
2024-02-09 12:20:54,926:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-09 12:20:54,926:INFO:[LightGBM] [Info] Total Bins 1872
2024-02-09 12:20:54,926:INFO:[LightGBM] [Info] Number of data points in the train set: 12600, number of used features: 8
2024-02-09 12:20:54,927:INFO:[LightGBM] [Info] Start training from score 539483.547460
2024-02-09 12:20:55,059:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000437 seconds.
2024-02-09 12:20:55,059:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-09 12:20:55,060:INFO:[LightGBM] [Info] Total Bins 1647
2024-02-09 12:20:55,060:INFO:[LightGBM] [Info] Number of data points in the train set: 12600, number of used features: 7
2024-02-09 12:20:55,060:INFO:[LightGBM] [Info] Start training from score 539483.547460
2024-02-09 12:20:55,342:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.095771 seconds.
2024-02-09 12:20:55,343:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-09 12:20:55,343:INFO:[LightGBM] [Info] Total Bins 1392
2024-02-09 12:20:55,365:INFO:[LightGBM] [Info] Number of data points in the train set: 12600, number of used features: 6
2024-02-09 12:20:55,403:INFO:[LightGBM] [Info] Start training from score 539483.547460
2024-02-09 12:20:55,899:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000319 seconds.
2024-02-09 12:20:55,899:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-09 12:20:55,899:INFO:[LightGBM] [Info] Total Bins 1275
2024-02-09 12:20:55,899:INFO:[LightGBM] [Info] Number of data points in the train set: 12600, number of used features: 5
2024-02-09 12:20:55,899:INFO:[LightGBM] [Info] Start training from score 539483.547460
2024-02-09 12:20:56,135:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000277 seconds.
2024-02-09 12:20:56,135:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-09 12:20:56,135:INFO:[LightGBM] [Info] Total Bins 1020
2024-02-09 12:20:56,135:INFO:[LightGBM] [Info] Number of data points in the train set: 12600, number of used features: 4
2024-02-09 12:20:56,135:INFO:[LightGBM] [Info] Start training from score 539483.547460
2024-02-09 12:20:56,233:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000201 seconds.
2024-02-09 12:20:56,233:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-09 12:20:56,234:INFO:[LightGBM] [Info] Total Bins 765
2024-02-09 12:20:56,234:INFO:[LightGBM] [Info] Number of data points in the train set: 12600, number of used features: 3
2024-02-09 12:20:56,234:INFO:[LightGBM] [Info] Start training from score 539483.547460
2024-02-09 12:20:57,094:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000141 seconds.
2024-02-09 12:20:57,095:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-09 12:20:57,095:INFO:[LightGBM] [Info] Total Bins 510
2024-02-09 12:20:57,095:INFO:[LightGBM] [Info] Number of data points in the train set: 12600, number of used features: 2
2024-02-09 12:20:57,095:INFO:[LightGBM] [Info] Start training from score 539483.547460
2024-02-09 12:20:57,244:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000105 seconds.
2024-02-09 12:20:57,244:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-09 12:20:57,244:INFO:[LightGBM] [Info] Total Bins 255
2024-02-09 12:20:57,244:INFO:[LightGBM] [Info] Number of data points in the train set: 12600, number of used features: 1
2024-02-09 12:20:57,244:INFO:[LightGBM] [Info] Start training from score 539483.547460
2024-02-09 12:20:57,372:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001415 seconds.
2024-02-09 12:20:57,372:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-02-09 12:20:57,372:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-02-09 12:20:57,372:INFO:[LightGBM] [Info] Total Bins 2618
2024-02-09 12:20:57,373:INFO:[LightGBM] [Info] Number of data points in the train set: 12600, number of used features: 22
2024-02-09 12:20:57,373:INFO:[LightGBM] [Info] Start training from score 538350.010794
2024-02-09 12:20:57,927:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003022 seconds.
2024-02-09 12:20:57,927:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-02-09 12:20:57,927:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-02-09 12:20:57,927:INFO:[LightGBM] [Info] Total Bins 2611
2024-02-09 12:20:57,927:INFO:[LightGBM] [Info] Number of data points in the train set: 12600, number of used features: 21
2024-02-09 12:20:57,928:INFO:[LightGBM] [Info] Start training from score 538350.010794
2024-02-09 12:20:58,280:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001324 seconds.
2024-02-09 12:20:58,280:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-09 12:20:58,280:INFO:[LightGBM] [Info] Total Bins 2608
2024-02-09 12:20:58,280:INFO:[LightGBM] [Info] Number of data points in the train set: 12600, number of used features: 20
2024-02-09 12:20:58,280:INFO:[LightGBM] [Info] Start training from score 538350.010794
2024-02-09 12:20:58,536:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001196 seconds.
2024-02-09 12:20:58,537:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-09 12:20:58,537:INFO:[LightGBM] [Info] Total Bins 2597
2024-02-09 12:20:58,537:INFO:[LightGBM] [Info] Number of data points in the train set: 12600, number of used features: 19
2024-02-09 12:20:58,537:INFO:[LightGBM] [Info] Start training from score 538350.010794
2024-02-09 12:20:58,773:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002219 seconds.
2024-02-09 12:20:58,774:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-09 12:20:58,774:INFO:[LightGBM] [Info] Total Bins 2565
2024-02-09 12:20:58,775:INFO:[LightGBM] [Info] Number of data points in the train set: 12600, number of used features: 18
2024-02-09 12:20:58,775:INFO:[LightGBM] [Info] Start training from score 538350.010794
2024-02-09 12:20:59,780:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001069 seconds.
2024-02-09 12:20:59,781:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-09 12:20:59,781:INFO:[LightGBM] [Info] Total Bins 2512
2024-02-09 12:20:59,781:INFO:[LightGBM] [Info] Number of data points in the train set: 12600, number of used features: 17
2024-02-09 12:20:59,781:INFO:[LightGBM] [Info] Start training from score 538350.010794
2024-02-09 12:21:00,047:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000776 seconds.
2024-02-09 12:21:00,051:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-02-09 12:21:00,051:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-02-09 12:21:00,051:INFO:[LightGBM] [Info] Total Bins 2510
2024-02-09 12:21:00,058:INFO:[LightGBM] [Info] Number of data points in the train set: 12600, number of used features: 16
2024-02-09 12:21:00,058:INFO:[LightGBM] [Info] Start training from score 538350.010794
2024-02-09 12:21:00,263:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000486 seconds.
2024-02-09 12:21:00,264:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-02-09 12:21:00,264:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-02-09 12:21:00,264:INFO:[LightGBM] [Info] Total Bins 2504
2024-02-09 12:21:00,264:INFO:[LightGBM] [Info] Number of data points in the train set: 12600, number of used features: 15
2024-02-09 12:21:00,264:INFO:[LightGBM] [Info] Start training from score 538350.010794
2024-02-09 12:21:00,532:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000875 seconds.
2024-02-09 12:21:00,532:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-09 12:21:00,532:INFO:[LightGBM] [Info] Total Bins 2491
2024-02-09 12:21:00,532:INFO:[LightGBM] [Info] Number of data points in the train set: 12600, number of used features: 14
2024-02-09 12:21:00,532:INFO:[LightGBM] [Info] Start training from score 538350.010794
2024-02-09 12:21:01,381:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001574 seconds.
2024-02-09 12:21:01,381:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-09 12:21:01,381:INFO:[LightGBM] [Info] Total Bins 2465
2024-02-09 12:21:01,381:INFO:[LightGBM] [Info] Number of data points in the train set: 12600, number of used features: 13
2024-02-09 12:21:01,382:INFO:[LightGBM] [Info] Start training from score 538350.010794
2024-02-09 12:21:01,557:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001228 seconds.
2024-02-09 12:21:01,557:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-09 12:21:01,557:INFO:[LightGBM] [Info] Total Bins 2454
2024-02-09 12:21:01,558:INFO:[LightGBM] [Info] Number of data points in the train set: 12600, number of used features: 12
2024-02-09 12:21:01,558:INFO:[LightGBM] [Info] Start training from score 538350.010794
2024-02-09 12:21:01,747:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000839 seconds.
2024-02-09 12:21:01,748:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-09 12:21:01,748:INFO:[LightGBM] [Info] Total Bins 2199
2024-02-09 12:21:01,748:INFO:[LightGBM] [Info] Number of data points in the train set: 12600, number of used features: 11
2024-02-09 12:21:01,748:INFO:[LightGBM] [Info] Start training from score 538350.010794
2024-02-09 12:21:01,980:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000615 seconds.
2024-02-09 12:21:01,980:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-09 12:21:01,980:INFO:[LightGBM] [Info] Total Bins 1944
2024-02-09 12:21:01,980:INFO:[LightGBM] [Info] Number of data points in the train set: 12600, number of used features: 10
2024-02-09 12:21:01,981:INFO:[LightGBM] [Info] Start training from score 538350.010794
2024-02-09 12:21:02,894:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000554 seconds.
2024-02-09 12:21:02,894:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-09 12:21:02,894:INFO:[LightGBM] [Info] Total Bins 1939
2024-02-09 12:21:02,895:INFO:[LightGBM] [Info] Number of data points in the train set: 12600, number of used features: 9
2024-02-09 12:21:02,895:INFO:[LightGBM] [Info] Start training from score 538350.010794
2024-02-09 12:21:03,051:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000488 seconds.
2024-02-09 12:21:03,052:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-09 12:21:03,052:INFO:[LightGBM] [Info] Total Bins 1868
2024-02-09 12:21:03,052:INFO:[LightGBM] [Info] Number of data points in the train set: 12600, number of used features: 8
2024-02-09 12:21:03,052:INFO:[LightGBM] [Info] Start training from score 538350.010794
2024-02-09 12:21:03,196:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000447 seconds.
2024-02-09 12:21:03,196:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-09 12:21:03,196:INFO:[LightGBM] [Info] Total Bins 1751
2024-02-09 12:21:03,196:INFO:[LightGBM] [Info] Number of data points in the train set: 12600, number of used features: 7
2024-02-09 12:21:03,196:INFO:[LightGBM] [Info] Start training from score 538350.010794
2024-02-09 12:21:03,370:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000141 seconds.
2024-02-09 12:21:03,370:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-02-09 12:21:03,370:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-02-09 12:21:03,370:INFO:[LightGBM] [Info] Total Bins 1496
2024-02-09 12:21:03,371:INFO:[LightGBM] [Info] Number of data points in the train set: 12600, number of used features: 6
2024-02-09 12:21:03,371:INFO:[LightGBM] [Info] Start training from score 538350.010794
2024-02-09 12:21:03,569:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000311 seconds.
2024-02-09 12:21:03,570:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-09 12:21:03,570:INFO:[LightGBM] [Info] Total Bins 1275
2024-02-09 12:21:03,570:INFO:[LightGBM] [Info] Number of data points in the train set: 12600, number of used features: 5
2024-02-09 12:21:03,570:INFO:[LightGBM] [Info] Start training from score 538350.010794
2024-02-09 12:21:03,823:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001988 seconds.
2024-02-09 12:21:03,823:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-09 12:21:03,824:INFO:[LightGBM] [Info] Total Bins 1020
2024-02-09 12:21:03,833:INFO:[LightGBM] [Info] Number of data points in the train set: 12600, number of used features: 4
2024-02-09 12:21:03,845:INFO:[LightGBM] [Info] Start training from score 538350.010794
2024-02-09 12:21:04,067:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000196 seconds.
2024-02-09 12:21:04,067:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-09 12:21:04,067:INFO:[LightGBM] [Info] Total Bins 765
2024-02-09 12:21:04,067:INFO:[LightGBM] [Info] Number of data points in the train set: 12600, number of used features: 3
2024-02-09 12:21:04,068:INFO:[LightGBM] [Info] Start training from score 538350.010794
2024-02-09 12:21:04,237:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000156 seconds.
2024-02-09 12:21:04,237:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-09 12:21:04,237:INFO:[LightGBM] [Info] Total Bins 510
2024-02-09 12:21:04,237:INFO:[LightGBM] [Info] Number of data points in the train set: 12600, number of used features: 2
2024-02-09 12:21:04,238:INFO:[LightGBM] [Info] Start training from score 538350.010794
2024-02-09 12:21:04,413:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000098 seconds.
2024-02-09 12:21:04,413:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-09 12:21:04,413:INFO:[LightGBM] [Info] Total Bins 255
2024-02-09 12:21:04,413:INFO:[LightGBM] [Info] Number of data points in the train set: 12600, number of used features: 1
2024-02-09 12:21:04,414:INFO:[LightGBM] [Info] Start training from score 538350.010794
2024-02-09 12:21:05,082:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000624 seconds.
2024-02-09 12:21:05,082:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-02-09 12:21:05,083:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-02-09 12:21:05,084:INFO:[LightGBM] [Info] Total Bins 2622
2024-02-09 12:21:05,084:INFO:[LightGBM] [Info] Number of data points in the train set: 12600, number of used features: 22
2024-02-09 12:21:05,085:INFO:[LightGBM] [Info] Start training from score 540196.142857
2024-02-09 12:21:05,629:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.030282 seconds.
2024-02-09 12:21:05,629:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-02-09 12:21:05,629:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-02-09 12:21:05,630:INFO:[LightGBM] [Info] Total Bins 2615
2024-02-09 12:21:05,630:INFO:[LightGBM] [Info] Number of data points in the train set: 12600, number of used features: 21
2024-02-09 12:21:05,630:INFO:[LightGBM] [Info] Start training from score 540196.142857
2024-02-09 12:21:06,130:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008567 seconds.
2024-02-09 12:21:06,131:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-09 12:21:06,131:INFO:[LightGBM] [Info] Total Bins 2604
2024-02-09 12:21:06,131:INFO:[LightGBM] [Info] Number of data points in the train set: 12600, number of used features: 20
2024-02-09 12:21:06,131:INFO:[LightGBM] [Info] Start training from score 540196.142857
2024-02-09 12:21:06,654:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001854 seconds.
2024-02-09 12:21:06,654:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-09 12:21:06,654:INFO:[LightGBM] [Info] Total Bins 2601
2024-02-09 12:21:06,654:INFO:[LightGBM] [Info] Number of data points in the train set: 12600, number of used features: 19
2024-02-09 12:21:06,655:INFO:[LightGBM] [Info] Start training from score 540196.142857
2024-02-09 12:21:07,368:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.188461 seconds.
2024-02-09 12:21:07,368:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-02-09 12:21:07,368:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-02-09 12:21:07,369:INFO:[LightGBM] [Info] Total Bins 2548
2024-02-09 12:21:07,375:INFO:[LightGBM] [Info] Number of data points in the train set: 12600, number of used features: 18
2024-02-09 12:21:07,405:INFO:[LightGBM] [Info] Start training from score 540196.142857
2024-02-09 12:21:08,931:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000510 seconds.
2024-02-09 12:21:08,931:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-02-09 12:21:08,932:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-02-09 12:21:08,932:INFO:[LightGBM] [Info] Total Bins 2546
2024-02-09 12:21:08,932:INFO:[LightGBM] [Info] Number of data points in the train set: 12600, number of used features: 17
2024-02-09 12:21:08,932:INFO:[LightGBM] [Info] Start training from score 540196.142857
2024-02-09 12:21:09,250:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001015 seconds.
2024-02-09 12:21:09,250:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-02-09 12:21:09,250:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-02-09 12:21:09,250:INFO:[LightGBM] [Info] Total Bins 2514
2024-02-09 12:21:09,251:INFO:[LightGBM] [Info] Number of data points in the train set: 12600, number of used features: 16
2024-02-09 12:21:09,251:INFO:[LightGBM] [Info] Start training from score 540196.142857
2024-02-09 12:21:09,561:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005136 seconds.
2024-02-09 12:21:09,561:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-02-09 12:21:09,561:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-02-09 12:21:09,561:INFO:[LightGBM] [Info] Total Bins 2508
2024-02-09 12:21:09,561:INFO:[LightGBM] [Info] Number of data points in the train set: 12600, number of used features: 15
2024-02-09 12:21:09,562:INFO:[LightGBM] [Info] Start training from score 540196.142857
2024-02-09 12:21:09,900:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000897 seconds.
2024-02-09 12:21:09,900:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-02-09 12:21:09,900:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-02-09 12:21:09,900:INFO:[LightGBM] [Info] Total Bins 2495
2024-02-09 12:21:09,901:INFO:[LightGBM] [Info] Number of data points in the train set: 12600, number of used features: 14
2024-02-09 12:21:09,901:INFO:[LightGBM] [Info] Start training from score 540196.142857
2024-02-09 12:21:10,234:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000445 seconds.
2024-02-09 12:21:10,235:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-02-09 12:21:10,235:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-02-09 12:21:10,235:INFO:[LightGBM] [Info] Total Bins 2470
2024-02-09 12:21:10,235:INFO:[LightGBM] [Info] Number of data points in the train set: 12600, number of used features: 13
2024-02-09 12:21:10,235:INFO:[LightGBM] [Info] Start training from score 540196.142857
2024-02-09 12:21:10,537:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000740 seconds.
2024-02-09 12:21:10,537:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-09 12:21:10,537:INFO:[LightGBM] [Info] Total Bins 2459
2024-02-09 12:21:10,537:INFO:[LightGBM] [Info] Number of data points in the train set: 12600, number of used features: 12
2024-02-09 12:21:10,538:INFO:[LightGBM] [Info] Start training from score 540196.142857
2024-02-09 12:21:10,837:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000396 seconds.
2024-02-09 12:21:10,838:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-02-09 12:21:10,838:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-02-09 12:21:10,838:INFO:[LightGBM] [Info] Total Bins 2204
2024-02-09 12:21:10,838:INFO:[LightGBM] [Info] Number of data points in the train set: 12600, number of used features: 11
2024-02-09 12:21:10,839:INFO:[LightGBM] [Info] Start training from score 540196.142857
2024-02-09 12:21:11,204:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000624 seconds.
2024-02-09 12:21:11,205:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-09 12:21:11,205:INFO:[LightGBM] [Info] Total Bins 2199
2024-02-09 12:21:11,206:INFO:[LightGBM] [Info] Number of data points in the train set: 12600, number of used features: 10
2024-02-09 12:21:11,206:INFO:[LightGBM] [Info] Start training from score 540196.142857
2024-02-09 12:21:11,517:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000745 seconds.
2024-02-09 12:21:11,517:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-09 12:21:11,517:INFO:[LightGBM] [Info] Total Bins 1944
2024-02-09 12:21:11,517:INFO:[LightGBM] [Info] Number of data points in the train set: 12600, number of used features: 9
2024-02-09 12:21:11,517:INFO:[LightGBM] [Info] Start training from score 540196.142857
2024-02-09 12:21:11,968:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000505 seconds.
2024-02-09 12:21:11,968:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-09 12:21:11,968:INFO:[LightGBM] [Info] Total Bins 1873
2024-02-09 12:21:11,968:INFO:[LightGBM] [Info] Number of data points in the train set: 12600, number of used features: 8
2024-02-09 12:21:11,968:INFO:[LightGBM] [Info] Start training from score 540196.142857
2024-02-09 12:21:12,185:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000495 seconds.
2024-02-09 12:21:12,185:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-09 12:21:12,185:INFO:[LightGBM] [Info] Total Bins 1756
2024-02-09 12:21:12,185:INFO:[LightGBM] [Info] Number of data points in the train set: 12600, number of used features: 7
2024-02-09 12:21:12,186:INFO:[LightGBM] [Info] Start training from score 540196.142857
2024-02-09 12:21:12,320:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000397 seconds.
2024-02-09 12:21:12,321:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-09 12:21:12,321:INFO:[LightGBM] [Info] Total Bins 1501
2024-02-09 12:21:12,321:INFO:[LightGBM] [Info] Number of data points in the train set: 12600, number of used features: 6
2024-02-09 12:21:12,321:INFO:[LightGBM] [Info] Start training from score 540196.142857
2024-02-09 12:21:12,559:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000320 seconds.
2024-02-09 12:21:12,559:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-09 12:21:12,559:INFO:[LightGBM] [Info] Total Bins 1275
2024-02-09 12:21:12,559:INFO:[LightGBM] [Info] Number of data points in the train set: 12600, number of used features: 5
2024-02-09 12:21:12,560:INFO:[LightGBM] [Info] Start training from score 540196.142857
2024-02-09 12:21:12,733:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000240 seconds.
2024-02-09 12:21:12,733:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-09 12:21:12,733:INFO:[LightGBM] [Info] Total Bins 1020
2024-02-09 12:21:12,733:INFO:[LightGBM] [Info] Number of data points in the train set: 12600, number of used features: 4
2024-02-09 12:21:12,733:INFO:[LightGBM] [Info] Start training from score 540196.142857
2024-02-09 12:21:13,060:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001752 seconds.
2024-02-09 12:21:13,060:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-09 12:21:13,060:INFO:[LightGBM] [Info] Total Bins 765
2024-02-09 12:21:13,060:INFO:[LightGBM] [Info] Number of data points in the train set: 12600, number of used features: 3
2024-02-09 12:21:13,061:INFO:[LightGBM] [Info] Start training from score 540196.142857
2024-02-09 12:21:13,272:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000153 seconds.
2024-02-09 12:21:13,272:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-09 12:21:13,272:INFO:[LightGBM] [Info] Total Bins 510
2024-02-09 12:21:13,272:INFO:[LightGBM] [Info] Number of data points in the train set: 12600, number of used features: 2
2024-02-09 12:21:13,272:INFO:[LightGBM] [Info] Start training from score 540196.142857
2024-02-09 12:21:13,382:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000101 seconds.
2024-02-09 12:21:13,382:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-09 12:21:13,382:INFO:[LightGBM] [Info] Total Bins 255
2024-02-09 12:21:13,383:INFO:[LightGBM] [Info] Number of data points in the train set: 12600, number of used features: 1
2024-02-09 12:21:13,383:INFO:[LightGBM] [Info] Start training from score 540196.142857
2024-02-09 12:21:13,529:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000623 seconds.
2024-02-09 12:21:13,529:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-02-09 12:21:13,529:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-02-09 12:21:13,529:INFO:[LightGBM] [Info] Total Bins 2616
2024-02-09 12:21:13,529:INFO:[LightGBM] [Info] Number of data points in the train set: 12600, number of used features: 22
2024-02-09 12:21:13,529:INFO:[LightGBM] [Info] Start training from score 541061.342778
2024-02-09 12:21:13,765:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000629 seconds.
2024-02-09 12:21:13,765:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-02-09 12:21:13,766:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-02-09 12:21:13,766:INFO:[LightGBM] [Info] Total Bins 2609
2024-02-09 12:21:13,766:INFO:[LightGBM] [Info] Number of data points in the train set: 12600, number of used features: 21
2024-02-09 12:21:13,767:INFO:[LightGBM] [Info] Start training from score 541061.342778
2024-02-09 12:21:14,058:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000658 seconds.
2024-02-09 12:21:14,058:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-02-09 12:21:14,058:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-02-09 12:21:14,059:INFO:[LightGBM] [Info] Total Bins 2606
2024-02-09 12:21:14,059:INFO:[LightGBM] [Info] Number of data points in the train set: 12600, number of used features: 20
2024-02-09 12:21:14,059:INFO:[LightGBM] [Info] Start training from score 541061.342778
2024-02-09 12:21:14,284:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001185 seconds.
2024-02-09 12:21:14,285:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-09 12:21:14,285:INFO:[LightGBM] [Info] Total Bins 2595
2024-02-09 12:21:14,285:INFO:[LightGBM] [Info] Number of data points in the train set: 12600, number of used features: 19
2024-02-09 12:21:14,285:INFO:[LightGBM] [Info] Start training from score 541061.342778
2024-02-09 12:21:14,519:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001496 seconds.
2024-02-09 12:21:14,519:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-09 12:21:14,520:INFO:[LightGBM] [Info] Total Bins 2593
2024-02-09 12:21:14,520:INFO:[LightGBM] [Info] Number of data points in the train set: 12600, number of used features: 18
2024-02-09 12:21:14,520:INFO:[LightGBM] [Info] Start training from score 541061.342778
2024-02-09 12:21:14,794:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004150 seconds.
2024-02-09 12:21:14,794:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-02-09 12:21:14,794:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-02-09 12:21:14,794:INFO:[LightGBM] [Info] Total Bins 2541
2024-02-09 12:21:14,794:INFO:[LightGBM] [Info] Number of data points in the train set: 12600, number of used features: 17
2024-02-09 12:21:14,794:INFO:[LightGBM] [Info] Start training from score 541061.342778
2024-02-09 12:21:15,027:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000526 seconds.
2024-02-09 12:21:15,027:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-02-09 12:21:15,027:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-02-09 12:21:15,027:INFO:[LightGBM] [Info] Total Bins 2509
2024-02-09 12:21:15,028:INFO:[LightGBM] [Info] Number of data points in the train set: 12600, number of used features: 16
2024-02-09 12:21:15,028:INFO:[LightGBM] [Info] Start training from score 541061.342778
2024-02-09 12:21:15,231:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000961 seconds.
2024-02-09 12:21:15,231:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-09 12:21:15,231:INFO:[LightGBM] [Info] Total Bins 2503
2024-02-09 12:21:15,232:INFO:[LightGBM] [Info] Number of data points in the train set: 12600, number of used features: 15
2024-02-09 12:21:15,232:INFO:[LightGBM] [Info] Start training from score 541061.342778
2024-02-09 12:21:15,502:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000917 seconds.
2024-02-09 12:21:15,502:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-09 12:21:15,503:INFO:[LightGBM] [Info] Total Bins 2490
2024-02-09 12:21:15,503:INFO:[LightGBM] [Info] Number of data points in the train set: 12600, number of used features: 14
2024-02-09 12:21:15,503:INFO:[LightGBM] [Info] Start training from score 541061.342778
2024-02-09 12:21:15,702:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000920 seconds.
2024-02-09 12:21:15,702:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-09 12:21:15,702:INFO:[LightGBM] [Info] Total Bins 2235
2024-02-09 12:21:15,702:INFO:[LightGBM] [Info] Number of data points in the train set: 12600, number of used features: 13
2024-02-09 12:21:15,703:INFO:[LightGBM] [Info] Start training from score 541061.342778
2024-02-09 12:21:15,907:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000765 seconds.
2024-02-09 12:21:15,908:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-02-09 12:21:15,908:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-02-09 12:21:15,908:INFO:[LightGBM] [Info] Total Bins 2209
2024-02-09 12:21:15,908:INFO:[LightGBM] [Info] Number of data points in the train set: 12600, number of used features: 12
2024-02-09 12:21:15,908:INFO:[LightGBM] [Info] Start training from score 541061.342778
2024-02-09 12:21:16,086:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000904 seconds.
2024-02-09 12:21:16,086:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-09 12:21:16,086:INFO:[LightGBM] [Info] Total Bins 2198
2024-02-09 12:21:16,086:INFO:[LightGBM] [Info] Number of data points in the train set: 12600, number of used features: 11
2024-02-09 12:21:16,087:INFO:[LightGBM] [Info] Start training from score 541061.342778
2024-02-09 12:21:16,311:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000649 seconds.
2024-02-09 12:21:16,311:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-09 12:21:16,311:INFO:[LightGBM] [Info] Total Bins 2193
2024-02-09 12:21:16,311:INFO:[LightGBM] [Info] Number of data points in the train set: 12600, number of used features: 10
2024-02-09 12:21:16,311:INFO:[LightGBM] [Info] Start training from score 541061.342778
2024-02-09 12:21:16,483:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000593 seconds.
2024-02-09 12:21:16,483:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-09 12:21:16,483:INFO:[LightGBM] [Info] Total Bins 1938
2024-02-09 12:21:16,483:INFO:[LightGBM] [Info] Number of data points in the train set: 12600, number of used features: 9
2024-02-09 12:21:16,484:INFO:[LightGBM] [Info] Start training from score 541061.342778
2024-02-09 12:21:16,630:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000521 seconds.
2024-02-09 12:21:16,630:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-09 12:21:16,630:INFO:[LightGBM] [Info] Total Bins 1867
2024-02-09 12:21:16,631:INFO:[LightGBM] [Info] Number of data points in the train set: 12600, number of used features: 8
2024-02-09 12:21:16,631:INFO:[LightGBM] [Info] Start training from score 541061.342778
2024-02-09 12:21:16,777:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000503 seconds.
2024-02-09 12:21:16,777:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-09 12:21:16,777:INFO:[LightGBM] [Info] Total Bins 1647
2024-02-09 12:21:16,777:INFO:[LightGBM] [Info] Number of data points in the train set: 12600, number of used features: 7
2024-02-09 12:21:16,777:INFO:[LightGBM] [Info] Start training from score 541061.342778
2024-02-09 12:21:17,053:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001421 seconds.
2024-02-09 12:21:17,053:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-09 12:21:17,053:INFO:[LightGBM] [Info] Total Bins 1392
2024-02-09 12:21:17,053:INFO:[LightGBM] [Info] Number of data points in the train set: 12600, number of used features: 6
2024-02-09 12:21:17,053:INFO:[LightGBM] [Info] Start training from score 541061.342778
2024-02-09 12:21:17,276:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000344 seconds.
2024-02-09 12:21:17,276:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-09 12:21:17,277:INFO:[LightGBM] [Info] Total Bins 1275
2024-02-09 12:21:17,277:INFO:[LightGBM] [Info] Number of data points in the train set: 12600, number of used features: 5
2024-02-09 12:21:17,277:INFO:[LightGBM] [Info] Start training from score 541061.342778
2024-02-09 12:21:17,569:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003414 seconds.
2024-02-09 12:21:17,570:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-02-09 12:21:17,570:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-02-09 12:21:17,570:INFO:[LightGBM] [Info] Total Bins 1020
2024-02-09 12:21:17,570:INFO:[LightGBM] [Info] Number of data points in the train set: 12600, number of used features: 4
2024-02-09 12:21:17,570:INFO:[LightGBM] [Info] Start training from score 541061.342778
2024-02-09 12:21:17,856:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000204 seconds.
2024-02-09 12:21:17,856:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-09 12:21:17,856:INFO:[LightGBM] [Info] Total Bins 765
2024-02-09 12:21:17,862:INFO:[LightGBM] [Info] Number of data points in the train set: 12600, number of used features: 3
2024-02-09 12:21:17,864:INFO:[LightGBM] [Info] Start training from score 541061.342778
2024-02-09 12:21:17,985:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000149 seconds.
2024-02-09 12:21:17,986:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-09 12:21:17,986:INFO:[LightGBM] [Info] Total Bins 510
2024-02-09 12:21:17,986:INFO:[LightGBM] [Info] Number of data points in the train set: 12600, number of used features: 2
2024-02-09 12:21:17,986:INFO:[LightGBM] [Info] Start training from score 541061.342778
2024-02-09 12:21:18,385:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000629 seconds.
2024-02-09 12:21:18,386:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-02-09 12:21:18,386:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-02-09 12:21:18,386:INFO:[LightGBM] [Info] Total Bins 2621
2024-02-09 12:21:18,393:INFO:[LightGBM] [Info] Number of data points in the train set: 12600, number of used features: 22
2024-02-09 12:21:18,396:INFO:[LightGBM] [Info] Start training from score 540193.995873
2024-02-09 12:21:18,734:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000648 seconds.
2024-02-09 12:21:18,734:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-02-09 12:21:18,734:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-02-09 12:21:18,734:INFO:[LightGBM] [Info] Total Bins 2614
2024-02-09 12:21:18,734:INFO:[LightGBM] [Info] Number of data points in the train set: 12600, number of used features: 21
2024-02-09 12:21:18,735:INFO:[LightGBM] [Info] Start training from score 540193.995873
2024-02-09 12:21:19,027:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001235 seconds.
2024-02-09 12:21:19,028:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-09 12:21:19,028:INFO:[LightGBM] [Info] Total Bins 2611
2024-02-09 12:21:19,028:INFO:[LightGBM] [Info] Number of data points in the train set: 12600, number of used features: 20
2024-02-09 12:21:19,029:INFO:[LightGBM] [Info] Start training from score 540193.995873
2024-02-09 12:21:19,562:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006959 seconds.
2024-02-09 12:21:19,562:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-02-09 12:21:19,562:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-02-09 12:21:19,563:INFO:[LightGBM] [Info] Total Bins 2559
2024-02-09 12:21:19,563:INFO:[LightGBM] [Info] Number of data points in the train set: 12600, number of used features: 19
2024-02-09 12:21:19,563:INFO:[LightGBM] [Info] Start training from score 540193.995873
2024-02-09 12:21:21,023:INFO:Initializing create_model()
2024-02-09 12:21:21,023:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fde8e643550>, estimator=lgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-09 12:21:21,023:INFO:Checking exceptions
2024-02-09 12:21:21,175:INFO:Initializing plot_model()
2024-02-09 12:21:21,175:INFO:plot_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fde8e643550>, estimator=LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
              importance_type='split', learning_rate=0.1, max_depth=-1,
              min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
              n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
              random_state=8730, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
              subsample_for_bin=200000, subsample_freq=0), plot=parameter, scale=1, save=False, fold=KFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-02-09 12:21:21,175:INFO:Checking exceptions
2024-02-09 12:21:21,181:INFO:Preloading libraries
2024-02-09 12:21:21,186:INFO:Copying training dataset
2024-02-09 12:21:21,186:INFO:Plot type: parameter
2024-02-09 12:21:21,211:INFO:Visual Rendered Successfully
2024-02-09 12:21:21,461:INFO:plot_model() successfully completed......................................
2024-02-09 12:21:28,440:INFO:Initializing create_model()
2024-02-09 12:21:28,441:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fde8e643550>, estimator=lgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-09 12:21:28,441:INFO:Checking exceptions
2024-02-09 12:23:12,623:INFO:Initializing create_model()
2024-02-09 12:23:12,628:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fde8e643550>, estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-09 12:23:12,629:INFO:Checking exceptions
2024-02-09 12:23:12,737:INFO:Importing libraries
2024-02-09 12:23:12,738:INFO:Copying training dataset
2024-02-09 12:23:12,763:INFO:Defining folds
2024-02-09 12:23:12,764:INFO:Declaring metric variables
2024-02-09 12:23:12,770:INFO:Importing untrained model
2024-02-09 12:23:12,777:INFO:Light Gradient Boosting Machine Imported successfully
2024-02-09 12:23:12,809:INFO:Starting cross validation
2024-02-09 12:23:12,811:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-09 12:23:18,245:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.519554 seconds.
2024-02-09 12:23:18,245:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-02-09 12:23:18,245:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-02-09 12:23:18,245:INFO:[LightGBM] [Info] Total Bins 2621
2024-02-09 12:23:18,278:INFO:[LightGBM] [Info] Number of data points in the train set: 12600, number of used features: 22
2024-02-09 12:23:18,282:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.481207 seconds.
2024-02-09 12:23:18,282:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-02-09 12:23:18,282:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-02-09 12:23:18,282:INFO:[LightGBM] [Info] Total Bins 2624
2024-02-09 12:23:18,294:INFO:[LightGBM] [Info] Number of data points in the train set: 12600, number of used features: 22
2024-02-09 12:23:18,362:INFO:[LightGBM] [Info] Start training from score 540193.995873
2024-02-09 12:23:18,391:INFO:[LightGBM] [Info] Start training from score 537272.034286
2024-02-09 12:23:18,434:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.486235 seconds.
2024-02-09 12:23:18,434:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-02-09 12:23:18,434:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-02-09 12:23:18,434:INFO:[LightGBM] [Info] Total Bins 2616
2024-02-09 12:23:18,482:INFO:[LightGBM] [Info] Number of data points in the train set: 12600, number of used features: 22
2024-02-09 12:23:18,508:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.537568 seconds.
2024-02-09 12:23:18,508:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-02-09 12:23:18,508:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-02-09 12:23:18,510:INFO:[LightGBM] [Info] Total Bins 2622
2024-02-09 12:23:18,552:INFO:[LightGBM] [Info] Start training from score 541061.342778
2024-02-09 12:23:18,553:INFO:[LightGBM] [Info] Number of data points in the train set: 12600, number of used features: 22
2024-02-09 12:23:18,602:INFO:[LightGBM] [Info] Start training from score 539583.932778
2024-02-09 12:27:26,572:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-09 12:27:26,573:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-09 12:27:26,573:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-09 12:27:26,573:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-09 12:27:32,346:INFO:PyCaret RegressionExperiment
2024-02-09 12:27:32,347:INFO:Logging name: reg-default-name
2024-02-09 12:27:32,347:INFO:ML Usecase: MLUsecase.REGRESSION
2024-02-09 12:27:32,347:INFO:version 3.2.0
2024-02-09 12:27:32,347:INFO:Initializing setup()
2024-02-09 12:27:32,347:INFO:self.USI: 71dc
2024-02-09 12:27:32,347:INFO:self._variable_keys: {'X', 'gpu_n_jobs_param', 'y', 'fold_generator', 'target_param', 'n_jobs_param', 'seed', 'gpu_param', '_available_plots', 'X_train', 'exp_name_log', '_ml_usecase', 'y_test', 'logging_param', 'transform_target_param', 'html_param', 'y_train', 'exp_id', 'USI', 'data', 'X_test', 'pipeline', 'fold_shuffle_param', 'memory', 'idx', 'fold_groups_param', 'log_plots_param'}
2024-02-09 12:27:32,348:INFO:Checking environment
2024-02-09 12:27:32,348:INFO:python_version: 3.11.7
2024-02-09 12:27:32,348:INFO:python_build: ('main', 'Dec  8 2023 14:22:46')
2024-02-09 12:27:32,348:INFO:machine: x86_64
2024-02-09 12:27:32,348:INFO:platform: Linux-6.5.0-kali3-amd64-x86_64-with-glibc2.37
2024-02-09 12:27:32,348:INFO:Memory: svmem(total=8197427200, available=5652357120, percent=31.0, used=1955450880, free=3192750080, active=2345480192, inactive=1530863616, buffers=997031936, cached=2052194304, shared=268832768, slab=745574400)
2024-02-09 12:27:32,349:INFO:Physical Core: 2
2024-02-09 12:27:32,350:INFO:Logical Core: 4
2024-02-09 12:27:32,350:INFO:Checking libraries
2024-02-09 12:27:32,350:INFO:System:
2024-02-09 12:27:32,351:INFO:    python: 3.11.7 (main, Dec  8 2023, 14:22:46) [GCC 13.2.0]
2024-02-09 12:27:32,351:INFO:executable: /bin/python
2024-02-09 12:27:32,352:INFO:   machine: Linux-6.5.0-kali3-amd64-x86_64-with-glibc2.37
2024-02-09 12:27:32,352:INFO:PyCaret required dependencies:
2024-02-09 12:27:32,446:INFO:                 pip: 23.3
2024-02-09 12:27:32,446:INFO:          setuptools: 68.1.2
2024-02-09 12:27:32,446:INFO:             pycaret: 3.2.0
2024-02-09 12:27:32,446:INFO:             IPython: 8.14.0
2024-02-09 12:27:32,446:INFO:          ipywidgets: 8.1.1
2024-02-09 12:27:32,446:INFO:                tqdm: 4.64.1
2024-02-09 12:27:32,446:INFO:               numpy: 1.24.2
2024-02-09 12:27:32,446:INFO:              pandas: 1.5.3
2024-02-09 12:27:32,446:INFO:              jinja2: 3.1.2
2024-02-09 12:27:32,446:INFO:               scipy: 1.10.1
2024-02-09 12:27:32,446:INFO:              joblib: 1.3.2
2024-02-09 12:27:32,446:INFO:             sklearn: 1.2.2
2024-02-09 12:27:32,446:INFO:                pyod: 1.1.2
2024-02-09 12:27:32,447:INFO:            imblearn: 0.12.0
2024-02-09 12:27:32,447:INFO:   category_encoders: 2.6.3
2024-02-09 12:27:32,447:INFO:            lightgbm: 4.3.0
2024-02-09 12:27:32,447:INFO:               numba: 0.57.1
2024-02-09 12:27:32,447:INFO:            requests: 2.31.0
2024-02-09 12:27:32,447:INFO:          matplotlib: 3.6.3
2024-02-09 12:27:32,447:INFO:          scikitplot: 0.3.7
2024-02-09 12:27:32,447:INFO:         yellowbrick: 1.5
2024-02-09 12:27:32,447:INFO:              plotly: 5.18.0
2024-02-09 12:27:32,447:INFO:    plotly-resampler: Not installed
2024-02-09 12:27:32,447:INFO:             kaleido: 0.2.1
2024-02-09 12:27:32,447:INFO:           schemdraw: 0.15
2024-02-09 12:27:32,447:INFO:         statsmodels: 0.14.1
2024-02-09 12:27:32,447:INFO:              sktime: 0.21.1
2024-02-09 12:27:32,447:INFO:               tbats: 1.1.3
2024-02-09 12:27:32,447:INFO:            pmdarima: 2.0.4
2024-02-09 12:27:32,447:INFO:              psutil: 5.9.5
2024-02-09 12:27:32,447:INFO:          markupsafe: 2.1.3
2024-02-09 12:27:32,447:INFO:             pickle5: Not installed
2024-02-09 12:27:32,447:INFO:         cloudpickle: 3.0.0
2024-02-09 12:27:32,447:INFO:         deprecation: 2.1.0
2024-02-09 12:27:32,447:INFO:              xxhash: 3.4.1
2024-02-09 12:27:32,447:INFO:           wurlitzer: 3.0.3
2024-02-09 12:27:32,447:INFO:PyCaret optional dependencies:
2024-02-09 12:27:33,323:INFO:                shap: Not installed
2024-02-09 12:27:33,323:INFO:           interpret: Not installed
2024-02-09 12:27:33,323:INFO:                umap: Not installed
2024-02-09 12:27:33,323:INFO:     ydata_profiling: Not installed
2024-02-09 12:27:33,324:INFO:  explainerdashboard: Not installed
2024-02-09 12:27:33,324:INFO:             autoviz: Not installed
2024-02-09 12:27:33,324:INFO:           fairlearn: Not installed
2024-02-09 12:27:33,324:INFO:          deepchecks: Not installed
2024-02-09 12:27:33,324:INFO:             xgboost: 2.0.3
2024-02-09 12:27:33,324:INFO:            catboost: Not installed
2024-02-09 12:27:33,324:INFO:              kmodes: Not installed
2024-02-09 12:27:33,324:INFO:             mlxtend: Not installed
2024-02-09 12:27:33,324:INFO:       statsforecast: Not installed
2024-02-09 12:27:33,324:INFO:        tune_sklearn: Not installed
2024-02-09 12:27:33,324:INFO:                 ray: Not installed
2024-02-09 12:27:33,324:INFO:            hyperopt: Not installed
2024-02-09 12:27:33,324:INFO:              optuna: Not installed
2024-02-09 12:27:33,324:INFO:               skopt: Not installed
2024-02-09 12:27:33,324:INFO:              mlflow: Not installed
2024-02-09 12:27:33,324:INFO:              gradio: Not installed
2024-02-09 12:27:33,324:INFO:             fastapi: 0.101.0
2024-02-09 12:27:33,324:INFO:             uvicorn: 0.24.0
2024-02-09 12:27:33,324:INFO:              m2cgen: Not installed
2024-02-09 12:27:33,324:INFO:           evidently: Not installed
2024-02-09 12:27:33,324:INFO:               fugue: Not installed
2024-02-09 12:27:33,324:INFO:           streamlit: Not installed
2024-02-09 12:27:33,324:INFO:             prophet: Not installed
2024-02-09 12:27:33,324:INFO:None
2024-02-09 12:27:33,324:INFO:Set up data.
2024-02-09 12:27:33,347:INFO:Set up folding strategy.
2024-02-09 12:27:33,347:INFO:Set up train/test split.
2024-02-09 12:27:33,359:INFO:Set up index.
2024-02-09 12:27:33,360:INFO:Assigning column types.
2024-02-09 12:27:33,370:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-02-09 12:27:33,371:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-02-09 12:27:33,378:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-02-09 12:27:33,382:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-02-09 12:27:33,460:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-02-09 12:27:33,528:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-02-09 12:27:33,529:INFO:Soft dependency imported: xgboost: 2.0.3
2024-02-09 12:27:33,532:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-02-09 12:27:33,532:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-02-09 12:27:33,540:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-02-09 12:27:33,544:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-02-09 12:27:33,610:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-02-09 12:27:33,654:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-02-09 12:27:33,655:INFO:Soft dependency imported: xgboost: 2.0.3
2024-02-09 12:27:33,657:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-02-09 12:27:33,657:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2024-02-09 12:27:33,661:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-02-09 12:27:33,664:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-02-09 12:27:33,731:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-02-09 12:27:33,777:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-02-09 12:27:33,778:INFO:Soft dependency imported: xgboost: 2.0.3
2024-02-09 12:27:33,780:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-02-09 12:27:33,785:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-02-09 12:27:33,789:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-02-09 12:27:33,856:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-02-09 12:27:33,898:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-02-09 12:27:33,899:INFO:Soft dependency imported: xgboost: 2.0.3
2024-02-09 12:27:33,906:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-02-09 12:27:33,906:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2024-02-09 12:27:33,913:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-02-09 12:27:33,977:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-02-09 12:27:34,021:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-02-09 12:27:34,021:INFO:Soft dependency imported: xgboost: 2.0.3
2024-02-09 12:27:34,023:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-02-09 12:27:34,030:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-02-09 12:27:34,102:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-02-09 12:27:34,151:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-02-09 12:27:34,152:INFO:Soft dependency imported: xgboost: 2.0.3
2024-02-09 12:27:34,155:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-02-09 12:27:34,155:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2024-02-09 12:27:34,231:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-02-09 12:27:34,276:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-02-09 12:27:34,277:INFO:Soft dependency imported: xgboost: 2.0.3
2024-02-09 12:27:34,279:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-02-09 12:27:34,365:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-02-09 12:27:34,414:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-02-09 12:27:34,415:INFO:Soft dependency imported: xgboost: 2.0.3
2024-02-09 12:27:34,419:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-02-09 12:27:34,420:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-02-09 12:27:34,491:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-02-09 12:27:34,540:INFO:Soft dependency imported: xgboost: 2.0.3
2024-02-09 12:27:34,542:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-02-09 12:27:34,609:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-02-09 12:27:34,658:INFO:Soft dependency imported: xgboost: 2.0.3
2024-02-09 12:27:34,660:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-02-09 12:27:34,660:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2024-02-09 12:27:34,780:INFO:Soft dependency imported: xgboost: 2.0.3
2024-02-09 12:27:34,783:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-02-09 12:27:34,909:INFO:Soft dependency imported: xgboost: 2.0.3
2024-02-09 12:27:34,911:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-02-09 12:27:34,912:INFO:Preparing preprocessing pipeline...
2024-02-09 12:27:34,912:INFO:Set up date feature engineering.
2024-02-09 12:27:34,913:INFO:Set up simple imputation.
2024-02-09 12:27:34,976:INFO:Finished creating preprocessing pipeline.
2024-02-09 12:27:34,983:INFO:Pipeline: Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['id', 'bedrooms', 'bathrooms',
                                             'sqft_living', 'sqft_lot',
                                             'floors', 'waterfront', 'view',
                                             'condition', 'grade', 'sqft_above',
                                             'sqft_basement', 'yr_built',
                                             'yr_renovated', 'zipcode', 'lat',
                                             'long', 'sqft_living15',
                                             'sqft_lot15'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent')))])
2024-02-09 12:27:34,983:INFO:Creating final display dataframe.
2024-02-09 12:27:35,181:INFO:Setup _display_container:                     Description             Value
0                    Session id              7844
1                        Target             price
2                   Target type        Regression
3           Original data shape       (20000, 21)
4        Transformed data shape       (20000, 23)
5   Transformed train set shape       (14000, 23)
6    Transformed test set shape        (6000, 23)
7              Numeric features                19
8                 Date features                 1
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13               Fold Generator             KFold
14                  Fold Number                10
15                     CPU Jobs                -1
16                      Use GPU             False
17               Log Experiment             False
18              Experiment Name  reg-default-name
19                          USI              71dc
2024-02-09 12:27:35,345:INFO:Soft dependency imported: xgboost: 2.0.3
2024-02-09 12:27:35,348:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-02-09 12:27:35,492:INFO:Soft dependency imported: xgboost: 2.0.3
2024-02-09 12:27:35,496:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-02-09 12:27:35,497:INFO:setup() successfully completed in 3.15s...............
2024-02-09 12:27:35,506:INFO:Initializing compare_models()
2024-02-09 12:27:35,507:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f990f24a0d0>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x7f990f24a0d0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>})
2024-02-09 12:27:35,507:INFO:Checking exceptions
2024-02-09 12:27:35,514:INFO:Preparing display monitor
2024-02-09 12:27:35,577:INFO:Initializing Linear Regression
2024-02-09 12:27:35,577:INFO:Total runtime is 5.062421162923177e-06 minutes
2024-02-09 12:27:35,587:INFO:SubProcess create_model() called ==================================
2024-02-09 12:27:35,587:INFO:Initializing create_model()
2024-02-09 12:27:35,587:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f990f24a0d0>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f990cfab190>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-09 12:27:35,588:INFO:Checking exceptions
2024-02-09 12:27:35,588:INFO:Importing libraries
2024-02-09 12:27:35,588:INFO:Copying training dataset
2024-02-09 12:27:35,607:INFO:Defining folds
2024-02-09 12:27:35,607:INFO:Declaring metric variables
2024-02-09 12:27:35,613:INFO:Importing untrained model
2024-02-09 12:27:35,622:INFO:Linear Regression Imported successfully
2024-02-09 12:27:35,635:INFO:Starting cross validation
2024-02-09 12:27:35,646:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-09 12:27:40,403:INFO:Calculating mean and std
2024-02-09 12:27:40,407:INFO:Creating metrics dataframe
2024-02-09 12:27:40,422:INFO:Uploading results into container
2024-02-09 12:27:40,424:INFO:Uploading model into container now
2024-02-09 12:27:40,425:INFO:_master_model_container: 1
2024-02-09 12:27:40,425:INFO:_display_container: 2
2024-02-09 12:27:40,425:INFO:LinearRegression(n_jobs=-1)
2024-02-09 12:27:40,425:INFO:create_model() successfully completed......................................
2024-02-09 12:27:40,578:INFO:SubProcess create_model() end ==================================
2024-02-09 12:27:40,578:INFO:Creating metrics dataframe
2024-02-09 12:27:40,592:INFO:Initializing Lasso Regression
2024-02-09 12:27:40,592:INFO:Total runtime is 0.08358778158823649 minutes
2024-02-09 12:27:40,595:INFO:SubProcess create_model() called ==================================
2024-02-09 12:27:40,596:INFO:Initializing create_model()
2024-02-09 12:27:40,596:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f990f24a0d0>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f990cfab190>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-09 12:27:40,596:INFO:Checking exceptions
2024-02-09 12:27:40,596:INFO:Importing libraries
2024-02-09 12:27:40,596:INFO:Copying training dataset
2024-02-09 12:27:40,613:INFO:Defining folds
2024-02-09 12:27:40,614:INFO:Declaring metric variables
2024-02-09 12:27:40,623:INFO:Importing untrained model
2024-02-09 12:27:40,629:INFO:Lasso Regression Imported successfully
2024-02-09 12:27:40,643:INFO:Starting cross validation
2024-02-09 12:27:40,645:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-09 12:27:41,864:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.247e+14, tolerance: 1.705e+11
  model = cd_fast.enet_coordinate_descent(

2024-02-09 12:27:41,921:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.202e+14, tolerance: 1.635e+11
  model = cd_fast.enet_coordinate_descent(

2024-02-09 12:27:42,131:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.305e+14, tolerance: 1.737e+11
  model = cd_fast.enet_coordinate_descent(

2024-02-09 12:27:42,295:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.268e+14, tolerance: 1.688e+11
  model = cd_fast.enet_coordinate_descent(

2024-02-09 12:27:43,333:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.236e+14, tolerance: 1.642e+11
  model = cd_fast.enet_coordinate_descent(

2024-02-09 12:27:43,385:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.297e+14, tolerance: 1.718e+11
  model = cd_fast.enet_coordinate_descent(

2024-02-09 12:27:43,449:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.184e+14, tolerance: 1.654e+11
  model = cd_fast.enet_coordinate_descent(

2024-02-09 12:27:43,697:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.278e+14, tolerance: 1.712e+11
  model = cd_fast.enet_coordinate_descent(

2024-02-09 12:27:44,034:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.306e+14, tolerance: 1.725e+11
  model = cd_fast.enet_coordinate_descent(

2024-02-09 12:27:44,114:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.310e+14, tolerance: 1.713e+11
  model = cd_fast.enet_coordinate_descent(

2024-02-09 12:27:44,140:INFO:Calculating mean and std
2024-02-09 12:27:44,141:INFO:Creating metrics dataframe
2024-02-09 12:27:44,149:INFO:Uploading results into container
2024-02-09 12:27:44,150:INFO:Uploading model into container now
2024-02-09 12:27:44,150:INFO:_master_model_container: 2
2024-02-09 12:27:44,150:INFO:_display_container: 2
2024-02-09 12:27:44,151:INFO:Lasso(random_state=7844)
2024-02-09 12:27:44,151:INFO:create_model() successfully completed......................................
2024-02-09 12:27:44,263:INFO:SubProcess create_model() end ==================================
2024-02-09 12:27:44,263:INFO:Creating metrics dataframe
2024-02-09 12:27:44,279:INFO:Initializing Ridge Regression
2024-02-09 12:27:44,279:INFO:Total runtime is 0.14504358768463135 minutes
2024-02-09 12:27:44,285:INFO:SubProcess create_model() called ==================================
2024-02-09 12:27:44,285:INFO:Initializing create_model()
2024-02-09 12:27:44,286:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f990f24a0d0>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f990cfab190>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-09 12:27:44,286:INFO:Checking exceptions
2024-02-09 12:27:44,286:INFO:Importing libraries
2024-02-09 12:27:44,286:INFO:Copying training dataset
2024-02-09 12:27:44,304:INFO:Defining folds
2024-02-09 12:27:44,304:INFO:Declaring metric variables
2024-02-09 12:27:44,311:INFO:Importing untrained model
2024-02-09 12:27:44,316:INFO:Ridge Regression Imported successfully
2024-02-09 12:27:44,328:INFO:Starting cross validation
2024-02-09 12:27:44,330:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-09 12:27:44,459:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=9.59494e-24): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-02-09 12:27:44,459:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=9.58739e-24): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-02-09 12:27:44,460:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=9.59788e-24): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-02-09 12:27:44,460:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=9.56591e-24): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-02-09 12:27:44,583:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=9.5714e-24): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-02-09 12:27:44,603:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=9.59804e-24): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-02-09 12:27:44,613:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=9.59153e-24): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-02-09 12:27:44,630:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=9.62714e-24): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-02-09 12:27:44,700:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=9.60618e-24): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-02-09 12:27:44,705:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=9.57871e-24): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-02-09 12:27:44,740:INFO:Calculating mean and std
2024-02-09 12:27:44,743:INFO:Creating metrics dataframe
2024-02-09 12:27:44,760:INFO:Uploading results into container
2024-02-09 12:27:44,761:INFO:Uploading model into container now
2024-02-09 12:27:44,761:INFO:_master_model_container: 3
2024-02-09 12:27:44,761:INFO:_display_container: 2
2024-02-09 12:27:44,762:INFO:Ridge(random_state=7844)
2024-02-09 12:27:44,762:INFO:create_model() successfully completed......................................
2024-02-09 12:27:44,870:INFO:SubProcess create_model() end ==================================
2024-02-09 12:27:44,870:INFO:Creating metrics dataframe
2024-02-09 12:27:44,889:INFO:Initializing Elastic Net
2024-02-09 12:27:44,890:INFO:Total runtime is 0.15521873633066813 minutes
2024-02-09 12:27:44,894:INFO:SubProcess create_model() called ==================================
2024-02-09 12:27:44,895:INFO:Initializing create_model()
2024-02-09 12:27:44,895:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f990f24a0d0>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f990cfab190>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-09 12:27:44,895:INFO:Checking exceptions
2024-02-09 12:27:44,895:INFO:Importing libraries
2024-02-09 12:27:44,895:INFO:Copying training dataset
2024-02-09 12:27:44,913:INFO:Defining folds
2024-02-09 12:27:44,913:INFO:Declaring metric variables
2024-02-09 12:27:44,921:INFO:Importing untrained model
2024-02-09 12:27:44,928:INFO:Elastic Net Imported successfully
2024-02-09 12:27:44,941:INFO:Starting cross validation
2024-02-09 12:27:44,943:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-09 12:27:46,101:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.414e+14, tolerance: 1.705e+11
  model = cd_fast.enet_coordinate_descent(

2024-02-09 12:27:46,359:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.459e+14, tolerance: 1.737e+11
  model = cd_fast.enet_coordinate_descent(

2024-02-09 12:27:46,443:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.275e+14, tolerance: 1.635e+11
  model = cd_fast.enet_coordinate_descent(

2024-02-09 12:27:46,798:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.413e+14, tolerance: 1.688e+11
  model = cd_fast.enet_coordinate_descent(

2024-02-09 12:27:47,156:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.331e+14, tolerance: 1.654e+11
  model = cd_fast.enet_coordinate_descent(

2024-02-09 12:27:48,030:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.331e+14, tolerance: 1.642e+11
  model = cd_fast.enet_coordinate_descent(

2024-02-09 12:27:48,059:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.424e+14, tolerance: 1.718e+11
  model = cd_fast.enet_coordinate_descent(

2024-02-09 12:27:48,083:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.408e+14, tolerance: 1.712e+11
  model = cd_fast.enet_coordinate_descent(

2024-02-09 12:27:48,316:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.455e+14, tolerance: 1.725e+11
  model = cd_fast.enet_coordinate_descent(

2024-02-09 12:27:48,603:WARNING:/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.457e+14, tolerance: 1.713e+11
  model = cd_fast.enet_coordinate_descent(

2024-02-09 12:27:48,632:INFO:Calculating mean and std
2024-02-09 12:27:48,633:INFO:Creating metrics dataframe
2024-02-09 12:27:48,639:INFO:Uploading results into container
2024-02-09 12:27:48,640:INFO:Uploading model into container now
2024-02-09 12:27:48,641:INFO:_master_model_container: 4
2024-02-09 12:27:48,641:INFO:_display_container: 2
2024-02-09 12:27:48,642:INFO:ElasticNet(random_state=7844)
2024-02-09 12:27:48,642:INFO:create_model() successfully completed......................................
2024-02-09 12:27:48,755:INFO:SubProcess create_model() end ==================================
2024-02-09 12:27:48,755:INFO:Creating metrics dataframe
2024-02-09 12:27:48,774:INFO:Initializing Least Angle Regression
2024-02-09 12:27:48,775:INFO:Total runtime is 0.21996636390686036 minutes
2024-02-09 12:27:48,778:INFO:SubProcess create_model() called ==================================
2024-02-09 12:27:48,778:INFO:Initializing create_model()
2024-02-09 12:27:48,779:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f990f24a0d0>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f990cfab190>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-09 12:27:48,779:INFO:Checking exceptions
2024-02-09 12:27:48,779:INFO:Importing libraries
2024-02-09 12:27:48,779:INFO:Copying training dataset
2024-02-09 12:27:48,798:INFO:Defining folds
2024-02-09 12:27:48,798:INFO:Declaring metric variables
2024-02-09 12:27:48,805:INFO:Importing untrained model
2024-02-09 12:27:48,813:INFO:Least Angle Regression Imported successfully
2024-02-09 12:27:48,824:INFO:Starting cross validation
2024-02-09 12:27:48,825:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-09 12:27:49,238:INFO:Calculating mean and std
2024-02-09 12:27:49,240:INFO:Creating metrics dataframe
2024-02-09 12:27:49,243:INFO:Uploading results into container
2024-02-09 12:27:49,244:INFO:Uploading model into container now
2024-02-09 12:27:49,244:INFO:_master_model_container: 5
2024-02-09 12:27:49,244:INFO:_display_container: 2
2024-02-09 12:27:49,244:INFO:Lars(random_state=7844)
2024-02-09 12:27:49,244:INFO:create_model() successfully completed......................................
2024-02-09 12:27:49,354:INFO:SubProcess create_model() end ==================================
2024-02-09 12:27:49,354:INFO:Creating metrics dataframe
2024-02-09 12:27:49,372:INFO:Initializing Lasso Least Angle Regression
2024-02-09 12:27:49,372:INFO:Total runtime is 0.22992924054463706 minutes
2024-02-09 12:27:49,378:INFO:SubProcess create_model() called ==================================
2024-02-09 12:27:49,378:INFO:Initializing create_model()
2024-02-09 12:27:49,378:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f990f24a0d0>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f990cfab190>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-09 12:27:49,378:INFO:Checking exceptions
2024-02-09 12:27:49,378:INFO:Importing libraries
2024-02-09 12:27:49,378:INFO:Copying training dataset
2024-02-09 12:27:49,397:INFO:Defining folds
2024-02-09 12:27:49,397:INFO:Declaring metric variables
2024-02-09 12:27:49,403:INFO:Importing untrained model
2024-02-09 12:27:49,409:INFO:Lasso Least Angle Regression Imported successfully
2024-02-09 12:27:49,425:INFO:Starting cross validation
2024-02-09 12:27:49,427:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-09 12:27:49,878:INFO:Calculating mean and std
2024-02-09 12:27:49,880:INFO:Creating metrics dataframe
2024-02-09 12:27:49,882:INFO:Uploading results into container
2024-02-09 12:27:49,883:INFO:Uploading model into container now
2024-02-09 12:27:49,883:INFO:_master_model_container: 6
2024-02-09 12:27:49,883:INFO:_display_container: 2
2024-02-09 12:27:49,884:INFO:LassoLars(random_state=7844)
2024-02-09 12:27:49,884:INFO:create_model() successfully completed......................................
2024-02-09 12:27:49,992:INFO:SubProcess create_model() end ==================================
2024-02-09 12:27:49,992:INFO:Creating metrics dataframe
2024-02-09 12:27:50,005:INFO:Initializing Orthogonal Matching Pursuit
2024-02-09 12:27:50,005:INFO:Total runtime is 0.240479584534963 minutes
2024-02-09 12:27:50,010:INFO:SubProcess create_model() called ==================================
2024-02-09 12:27:50,011:INFO:Initializing create_model()
2024-02-09 12:27:50,011:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f990f24a0d0>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f990cfab190>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-09 12:27:50,011:INFO:Checking exceptions
2024-02-09 12:27:50,011:INFO:Importing libraries
2024-02-09 12:27:50,011:INFO:Copying training dataset
2024-02-09 12:27:50,030:INFO:Defining folds
2024-02-09 12:27:50,030:INFO:Declaring metric variables
2024-02-09 12:27:50,038:INFO:Importing untrained model
2024-02-09 12:27:50,043:INFO:Orthogonal Matching Pursuit Imported successfully
2024-02-09 12:27:50,059:INFO:Starting cross validation
2024-02-09 12:27:50,072:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-09 12:27:50,455:INFO:Calculating mean and std
2024-02-09 12:27:50,457:INFO:Creating metrics dataframe
2024-02-09 12:27:50,464:INFO:Uploading results into container
2024-02-09 12:27:50,465:INFO:Uploading model into container now
2024-02-09 12:27:50,465:INFO:_master_model_container: 7
2024-02-09 12:27:50,466:INFO:_display_container: 2
2024-02-09 12:27:50,466:INFO:OrthogonalMatchingPursuit()
2024-02-09 12:27:50,466:INFO:create_model() successfully completed......................................
2024-02-09 12:27:50,572:INFO:SubProcess create_model() end ==================================
2024-02-09 12:27:50,572:INFO:Creating metrics dataframe
2024-02-09 12:27:50,588:INFO:Initializing Bayesian Ridge
2024-02-09 12:27:50,588:INFO:Total runtime is 0.2501974066098531 minutes
2024-02-09 12:27:50,593:INFO:SubProcess create_model() called ==================================
2024-02-09 12:27:50,593:INFO:Initializing create_model()
2024-02-09 12:27:50,594:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f990f24a0d0>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f990cfab190>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-09 12:27:50,594:INFO:Checking exceptions
2024-02-09 12:27:50,594:INFO:Importing libraries
2024-02-09 12:27:50,594:INFO:Copying training dataset
2024-02-09 12:27:50,610:INFO:Defining folds
2024-02-09 12:27:50,610:INFO:Declaring metric variables
2024-02-09 12:27:50,615:INFO:Importing untrained model
2024-02-09 12:27:50,624:INFO:Bayesian Ridge Imported successfully
2024-02-09 12:27:50,635:INFO:Starting cross validation
2024-02-09 12:27:50,639:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-09 12:27:51,110:INFO:Calculating mean and std
2024-02-09 12:27:51,114:INFO:Creating metrics dataframe
2024-02-09 12:27:51,134:INFO:Uploading results into container
2024-02-09 12:27:51,135:INFO:Uploading model into container now
2024-02-09 12:27:51,136:INFO:_master_model_container: 8
2024-02-09 12:27:51,136:INFO:_display_container: 2
2024-02-09 12:27:51,137:INFO:BayesianRidge()
2024-02-09 12:27:51,137:INFO:create_model() successfully completed......................................
2024-02-09 12:27:51,255:INFO:SubProcess create_model() end ==================================
2024-02-09 12:27:51,255:INFO:Creating metrics dataframe
2024-02-09 12:27:51,268:INFO:Initializing Passive Aggressive Regressor
2024-02-09 12:27:51,268:INFO:Total runtime is 0.2615296522776286 minutes
2024-02-09 12:27:51,272:INFO:SubProcess create_model() called ==================================
2024-02-09 12:27:51,273:INFO:Initializing create_model()
2024-02-09 12:27:51,273:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f990f24a0d0>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f990cfab190>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-09 12:27:51,273:INFO:Checking exceptions
2024-02-09 12:27:51,273:INFO:Importing libraries
2024-02-09 12:27:51,273:INFO:Copying training dataset
2024-02-09 12:27:51,292:INFO:Defining folds
2024-02-09 12:27:51,292:INFO:Declaring metric variables
2024-02-09 12:27:51,296:INFO:Importing untrained model
2024-02-09 12:27:51,306:INFO:Passive Aggressive Regressor Imported successfully
2024-02-09 12:27:51,319:INFO:Starting cross validation
2024-02-09 12:27:51,321:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-09 12:27:51,887:INFO:Calculating mean and std
2024-02-09 12:27:51,890:INFO:Creating metrics dataframe
2024-02-09 12:27:51,894:INFO:Uploading results into container
2024-02-09 12:27:51,894:INFO:Uploading model into container now
2024-02-09 12:27:51,895:INFO:_master_model_container: 9
2024-02-09 12:27:51,895:INFO:_display_container: 2
2024-02-09 12:27:51,895:INFO:PassiveAggressiveRegressor(random_state=7844)
2024-02-09 12:27:51,895:INFO:create_model() successfully completed......................................
2024-02-09 12:27:51,998:INFO:SubProcess create_model() end ==================================
2024-02-09 12:27:51,998:INFO:Creating metrics dataframe
2024-02-09 12:27:52,022:INFO:Initializing Huber Regressor
2024-02-09 12:27:52,022:INFO:Total runtime is 0.2740906119346619 minutes
2024-02-09 12:27:52,027:INFO:SubProcess create_model() called ==================================
2024-02-09 12:27:52,027:INFO:Initializing create_model()
2024-02-09 12:27:52,027:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f990f24a0d0>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f990cfab190>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-09 12:27:52,028:INFO:Checking exceptions
2024-02-09 12:27:52,028:INFO:Importing libraries
2024-02-09 12:27:52,028:INFO:Copying training dataset
2024-02-09 12:27:52,043:INFO:Defining folds
2024-02-09 12:27:52,044:INFO:Declaring metric variables
2024-02-09 12:27:52,048:INFO:Importing untrained model
2024-02-09 12:27:52,056:INFO:Huber Regressor Imported successfully
2024-02-09 12:27:52,068:INFO:Starting cross validation
2024-02-09 12:27:52,070:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-09 12:27:52,799:INFO:Calculating mean and std
2024-02-09 12:27:52,801:INFO:Creating metrics dataframe
2024-02-09 12:27:52,806:INFO:Uploading results into container
2024-02-09 12:27:52,807:INFO:Uploading model into container now
2024-02-09 12:27:52,808:INFO:_master_model_container: 10
2024-02-09 12:27:52,809:INFO:_display_container: 2
2024-02-09 12:27:52,809:INFO:HuberRegressor()
2024-02-09 12:27:52,810:INFO:create_model() successfully completed......................................
2024-02-09 12:27:52,916:INFO:SubProcess create_model() end ==================================
2024-02-09 12:27:52,917:INFO:Creating metrics dataframe
2024-02-09 12:27:52,938:INFO:Initializing K Neighbors Regressor
2024-02-09 12:27:52,939:INFO:Total runtime is 0.2893662134806315 minutes
2024-02-09 12:27:52,945:INFO:SubProcess create_model() called ==================================
2024-02-09 12:27:52,946:INFO:Initializing create_model()
2024-02-09 12:27:52,946:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f990f24a0d0>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f990cfab190>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-09 12:27:52,946:INFO:Checking exceptions
2024-02-09 12:27:52,946:INFO:Importing libraries
2024-02-09 12:27:52,946:INFO:Copying training dataset
2024-02-09 12:27:52,967:INFO:Defining folds
2024-02-09 12:27:52,967:INFO:Declaring metric variables
2024-02-09 12:27:52,973:INFO:Importing untrained model
2024-02-09 12:27:52,979:INFO:K Neighbors Regressor Imported successfully
2024-02-09 12:27:52,994:INFO:Starting cross validation
2024-02-09 12:27:52,995:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-09 12:27:53,821:INFO:Calculating mean and std
2024-02-09 12:27:53,823:INFO:Creating metrics dataframe
2024-02-09 12:27:53,826:INFO:Uploading results into container
2024-02-09 12:27:53,827:INFO:Uploading model into container now
2024-02-09 12:27:53,827:INFO:_master_model_container: 11
2024-02-09 12:27:53,827:INFO:_display_container: 2
2024-02-09 12:27:53,828:INFO:KNeighborsRegressor(n_jobs=-1)
2024-02-09 12:27:53,828:INFO:create_model() successfully completed......................................
2024-02-09 12:27:53,933:INFO:SubProcess create_model() end ==================================
2024-02-09 12:27:53,933:INFO:Creating metrics dataframe
2024-02-09 12:27:53,949:INFO:Initializing Decision Tree Regressor
2024-02-09 12:27:53,949:INFO:Total runtime is 0.3062053600947062 minutes
2024-02-09 12:27:53,957:INFO:SubProcess create_model() called ==================================
2024-02-09 12:27:53,958:INFO:Initializing create_model()
2024-02-09 12:27:53,958:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f990f24a0d0>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f990cfab190>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-09 12:27:53,958:INFO:Checking exceptions
2024-02-09 12:27:53,959:INFO:Importing libraries
2024-02-09 12:27:53,959:INFO:Copying training dataset
2024-02-09 12:27:53,980:INFO:Defining folds
2024-02-09 12:27:53,980:INFO:Declaring metric variables
2024-02-09 12:27:53,987:INFO:Importing untrained model
2024-02-09 12:27:53,993:INFO:Decision Tree Regressor Imported successfully
2024-02-09 12:27:54,008:INFO:Starting cross validation
2024-02-09 12:27:54,010:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-09 12:27:55,301:INFO:Calculating mean and std
2024-02-09 12:27:55,306:INFO:Creating metrics dataframe
2024-02-09 12:27:55,312:INFO:Uploading results into container
2024-02-09 12:27:55,313:INFO:Uploading model into container now
2024-02-09 12:27:55,314:INFO:_master_model_container: 12
2024-02-09 12:27:55,314:INFO:_display_container: 2
2024-02-09 12:27:55,315:INFO:DecisionTreeRegressor(random_state=7844)
2024-02-09 12:27:55,315:INFO:create_model() successfully completed......................................
2024-02-09 12:27:55,448:INFO:SubProcess create_model() end ==================================
2024-02-09 12:27:55,449:INFO:Creating metrics dataframe
2024-02-09 12:27:55,466:INFO:Initializing Random Forest Regressor
2024-02-09 12:27:55,466:INFO:Total runtime is 0.3314878781636556 minutes
2024-02-09 12:27:55,473:INFO:SubProcess create_model() called ==================================
2024-02-09 12:27:55,473:INFO:Initializing create_model()
2024-02-09 12:27:55,474:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f990f24a0d0>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f990cfab190>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-09 12:27:55,474:INFO:Checking exceptions
2024-02-09 12:27:55,474:INFO:Importing libraries
2024-02-09 12:27:55,474:INFO:Copying training dataset
2024-02-09 12:27:55,493:INFO:Defining folds
2024-02-09 12:27:55,494:INFO:Declaring metric variables
2024-02-09 12:27:55,500:INFO:Importing untrained model
2024-02-09 12:27:55,508:INFO:Random Forest Regressor Imported successfully
2024-02-09 12:27:55,521:INFO:Starting cross validation
2024-02-09 12:27:55,523:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-09 12:28:55,562:INFO:Calculating mean and std
2024-02-09 12:28:55,564:INFO:Creating metrics dataframe
2024-02-09 12:28:55,572:INFO:Uploading results into container
2024-02-09 12:28:55,572:INFO:Uploading model into container now
2024-02-09 12:28:55,573:INFO:_master_model_container: 13
2024-02-09 12:28:55,573:INFO:_display_container: 2
2024-02-09 12:28:55,573:INFO:RandomForestRegressor(n_jobs=-1, random_state=7844)
2024-02-09 12:28:55,573:INFO:create_model() successfully completed......................................
2024-02-09 12:28:55,686:INFO:SubProcess create_model() end ==================================
2024-02-09 12:28:55,687:INFO:Creating metrics dataframe
2024-02-09 12:28:55,704:INFO:Initializing Extra Trees Regressor
2024-02-09 12:28:55,704:INFO:Total runtime is 1.3354583342870077 minutes
2024-02-09 12:28:55,708:INFO:SubProcess create_model() called ==================================
2024-02-09 12:28:55,709:INFO:Initializing create_model()
2024-02-09 12:28:55,709:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f990f24a0d0>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f990cfab190>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-09 12:28:55,709:INFO:Checking exceptions
2024-02-09 12:28:55,709:INFO:Importing libraries
2024-02-09 12:28:55,709:INFO:Copying training dataset
2024-02-09 12:28:55,725:INFO:Defining folds
2024-02-09 12:28:55,725:INFO:Declaring metric variables
2024-02-09 12:28:55,730:INFO:Importing untrained model
2024-02-09 12:28:55,738:INFO:Extra Trees Regressor Imported successfully
2024-02-09 12:28:55,749:INFO:Starting cross validation
2024-02-09 12:28:55,750:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-09 12:29:25,196:INFO:Calculating mean and std
2024-02-09 12:29:25,200:INFO:Creating metrics dataframe
2024-02-09 12:29:25,205:INFO:Uploading results into container
2024-02-09 12:29:25,206:INFO:Uploading model into container now
2024-02-09 12:29:25,207:INFO:_master_model_container: 14
2024-02-09 12:29:25,207:INFO:_display_container: 2
2024-02-09 12:29:25,207:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=7844)
2024-02-09 12:29:25,211:INFO:create_model() successfully completed......................................
2024-02-09 12:29:25,328:INFO:SubProcess create_model() end ==================================
2024-02-09 12:29:25,328:INFO:Creating metrics dataframe
2024-02-09 12:29:25,348:INFO:Initializing AdaBoost Regressor
2024-02-09 12:29:25,348:INFO:Total runtime is 1.8295183857282002 minutes
2024-02-09 12:29:25,352:INFO:SubProcess create_model() called ==================================
2024-02-09 12:29:25,353:INFO:Initializing create_model()
2024-02-09 12:29:25,353:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f990f24a0d0>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f990cfab190>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-09 12:29:25,353:INFO:Checking exceptions
2024-02-09 12:29:25,353:INFO:Importing libraries
2024-02-09 12:29:25,353:INFO:Copying training dataset
2024-02-09 12:29:25,368:INFO:Defining folds
2024-02-09 12:29:25,368:INFO:Declaring metric variables
2024-02-09 12:29:25,373:INFO:Importing untrained model
2024-02-09 12:29:25,380:INFO:AdaBoost Regressor Imported successfully
2024-02-09 12:29:25,393:INFO:Starting cross validation
2024-02-09 12:29:25,395:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-09 12:29:33,113:INFO:Calculating mean and std
2024-02-09 12:29:33,115:INFO:Creating metrics dataframe
2024-02-09 12:29:33,117:INFO:Uploading results into container
2024-02-09 12:29:33,118:INFO:Uploading model into container now
2024-02-09 12:29:33,118:INFO:_master_model_container: 15
2024-02-09 12:29:33,119:INFO:_display_container: 2
2024-02-09 12:29:33,119:INFO:AdaBoostRegressor(random_state=7844)
2024-02-09 12:29:33,119:INFO:create_model() successfully completed......................................
2024-02-09 12:29:33,224:INFO:SubProcess create_model() end ==================================
2024-02-09 12:29:33,224:INFO:Creating metrics dataframe
2024-02-09 12:29:33,241:INFO:Initializing Gradient Boosting Regressor
2024-02-09 12:29:33,241:INFO:Total runtime is 1.9610755125681558 minutes
2024-02-09 12:29:33,246:INFO:SubProcess create_model() called ==================================
2024-02-09 12:29:33,247:INFO:Initializing create_model()
2024-02-09 12:29:33,247:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f990f24a0d0>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f990cfab190>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-09 12:29:33,248:INFO:Checking exceptions
2024-02-09 12:29:33,248:INFO:Importing libraries
2024-02-09 12:29:33,248:INFO:Copying training dataset
2024-02-09 12:29:33,260:INFO:Defining folds
2024-02-09 12:29:33,260:INFO:Declaring metric variables
2024-02-09 12:29:33,268:INFO:Importing untrained model
2024-02-09 12:29:33,272:INFO:Gradient Boosting Regressor Imported successfully
2024-02-09 12:29:33,283:INFO:Starting cross validation
2024-02-09 12:29:33,285:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-09 12:29:50,534:INFO:Calculating mean and std
2024-02-09 12:29:50,535:INFO:Creating metrics dataframe
2024-02-09 12:29:50,538:INFO:Uploading results into container
2024-02-09 12:29:50,538:INFO:Uploading model into container now
2024-02-09 12:29:50,538:INFO:_master_model_container: 16
2024-02-09 12:29:50,538:INFO:_display_container: 2
2024-02-09 12:29:50,539:INFO:GradientBoostingRegressor(random_state=7844)
2024-02-09 12:29:50,539:INFO:create_model() successfully completed......................................
2024-02-09 12:29:50,653:INFO:SubProcess create_model() end ==================================
2024-02-09 12:29:50,653:INFO:Creating metrics dataframe
2024-02-09 12:29:50,681:INFO:Initializing Extreme Gradient Boosting
2024-02-09 12:29:50,681:INFO:Total runtime is 2.2517411748568215 minutes
2024-02-09 12:29:50,686:INFO:SubProcess create_model() called ==================================
2024-02-09 12:29:50,687:INFO:Initializing create_model()
2024-02-09 12:29:50,687:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f990f24a0d0>, estimator=xgboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f990cfab190>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-09 12:29:50,687:INFO:Checking exceptions
2024-02-09 12:29:50,687:INFO:Importing libraries
2024-02-09 12:29:50,687:INFO:Copying training dataset
2024-02-09 12:29:50,705:INFO:Defining folds
2024-02-09 12:29:50,705:INFO:Declaring metric variables
2024-02-09 12:29:50,712:INFO:Importing untrained model
2024-02-09 12:29:50,718:INFO:Extreme Gradient Boosting Imported successfully
2024-02-09 12:29:50,731:INFO:Starting cross validation
2024-02-09 12:29:50,733:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-09 12:29:53,499:INFO:Calculating mean and std
2024-02-09 12:29:53,500:INFO:Creating metrics dataframe
2024-02-09 12:29:53,503:INFO:Uploading results into container
2024-02-09 12:29:53,504:INFO:Uploading model into container now
2024-02-09 12:29:53,504:INFO:_master_model_container: 17
2024-02-09 12:29:53,504:INFO:_display_container: 2
2024-02-09 12:29:53,505:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, random_state=7844, ...)
2024-02-09 12:29:53,505:INFO:create_model() successfully completed......................................
2024-02-09 12:29:53,613:INFO:SubProcess create_model() end ==================================
2024-02-09 12:29:53,613:INFO:Creating metrics dataframe
2024-02-09 12:29:53,634:INFO:Initializing Light Gradient Boosting Machine
2024-02-09 12:29:53,635:INFO:Total runtime is 2.300968273480733 minutes
2024-02-09 12:29:53,641:INFO:SubProcess create_model() called ==================================
2024-02-09 12:29:53,641:INFO:Initializing create_model()
2024-02-09 12:29:53,641:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f990f24a0d0>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f990cfab190>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-09 12:29:53,641:INFO:Checking exceptions
2024-02-09 12:29:53,642:INFO:Importing libraries
2024-02-09 12:29:53,642:INFO:Copying training dataset
2024-02-09 12:29:53,661:INFO:Defining folds
2024-02-09 12:29:53,662:INFO:Declaring metric variables
2024-02-09 12:29:53,668:INFO:Importing untrained model
2024-02-09 12:29:53,675:INFO:Light Gradient Boosting Machine Imported successfully
2024-02-09 12:29:53,691:INFO:Starting cross validation
2024-02-09 12:29:53,693:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-09 12:44:49,221:INFO:Calculating mean and std
2024-02-09 12:44:49,223:INFO:Creating metrics dataframe
2024-02-09 12:44:49,232:INFO:Uploading results into container
2024-02-09 12:44:49,233:INFO:Uploading model into container now
2024-02-09 12:44:49,234:INFO:_master_model_container: 18
2024-02-09 12:44:49,234:INFO:_display_container: 2
2024-02-09 12:44:49,235:INFO:LGBMRegressor(n_jobs=-1, random_state=7844)
2024-02-09 12:44:49,235:INFO:create_model() successfully completed......................................
2024-02-09 12:44:49,346:INFO:SubProcess create_model() end ==================================
2024-02-09 12:44:49,346:INFO:Creating metrics dataframe
2024-02-09 12:44:49,364:INFO:Initializing Dummy Regressor
2024-02-09 12:44:49,365:INFO:Total runtime is 17.22979890902837 minutes
2024-02-09 12:44:49,368:INFO:SubProcess create_model() called ==================================
2024-02-09 12:44:49,368:INFO:Initializing create_model()
2024-02-09 12:44:49,369:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f990f24a0d0>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f990cfab190>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-09 12:44:49,369:INFO:Checking exceptions
2024-02-09 12:44:49,369:INFO:Importing libraries
2024-02-09 12:44:49,369:INFO:Copying training dataset
2024-02-09 12:44:49,385:INFO:Defining folds
2024-02-09 12:44:49,385:INFO:Declaring metric variables
2024-02-09 12:44:49,390:INFO:Importing untrained model
2024-02-09 12:44:49,395:INFO:Dummy Regressor Imported successfully
2024-02-09 12:44:49,403:INFO:Starting cross validation
2024-02-09 12:44:49,405:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-09 12:44:49,879:INFO:Calculating mean and std
2024-02-09 12:44:49,882:INFO:Creating metrics dataframe
2024-02-09 12:44:49,886:INFO:Uploading results into container
2024-02-09 12:44:49,887:INFO:Uploading model into container now
2024-02-09 12:44:49,887:INFO:_master_model_container: 19
2024-02-09 12:44:49,887:INFO:_display_container: 2
2024-02-09 12:44:49,888:INFO:DummyRegressor()
2024-02-09 12:44:49,888:INFO:create_model() successfully completed......................................
2024-02-09 12:44:50,000:INFO:SubProcess create_model() end ==================================
2024-02-09 12:44:50,000:INFO:Creating metrics dataframe
2024-02-09 12:44:50,032:INFO:Initializing create_model()
2024-02-09 12:44:50,032:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f990f24a0d0>, estimator=LGBMRegressor(n_jobs=-1, random_state=7844), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-09 12:44:50,033:INFO:Checking exceptions
2024-02-09 12:44:50,036:INFO:Importing libraries
2024-02-09 12:44:50,036:INFO:Copying training dataset
2024-02-09 12:44:50,049:INFO:Defining folds
2024-02-09 12:44:50,050:INFO:Declaring metric variables
2024-02-09 12:44:50,050:INFO:Importing untrained model
2024-02-09 12:44:50,050:INFO:Declaring custom model
2024-02-09 12:44:50,050:INFO:Light Gradient Boosting Machine Imported successfully
2024-02-09 12:44:50,051:INFO:Cross validation set to False
2024-02-09 12:44:50,051:INFO:Fitting Model
2024-02-09 12:44:50,139:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001415 seconds.
2024-02-09 12:44:50,140:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-09 12:44:50,140:INFO:[LightGBM] [Info] Total Bins 2633
2024-02-09 12:44:50,140:INFO:[LightGBM] [Info] Number of data points in the train set: 14000, number of used features: 22
2024-02-09 12:44:50,141:INFO:[LightGBM] [Info] Start training from score 540026.732714
2024-02-09 12:44:50,416:INFO:LGBMRegressor(n_jobs=-1, random_state=7844)
2024-02-09 12:44:50,416:INFO:create_model() successfully completed......................................
2024-02-09 12:44:50,597:INFO:_master_model_container: 19
2024-02-09 12:44:50,598:INFO:_display_container: 2
2024-02-09 12:44:50,599:INFO:LGBMRegressor(n_jobs=-1, random_state=7844)
2024-02-09 12:44:50,599:INFO:compare_models() successfully completed......................................
2024-02-09 12:46:26,721:INFO:Initializing create_model()
2024-02-09 12:46:26,722:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f990f24a0d0>, estimator=LGBMRegressor(n_jobs=-1, random_state=7844), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-09 12:46:26,722:INFO:Checking exceptions
2024-02-09 12:46:26,849:INFO:Importing libraries
2024-02-09 12:46:26,850:INFO:Copying training dataset
2024-02-09 12:46:26,897:INFO:Defining folds
2024-02-09 12:46:26,898:INFO:Declaring metric variables
2024-02-09 12:46:26,920:INFO:Importing untrained model
2024-02-09 12:46:26,921:INFO:Declaring custom model
2024-02-09 12:46:26,928:INFO:Light Gradient Boosting Machine Imported successfully
2024-02-09 12:46:26,939:INFO:Starting cross validation
2024-02-09 12:46:26,941:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-09 13:11:25,446:INFO:Initializing evaluate_model()
2024-02-09 13:11:25,454:INFO:evaluate_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f990f24a0d0>, estimator=LGBMRegressor(n_jobs=-1, random_state=7844), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2024-02-09 13:11:25,543:INFO:Initializing plot_model()
2024-02-09 13:11:25,543:INFO:plot_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f990f24a0d0>, estimator=LGBMRegressor(n_jobs=-1, random_state=7844), plot=pipeline, scale=1, save=False, fold=KFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-02-09 13:11:25,544:INFO:Checking exceptions
2024-02-09 13:11:25,549:INFO:Preloading libraries
2024-02-09 13:11:25,554:INFO:Copying training dataset
2024-02-09 13:11:25,554:INFO:Plot type: pipeline
2024-02-09 13:11:25,821:INFO:Visual Rendered Successfully
2024-02-09 13:11:25,996:INFO:plot_model() successfully completed......................................
2024-02-09 13:11:36,061:INFO:Initializing plot_model()
2024-02-09 13:11:36,061:INFO:plot_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f990f24a0d0>, estimator=LGBMRegressor(n_jobs=-1, random_state=7844), plot=feature, scale=1, save=False, fold=KFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-02-09 13:11:36,061:INFO:Checking exceptions
2024-02-09 13:11:36,066:INFO:Preloading libraries
2024-02-09 13:11:36,073:INFO:Copying training dataset
2024-02-09 13:11:36,074:INFO:Plot type: feature
2024-02-09 13:11:36,075:WARNING:No coef_ found. Trying feature_importances_
2024-02-09 13:11:36,377:INFO:Visual Rendered Successfully
2024-02-09 13:11:36,547:INFO:plot_model() successfully completed......................................
2024-02-09 13:11:40,179:INFO:Initializing plot_model()
2024-02-09 13:11:40,180:INFO:plot_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f990f24a0d0>, estimator=LGBMRegressor(n_jobs=-1, random_state=7844), plot=feature_all, scale=1, save=False, fold=KFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-02-09 13:11:40,181:INFO:Checking exceptions
2024-02-09 13:11:40,200:INFO:Preloading libraries
2024-02-09 13:11:40,237:INFO:Copying training dataset
2024-02-09 13:11:40,237:INFO:Plot type: feature_all
2024-02-09 13:11:40,296:WARNING:No coef_ found. Trying feature_importances_
2024-02-09 13:11:40,524:INFO:Visual Rendered Successfully
2024-02-09 13:11:40,646:INFO:plot_model() successfully completed......................................
2024-02-09 13:11:42,185:INFO:Initializing plot_model()
2024-02-09 13:11:42,185:INFO:plot_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f990f24a0d0>, estimator=LGBMRegressor(n_jobs=-1, random_state=7844), plot=feature, scale=1, save=False, fold=KFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-02-09 13:11:42,186:INFO:Checking exceptions
2024-02-09 13:11:42,204:INFO:Preloading libraries
2024-02-09 13:11:42,212:INFO:Copying training dataset
2024-02-09 13:11:42,212:INFO:Plot type: feature
2024-02-09 13:11:42,214:WARNING:No coef_ found. Trying feature_importances_
2024-02-09 13:11:42,409:INFO:Visual Rendered Successfully
2024-02-09 13:11:42,599:INFO:plot_model() successfully completed......................................
